{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFlearn is a modular and transparent deep learning library built on top of Tensorflow. It was designed to provide a higher-level api to Tesorflow in order to facilitate and speed-up experimentations, while remaining fully transparent and compatible with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "import speech_data\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_ITERS = 300000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "WIDTH = 20\n",
    "HEIGHT = 80\n",
    "CLASSES = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for data spoken_numbers_pcm.tar in data/\n",
      "Extracting data/spoken_numbers_pcm.tar to data/\n",
      "Data ready!\n",
      "loaded batch of 2402 files\n",
      "(64, 20, 80) (64, 10)\n"
     ]
    }
   ],
   "source": [
    "batch = word_batch = speech_data.mfcc_batch_generator(BATCH_SIZE)\n",
    "x, y = next(batch)\n",
    "trainX, trainY = x, y\n",
    "testX, testY = x, y  # overfitting\n",
    "print(np.shape(trainX), np.shape(trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tflearn.input_data(shape = [None, WIDTH, HEIGHT])\n",
    "net = tflearn.lstm(net, 128, dropout = 0.8)\n",
    "net = tflearn.fully_connected(net, CLASSES, activation = 'softmax')\n",
    "net = tflearn.regression(net, optimizer = 'adam', learning_rate = LEARNING_RATE, loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 5BS4NY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m2.29167\u001b[0m\u001b[0m | time: 1.256s\n",
      "| Adam | epoch: 011 | loss: 2.29167 - acc: 0.1314 | val_loss: 2.27211 - val_acc: 0.2031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m2.29533\u001b[0m\u001b[0m | time: 1.083s\n",
      "| Adam | epoch: 012 | loss: 2.29533 - acc: 0.1215 | val_loss: 2.27040 - val_acc: 0.2031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m2.28876\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 013 | loss: 2.28876 - acc: 0.1565 | val_loss: 2.26883 - val_acc: 0.2031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m2.28976\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 014 | loss: 2.28976 - acc: 0.1372 | val_loss: 2.26720 - val_acc: 0.2031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m2.28811\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 015 | loss: 2.28811 - acc: 0.1447 | val_loss: 2.26559 - val_acc: 0.2031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m2.28383\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 016 | loss: 2.28383 - acc: 0.1490 | val_loss: 2.26390 - val_acc: 0.2031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m2.27996\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 017 | loss: 2.27996 - acc: 0.1741 | val_loss: 2.26219 - val_acc: 0.2031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m2.27766\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 018 | loss: 2.27766 - acc: 0.1679 | val_loss: 2.26042 - val_acc: 0.2188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m2.27664\u001b[0m\u001b[0m | time: 1.072s\n",
      "| Adam | epoch: 019 | loss: 2.27664 - acc: 0.1640 | val_loss: 2.25865 - val_acc: 0.2344 -- iter: 64/64\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m2.28116\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 020 | loss: 2.28116 - acc: 0.1364 | val_loss: 2.25683 - val_acc: 0.2344 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: AIKAXZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m2.28132\u001b[0m\u001b[0m | time: 1.228s\n",
      "| Adam | epoch: 021 | loss: 2.28132 - acc: 0.1474 | val_loss: 2.25497 - val_acc: 0.2344 -- iter: 64/64\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m2.28104\u001b[0m\u001b[0m | time: 1.098s\n",
      "| Adam | epoch: 022 | loss: 2.28104 - acc: 0.1407 | val_loss: 2.25308 - val_acc: 0.2344 -- iter: 64/64\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m2.27883\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 023 | loss: 2.27883 - acc: 0.1497 | val_loss: 2.25140 - val_acc: 0.2344 -- iter: 64/64\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m2.28600\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 024 | loss: 2.28600 - acc: 0.1472 | val_loss: 2.24967 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m2.28165\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 025 | loss: 2.28165 - acc: 0.1710 | val_loss: 2.24790 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m2.28085\u001b[0m\u001b[0m | time: 1.070s\n",
      "| Adam | epoch: 026 | loss: 2.28085 - acc: 0.1712 | val_loss: 2.24630 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m2.28228\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 027 | loss: 2.28228 - acc: 0.1593 | val_loss: 2.24473 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m2.27960\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 028 | loss: 2.27960 - acc: 0.1625 | val_loss: 2.24309 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m2.27226\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 029 | loss: 2.27226 - acc: 0.1876 | val_loss: 2.24149 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m2.27326\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 030 | loss: 2.27326 - acc: 0.1727 | val_loss: 2.23985 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: J963G5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m2.27057\u001b[0m\u001b[0m | time: 1.193s\n",
      "| Adam | epoch: 031 | loss: 2.27057 - acc: 0.1834 | val_loss: 2.23836 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m2.27587\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 032 | loss: 2.27587 - acc: 0.1667 | val_loss: 2.23679 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m2.27223\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 033 | loss: 2.27223 - acc: 0.1850 | val_loss: 2.23524 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m2.27337\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 034 | loss: 2.27337 - acc: 0.1721 | val_loss: 2.23362 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m2.26999\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 035 | loss: 2.26999 - acc: 0.1754 | val_loss: 2.23207 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m2.27078\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 036 | loss: 2.27078 - acc: 0.1810 | val_loss: 2.23045 - val_acc: 0.2500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m2.26669\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 037 | loss: 2.26669 - acc: 0.2042 | val_loss: 2.22893 - val_acc: 0.2656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m2.27136\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 038 | loss: 2.27136 - acc: 0.1887 | val_loss: 2.22737 - val_acc: 0.2656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m2.26708\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 039 | loss: 2.26708 - acc: 0.1975 | val_loss: 2.22592 - val_acc: 0.2656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m2.27230\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 040 | loss: 2.27230 - acc: 0.1751 | val_loss: 2.22440 - val_acc: 0.2812 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: KZ8YXN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m2.26589\u001b[0m\u001b[0m | time: 1.196s\n",
      "| Adam | epoch: 041 | loss: 2.26589 - acc: 0.1974 | val_loss: 2.22303 - val_acc: 0.2812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m2.27078\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 042 | loss: 2.27078 - acc: 0.1872 | val_loss: 2.22160 - val_acc: 0.2812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m2.26527\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 043 | loss: 2.26527 - acc: 0.2066 | val_loss: 2.22010 - val_acc: 0.2812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m2.26183\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 044 | loss: 2.26183 - acc: 0.2141 | val_loss: 2.21864 - val_acc: 0.2812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m2.26355\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 045 | loss: 2.26355 - acc: 0.2122 | val_loss: 2.21729 - val_acc: 0.2812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m2.26661\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 046 | loss: 2.26661 - acc: 0.2029 | val_loss: 2.21586 - val_acc: 0.2812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m2.26484\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 047 | loss: 2.26484 - acc: 0.2004 | val_loss: 2.21452 - val_acc: 0.2656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m2.27001\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 048 | loss: 2.27001 - acc: 0.1807 | val_loss: 2.21311 - val_acc: 0.2656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m2.26589\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 049 | loss: 2.26589 - acc: 0.1867 | val_loss: 2.21185 - val_acc: 0.2656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m2.27078\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 050 | loss: 2.27078 - acc: 0.1747 | val_loss: 2.21049 - val_acc: 0.2656 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: CN55GE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m2.26649\u001b[0m\u001b[0m | time: 1.196s\n",
      "| Adam | epoch: 051 | loss: 2.26649 - acc: 0.1814 | val_loss: 2.20929 - val_acc: 0.2812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m2.27227\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 052 | loss: 2.27227 - acc: 0.1659 | val_loss: 2.20798 - val_acc: 0.2969 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m2.26608\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 053 | loss: 2.26608 - acc: 0.1830 | val_loss: 2.20678 - val_acc: 0.2969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m2.26968\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 054 | loss: 2.26968 - acc: 0.1655 | val_loss: 2.20548 - val_acc: 0.2969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m2.26407\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 055 | loss: 2.26407 - acc: 0.1798 | val_loss: 2.20411 - val_acc: 0.2969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m2.25861\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 056 | loss: 2.25861 - acc: 0.1940 | val_loss: 2.20284 - val_acc: 0.2969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m2.26085\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 057 | loss: 2.26085 - acc: 0.1931 | val_loss: 2.20165 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m2.26117\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 058 | loss: 2.26117 - acc: 0.1988 | val_loss: 2.20035 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m2.25516\u001b[0m\u001b[0m | time: 1.073s\n",
      "| Adam | epoch: 059 | loss: 2.25516 - acc: 0.2119 | val_loss: 2.19909 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m2.25820\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 060 | loss: 2.25820 - acc: 0.2046 | val_loss: 2.19773 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 4A1P73\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m2.25317\u001b[0m\u001b[0m | time: 1.198s\n",
      "| Adam | epoch: 061 | loss: 2.25317 - acc: 0.2187 | val_loss: 2.19648 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m2.25683\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 062 | loss: 2.25683 - acc: 0.2006 | val_loss: 2.19513 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m2.25289\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 063 | loss: 2.25289 - acc: 0.2108 | val_loss: 2.19381 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m2.25346\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 064 | loss: 2.25346 - acc: 0.2098 | val_loss: 2.19241 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m2.24993\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 065 | loss: 2.24993 - acc: 0.2167 | val_loss: 2.19107 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m2.25076\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 066 | loss: 2.25076 - acc: 0.2189 | val_loss: 2.18964 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m2.24665\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 067 | loss: 2.24665 - acc: 0.2245 | val_loss: 2.18834 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m2.25259\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 068 | loss: 2.25259 - acc: 0.2183 | val_loss: 2.18694 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m2.24769\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 069 | loss: 2.24769 - acc: 0.2274 | val_loss: 2.18568 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m2.25182\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 070 | loss: 2.25182 - acc: 0.2138 | val_loss: 2.18435 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: GNYMX0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m2.24828\u001b[0m\u001b[0m | time: 1.259s\n",
      "| Adam | epoch: 071 | loss: 2.24828 - acc: 0.2179 | val_loss: 2.18292 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m2.24434\u001b[0m\u001b[0m | time: 1.066s\n",
      "| Adam | epoch: 072 | loss: 2.24434 - acc: 0.2251 | val_loss: 2.18142 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m2.24125\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 073 | loss: 2.24125 - acc: 0.2296 | val_loss: 2.18004 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m2.24476\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 074 | loss: 2.24476 - acc: 0.2267 | val_loss: 2.17859 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m2.24103\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 075 | loss: 2.24103 - acc: 0.2326 | val_loss: 2.17705 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m2.23734\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 076 | loss: 2.23734 - acc: 0.2445 | val_loss: 2.17545 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m2.23378\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 077 | loss: 2.23378 - acc: 0.2500 | val_loss: 2.17396 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m2.23689\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 078 | loss: 2.23689 - acc: 0.2370 | val_loss: 2.17240 - val_acc: 0.3125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m2.23305\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 079 | loss: 2.23305 - acc: 0.2464 | val_loss: 2.17098 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m2.23721\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 080 | loss: 2.23721 - acc: 0.2404 | val_loss: 2.16946 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: EOE5YZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m2.23416\u001b[0m\u001b[0m | time: 1.212s\n",
      "| Adam | epoch: 081 | loss: 2.23416 - acc: 0.2461 | val_loss: 2.16806 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m2.23733\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 082 | loss: 2.23733 - acc: 0.2387 | val_loss: 2.16657 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m2.23452\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 083 | loss: 2.23452 - acc: 0.2382 | val_loss: 2.16502 - val_acc: 0.3281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m2.23305\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 084 | loss: 2.23305 - acc: 0.2394 | val_loss: 2.16365 - val_acc: 0.3438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m2.23741\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 085 | loss: 2.23741 - acc: 0.2280 | val_loss: 2.16217 - val_acc: 0.3438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m2.23261\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 086 | loss: 2.23261 - acc: 0.2364 | val_loss: 2.16061 - val_acc: 0.3594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m2.22970\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 087 | loss: 2.22970 - acc: 0.2487 | val_loss: 2.15919 - val_acc: 0.3594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m2.23497\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 088 | loss: 2.23497 - acc: 0.2363 | val_loss: 2.15768 - val_acc: 0.3594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m2.23215\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 089 | loss: 2.23215 - acc: 0.2440 | val_loss: 2.15631 - val_acc: 0.3594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m2.23732\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 090 | loss: 2.23732 - acc: 0.2336 | val_loss: 2.15486 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: QIIYMY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m2.23342\u001b[0m\u001b[0m | time: 1.187s\n",
      "| Adam | epoch: 091 | loss: 2.23342 - acc: 0.2431 | val_loss: 2.15345 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m2.23378\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 092 | loss: 2.23378 - acc: 0.2406 | val_loss: 2.15193 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m2.23000\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 093 | loss: 2.23000 - acc: 0.2447 | val_loss: 2.15059 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m2.23634\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 094 | loss: 2.23634 - acc: 0.2327 | val_loss: 2.14915 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m2.23108\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 095 | loss: 2.23108 - acc: 0.2454 | val_loss: 2.14761 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m2.22752\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 096 | loss: 2.22752 - acc: 0.2584 | val_loss: 2.14623 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m2.23338\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 097 | loss: 2.23338 - acc: 0.2435 | val_loss: 2.14483 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m2.23260\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 098 | loss: 2.23260 - acc: 0.2426 | val_loss: 2.14333 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m2.22770\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 099 | loss: 2.22770 - acc: 0.2527 | val_loss: 2.14198 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m2.23330\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 100 | loss: 2.23330 - acc: 0.2399 | val_loss: 2.14052 - val_acc: 0.3750 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 7BVEN3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m2.22884\u001b[0m\u001b[0m | time: 1.216s\n",
      "| Adam | epoch: 101 | loss: 2.22884 - acc: 0.2487 | val_loss: 2.13898 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m2.22466\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 102 | loss: 2.22466 - acc: 0.2535 | val_loss: 2.13731 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m2.21791\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 103 | loss: 2.21791 - acc: 0.2672 | val_loss: 2.13569 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m2.21882\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 104 | loss: 2.21882 - acc: 0.2640 | val_loss: 2.13398 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m2.21632\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 105 | loss: 2.21632 - acc: 0.2688 | val_loss: 2.13245 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m2.22350\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 106 | loss: 2.22350 - acc: 0.2560 | val_loss: 2.13084 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m2.21891\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 107 | loss: 2.21891 - acc: 0.2648 | val_loss: 2.12939 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m2.22301\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 108 | loss: 2.22301 - acc: 0.2524 | val_loss: 2.12784 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m2.21817\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 109 | loss: 2.21817 - acc: 0.2584 | val_loss: 2.12632 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m2.21947\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 110 | loss: 2.21947 - acc: 0.2513 | val_loss: 2.12468 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: U8XL0I\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m2.21328\u001b[0m\u001b[0m | time: 1.244s\n",
      "| Adam | epoch: 111 | loss: 2.21328 - acc: 0.2605 | val_loss: 2.12315 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m2.21754\u001b[0m\u001b[0m | time: 1.070s\n",
      "| Adam | epoch: 112 | loss: 2.21754 - acc: 0.2532 | val_loss: 2.12155 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m2.21292\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 113 | loss: 2.21292 - acc: 0.2607 | val_loss: 2.11998 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m2.21306\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 114 | loss: 2.21306 - acc: 0.2596 | val_loss: 2.11828 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m2.20886\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 115 | loss: 2.20886 - acc: 0.2696 | val_loss: 2.11662 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m2.20939\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 116 | loss: 2.20939 - acc: 0.2630 | val_loss: 2.11492 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m2.20614\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 117 | loss: 2.20614 - acc: 0.2679 | val_loss: 2.11327 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m2.20759\u001b[0m\u001b[0m | time: 1.072s\n",
      "| Adam | epoch: 118 | loss: 2.20759 - acc: 0.2599 | val_loss: 2.11153 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m2.20280\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 119 | loss: 2.20280 - acc: 0.2636 | val_loss: 2.10991 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m2.20764\u001b[0m\u001b[0m | time: 1.099s\n",
      "| Adam | epoch: 120 | loss: 2.20764 - acc: 0.2544 | val_loss: 2.10818 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: JJB5GF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m2.20202\u001b[0m\u001b[0m | time: 1.232s\n",
      "| Adam | epoch: 121 | loss: 2.20202 - acc: 0.2618 | val_loss: 2.10651 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m2.20290\u001b[0m\u001b[0m | time: 1.083s\n",
      "| Adam | epoch: 122 | loss: 2.20290 - acc: 0.2575 | val_loss: 2.10476 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m2.19980\u001b[0m\u001b[0m | time: 1.074s\n",
      "| Adam | epoch: 123 | loss: 2.19980 - acc: 0.2583 | val_loss: 2.10309 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m2.20249\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 124 | loss: 2.20249 - acc: 0.2528 | val_loss: 2.10133 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m2.19868\u001b[0m\u001b[0m | time: 1.108s\n",
      "| Adam | epoch: 125 | loss: 2.19868 - acc: 0.2603 | val_loss: 2.09948 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m2.19541\u001b[0m\u001b[0m | time: 1.077s\n",
      "| Adam | epoch: 126 | loss: 2.19541 - acc: 0.2718 | val_loss: 2.09755 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m2.18927\u001b[0m\u001b[0m | time: 1.076s\n",
      "| Adam | epoch: 127 | loss: 2.18927 - acc: 0.2805 | val_loss: 2.09579 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m2.19678\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 128 | loss: 2.19678 - acc: 0.2665 | val_loss: 2.09396 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m2.19227\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 129 | loss: 2.19227 - acc: 0.2790 | val_loss: 2.09233 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m2.19925\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 130 | loss: 2.19925 - acc: 0.2651 | val_loss: 2.09058 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: YPBHS6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m2.19415\u001b[0m\u001b[0m | time: 1.191s\n",
      "| Adam | epoch: 131 | loss: 2.19415 - acc: 0.2667 | val_loss: 2.08899 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m2.19904\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 132 | loss: 2.19904 - acc: 0.2619 | val_loss: 2.08729 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m2.19306\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 133 | loss: 2.19306 - acc: 0.2670 | val_loss: 2.08554 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m2.18810\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 134 | loss: 2.18810 - acc: 0.2762 | val_loss: 2.08373 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m2.18315\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 135 | loss: 2.18315 - acc: 0.2736 | val_loss: 2.08209 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m2.19243\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 136 | loss: 2.19243 - acc: 0.2634 | val_loss: 2.08036 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m2.18782\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 137 | loss: 2.18782 - acc: 0.2746 | val_loss: 2.07880 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m2.19546\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 138 | loss: 2.19546 - acc: 0.2628 | val_loss: 2.07712 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m2.18938\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 139 | loss: 2.18938 - acc: 0.2709 | val_loss: 2.07548 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m2.19066\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 140 | loss: 2.19066 - acc: 0.2594 | val_loss: 2.07372 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: ONIFUC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m2.18496\u001b[0m\u001b[0m | time: 1.199s\n",
      "| Adam | epoch: 141 | loss: 2.18496 - acc: 0.2647 | val_loss: 2.07213 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m2.19302\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 142 | loss: 2.19302 - acc: 0.2523 | val_loss: 2.07045 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m2.18613\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 143 | loss: 2.18613 - acc: 0.2614 | val_loss: 2.06896 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m2.19468\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 144 | loss: 2.19468 - acc: 0.2556 | val_loss: 2.06738 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m2.18872\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 145 | loss: 2.18872 - acc: 0.2613 | val_loss: 2.06585 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m2.18973\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 146 | loss: 2.18973 - acc: 0.2602 | val_loss: 2.06422 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m2.18453\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 147 | loss: 2.18453 - acc: 0.2654 | val_loss: 2.06265 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m2.18598\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 148 | loss: 2.18598 - acc: 0.2623 | val_loss: 2.06101 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m2.17931\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 149 | loss: 2.17931 - acc: 0.2767 | val_loss: 2.05954 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m2.18643\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 150 | loss: 2.18643 - acc: 0.2615 | val_loss: 2.05796 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: JHPCHP\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m2.18003\u001b[0m\u001b[0m | time: 1.194s\n",
      "| Adam | epoch: 151 | loss: 2.18003 - acc: 0.2635 | val_loss: 2.05628 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m2.17482\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 152 | loss: 2.17482 - acc: 0.2731 | val_loss: 2.05478 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m2.18594\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 153 | loss: 2.18594 - acc: 0.2583 | val_loss: 2.05331 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m2.18916\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 154 | loss: 2.18916 - acc: 0.2590 | val_loss: 2.05172 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m2.18001\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 155 | loss: 2.18001 - acc: 0.2737 | val_loss: 2.05027 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m2.18568\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 156 | loss: 2.18568 - acc: 0.2651 | val_loss: 2.04867 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m2.17591\u001b[0m\u001b[0m | time: 1.150s\n",
      "| Adam | epoch: 157 | loss: 2.17591 - acc: 0.2761 | val_loss: 2.04713 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m2.18103\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 158 | loss: 2.18103 - acc: 0.2719 | val_loss: 2.04545 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m2.17332\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 159 | loss: 2.17332 - acc: 0.2744 | val_loss: 2.04393 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m2.18011\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 160 | loss: 2.18011 - acc: 0.2579 | val_loss: 2.04230 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 9XEEY4\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m2.17277\u001b[0m\u001b[0m | time: 1.195s\n",
      "| Adam | epoch: 161 | loss: 2.17277 - acc: 0.2696 | val_loss: 2.04086 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m2.18335\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 162 | loss: 2.18335 - acc: 0.2505 | val_loss: 2.03931 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m2.17643\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 163 | loss: 2.17643 - acc: 0.2582 | val_loss: 2.03792 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m2.18489\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 164 | loss: 2.18489 - acc: 0.2402 | val_loss: 2.03644 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m2.17806\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 165 | loss: 2.17806 - acc: 0.2537 | val_loss: 2.03486 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m2.17147\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 166 | loss: 2.17147 - acc: 0.2611 | val_loss: 2.03350 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m2.18216\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 167 | loss: 2.18216 - acc: 0.2444 | val_loss: 2.03218 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m2.18632\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 168 | loss: 2.18632 - acc: 0.2372 | val_loss: 2.03070 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m2.17711\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 169 | loss: 2.17711 - acc: 0.2509 | val_loss: 2.02911 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m2.16857\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 170 | loss: 2.16857 - acc: 0.2602 | val_loss: 2.02759 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: Z2K7UK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m2.17281\u001b[0m\u001b[0m | time: 1.196s\n",
      "| Adam | epoch: 171 | loss: 2.17281 - acc: 0.2561 | val_loss: 2.02596 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m2.16355\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 172 | loss: 2.16355 - acc: 0.2602 | val_loss: 2.02454 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m2.17508\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 173 | loss: 2.17508 - acc: 0.2435 | val_loss: 2.02334 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m2.18726\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 174 | loss: 2.18726 - acc: 0.2285 | val_loss: 2.02200 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m2.17796\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 175 | loss: 2.17796 - acc: 0.2479 | val_loss: 2.02051 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m2.16902\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 176 | loss: 2.16902 - acc: 0.2590 | val_loss: 2.01915 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m2.17428\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 177 | loss: 2.17428 - acc: 0.2503 | val_loss: 2.01786 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m2.17511\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 178 | loss: 2.17511 - acc: 0.2440 | val_loss: 2.01643 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m2.16574\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 179 | loss: 2.16574 - acc: 0.2556 | val_loss: 2.01487 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m2.15854\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 180 | loss: 2.15854 - acc: 0.2644 | val_loss: 2.01352 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: OTF4GY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m2.16834\u001b[0m\u001b[0m | time: 1.200s\n",
      "| Adam | epoch: 181 | loss: 2.16834 - acc: 0.2520 | val_loss: 2.01201 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m2.15778\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 182 | loss: 2.15778 - acc: 0.2674 | val_loss: 2.01066 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m2.16662\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 183 | loss: 2.16662 - acc: 0.2532 | val_loss: 2.00918 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m2.15869\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 184 | loss: 2.15869 - acc: 0.2607 | val_loss: 2.00778 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m2.16144\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 185 | loss: 2.16144 - acc: 0.2596 | val_loss: 2.00621 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m2.15153\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 186 | loss: 2.15153 - acc: 0.2712 | val_loss: 2.00454 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m2.14421\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 187 | loss: 2.14421 - acc: 0.2800 | val_loss: 2.00279 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m2.13802\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 188 | loss: 2.13802 - acc: 0.2832 | val_loss: 2.00095 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m2.13337\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 189 | loss: 2.13337 - acc: 0.2877 | val_loss: 1.99922 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m2.14035\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 190 | loss: 2.14035 - acc: 0.2777 | val_loss: 1.99743 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: Q1JMAY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m2.13332\u001b[0m\u001b[0m | time: 1.189s\n",
      "| Adam | epoch: 191 | loss: 2.13332 - acc: 0.2812 | val_loss: 1.99590 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m2.14783\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 192 | loss: 2.14783 - acc: 0.2593 | val_loss: 1.99426 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m2.14089\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 193 | loss: 2.14089 - acc: 0.2662 | val_loss: 1.99271 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m2.14506\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 194 | loss: 2.14506 - acc: 0.2708 | val_loss: 1.99103 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m2.13547\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 195 | loss: 2.13547 - acc: 0.2812 | val_loss: 1.98961 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m2.15101\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 196 | loss: 2.15101 - acc: 0.2656 | val_loss: 1.98810 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m2.14201\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 197 | loss: 2.14201 - acc: 0.2781 | val_loss: 1.98646 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m2.13487\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 198 | loss: 2.13487 - acc: 0.2800 | val_loss: 1.98506 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m2.15135\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 199 | loss: 2.15135 - acc: 0.2645 | val_loss: 1.98384 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m2.16330\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 200 | loss: 2.16330 - acc: 0.2568 | val_loss: 1.98246 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: JBX6FN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m2.15242\u001b[0m\u001b[0m | time: 1.197s\n",
      "| Adam | epoch: 201 | loss: 2.15242 - acc: 0.2733 | val_loss: 1.98105 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m2.15091\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 202 | loss: 2.15091 - acc: 0.2710 | val_loss: 1.97949 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m2.14092\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 203 | loss: 2.14092 - acc: 0.2829 | val_loss: 1.97800 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m2.14661\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 204 | loss: 2.14661 - acc: 0.2765 | val_loss: 1.97639 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m2.13780\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 205 | loss: 2.13780 - acc: 0.2848 | val_loss: 1.97467 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m2.12998\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 206 | loss: 2.12998 - acc: 0.2813 | val_loss: 1.97314 - val_acc: 0.3906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m2.14366\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 207 | loss: 2.14366 - acc: 0.2704 | val_loss: 1.97167 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m2.14738\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 208 | loss: 2.14738 - acc: 0.2637 | val_loss: 1.97007 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m2.13774\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 209 | loss: 2.13774 - acc: 0.2717 | val_loss: 1.96860 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m2.14492\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 210 | loss: 2.14492 - acc: 0.2648 | val_loss: 1.96694 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: PM8AK6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m2.13258\u001b[0m\u001b[0m | time: 1.200s\n",
      "| Adam | epoch: 211 | loss: 2.13258 - acc: 0.2774 | val_loss: 1.96551 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m2.14436\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 212 | loss: 2.14436 - acc: 0.2637 | val_loss: 1.96396 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m2.13345\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 213 | loss: 2.13345 - acc: 0.2748 | val_loss: 1.96267 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m2.15034\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 214 | loss: 2.15034 - acc: 0.2599 | val_loss: 1.96123 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m2.13931\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 215 | loss: 2.13931 - acc: 0.2729 | val_loss: 1.95962 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m2.12938\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 216 | loss: 2.12938 - acc: 0.2800 | val_loss: 1.95826 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m2.14401\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 217 | loss: 2.14401 - acc: 0.2661 | val_loss: 1.95709 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m2.15418\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 218 | loss: 2.15418 - acc: 0.2582 | val_loss: 1.95579 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m2.14413\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 219 | loss: 2.14413 - acc: 0.2668 | val_loss: 1.95461 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m2.15649\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 220 | loss: 2.15649 - acc: 0.2542 | val_loss: 1.95326 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 1WO96P\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m2.14510\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 221 | loss: 2.14510 - acc: 0.2584 | val_loss: 1.95213 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m2.15924\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 222 | loss: 2.15924 - acc: 0.2498 | val_loss: 1.95083 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m2.14571\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 223 | loss: 2.14571 - acc: 0.2685 | val_loss: 1.94970 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m2.15519\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 224 | loss: 2.15519 - acc: 0.2573 | val_loss: 1.94839 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m2.14237\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 225 | loss: 2.14237 - acc: 0.2691 | val_loss: 1.94695 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m2.13129\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 226 | loss: 2.13129 - acc: 0.2719 | val_loss: 1.94568 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m2.14601\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 227 | loss: 2.14601 - acc: 0.2525 | val_loss: 1.94456 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m2.15906\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 228 | loss: 2.15906 - acc: 0.2366 | val_loss: 1.94326 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m2.14811\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 229 | loss: 2.14811 - acc: 0.2489 | val_loss: 1.94217 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m2.16281\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 230 | loss: 2.16281 - acc: 0.2365 | val_loss: 1.94089 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: IV6AG3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m2.14886\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 231 | loss: 2.14886 - acc: 0.2535 | val_loss: 1.93945 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m2.13807\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 232 | loss: 2.13807 - acc: 0.2625 | val_loss: 1.93786 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m2.12783\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 233 | loss: 2.12783 - acc: 0.2753 | val_loss: 1.93645 - val_acc: 0.4062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m2.14175\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 234 | loss: 2.14175 - acc: 0.2603 | val_loss: 1.93492 - val_acc: 0.4219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m2.13143\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 235 | loss: 2.13143 - acc: 0.2671 | val_loss: 1.93357 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m2.14237\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 236 | loss: 2.14237 - acc: 0.2622 | val_loss: 1.93203 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m2.12856\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 237 | loss: 2.12856 - acc: 0.2735 | val_loss: 1.93056 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m2.13118\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 238 | loss: 2.13118 - acc: 0.2665 | val_loss: 1.92893 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m2.12179\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 239 | loss: 2.12179 - acc: 0.2758 | val_loss: 1.92753 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m2.13503\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 240 | loss: 2.13503 - acc: 0.2685 | val_loss: 1.92600 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: UVMDOE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m2.12401\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 241 | loss: 2.12401 - acc: 0.2807 | val_loss: 1.92433 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m2.11170\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 242 | loss: 2.11170 - acc: 0.2870 | val_loss: 1.92252 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m2.09989\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 243 | loss: 2.09989 - acc: 0.2989 | val_loss: 1.92065 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m2.09108\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 244 | loss: 2.09108 - acc: 0.3050 | val_loss: 1.91864 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m2.08287\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 245 | loss: 2.08287 - acc: 0.3167 | val_loss: 1.91688 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m2.10311\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 246 | loss: 2.10311 - acc: 0.2991 | val_loss: 1.91501 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m2.09160\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 247 | loss: 2.09160 - acc: 0.3098 | val_loss: 1.91323 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m2.09601\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 248 | loss: 2.09601 - acc: 0.3038 | val_loss: 1.91134 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m2.08603\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 249 | loss: 2.08603 - acc: 0.3141 | val_loss: 1.90952 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m2.09066\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 250 | loss: 2.09066 - acc: 0.3092 | val_loss: 1.90756 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: MC1O46\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m2.08212\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 251 | loss: 2.08212 - acc: 0.3205 | val_loss: 1.90586 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m2.10159\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 252 | loss: 2.10159 - acc: 0.2931 | val_loss: 1.90401 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m2.09291\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 253 | loss: 2.09291 - acc: 0.3013 | val_loss: 1.90205 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m2.08518\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 254 | loss: 2.08518 - acc: 0.3118 | val_loss: 1.90013 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m2.08848\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 255 | loss: 2.08848 - acc: 0.3103 | val_loss: 1.89849 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m2.10652\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 256 | loss: 2.10652 - acc: 0.2949 | val_loss: 1.89670 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m2.09568\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 257 | loss: 2.09568 - acc: 0.3029 | val_loss: 1.89516 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m2.11067\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 258 | loss: 2.11067 - acc: 0.2976 | val_loss: 1.89346 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m2.09809\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 259 | loss: 2.09809 - acc: 0.3054 | val_loss: 1.89189 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m2.10851\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 260 | loss: 2.10851 - acc: 0.2998 | val_loss: 1.89019 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: B2PO9X\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m2.09649\u001b[0m\u001b[0m | time: 1.195s\n",
      "| Adam | epoch: 261 | loss: 2.09649 - acc: 0.3120 | val_loss: 1.88877 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m2.11775\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 262 | loss: 2.11775 - acc: 0.2949 | val_loss: 1.88720 - val_acc: 0.4375 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m2.10426\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 263 | loss: 2.10426 - acc: 0.3045 | val_loss: 1.88583 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m2.12100\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 264 | loss: 2.12100 - acc: 0.2896 | val_loss: 1.88431 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m2.10789\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 265 | loss: 2.10789 - acc: 0.3029 | val_loss: 1.88295 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m2.11873\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 266 | loss: 2.11873 - acc: 0.2976 | val_loss: 1.88146 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m2.10516\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 267 | loss: 2.10516 - acc: 0.3116 | val_loss: 1.88017 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m2.12623\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 268 | loss: 2.12623 - acc: 0.2898 | val_loss: 1.87874 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m2.11104\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 269 | loss: 2.11104 - acc: 0.3014 | val_loss: 1.87731 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m2.11250\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 270 | loss: 2.11250 - acc: 0.3057 | val_loss: 1.87574 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: IJRY6A\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m2.10017\u001b[0m\u001b[0m | time: 1.206s\n",
      "| Adam | epoch: 271 | loss: 2.10017 - acc: 0.3142 | val_loss: 1.87443 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m2.12075\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 272 | loss: 2.12075 - acc: 0.2890 | val_loss: 1.87296 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m2.10477\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 273 | loss: 2.10477 - acc: 0.2976 | val_loss: 1.87176 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m2.12889\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 274 | loss: 2.12889 - acc: 0.2788 | val_loss: 1.87041 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m2.11500\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 275 | loss: 2.11500 - acc: 0.2884 | val_loss: 1.86892 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m2.09838\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 276 | loss: 2.09838 - acc: 0.3064 | val_loss: 1.86759 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m2.11021\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 277 | loss: 2.11021 - acc: 0.2930 | val_loss: 1.86612 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m2.09560\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 278 | loss: 2.09560 - acc: 0.3012 | val_loss: 1.86451 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m2.08022\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 279 | loss: 2.08022 - acc: 0.3101 | val_loss: 1.86290 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m2.07807\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 280 | loss: 2.07807 - acc: 0.3104 | val_loss: 1.86119 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 62ZGWR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m2.06612\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 281 | loss: 2.06612 - acc: 0.3199 | val_loss: 1.85973 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m2.08581\u001b[0m\u001b[0m | time: 1.068s\n",
      "| Adam | epoch: 282 | loss: 2.08581 - acc: 0.3005 | val_loss: 1.85811 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m2.07145\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 283 | loss: 2.07145 - acc: 0.3204 | val_loss: 1.85634 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m2.06227\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 284 | loss: 2.06227 - acc: 0.3274 | val_loss: 1.85490 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m2.09159\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 285 | loss: 2.09159 - acc: 0.3072 | val_loss: 1.85373 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m2.11340\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 286 | loss: 2.11340 - acc: 0.2843 | val_loss: 1.85236 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m2.09729\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 287 | loss: 2.09729 - acc: 0.2965 | val_loss: 1.85128 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m2.12302\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 288 | loss: 2.12302 - acc: 0.2731 | val_loss: 1.84996 - val_acc: 0.4531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m2.10527\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 289 | loss: 2.10527 - acc: 0.2911 | val_loss: 1.84889 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m2.12835\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 290 | loss: 2.12835 - acc: 0.2682 | val_loss: 1.84760 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 5KMYI2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m2.11068\u001b[0m\u001b[0m | time: 1.288s\n",
      "| Adam | epoch: 291 | loss: 2.11068 - acc: 0.2805 | val_loss: 1.84608 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m2.09224\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 292 | loss: 2.09224 - acc: 0.2930 | val_loss: 1.84442 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m2.08015\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 293 | loss: 2.08015 - acc: 0.3044 | val_loss: 1.84285 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m2.08206\u001b[0m\u001b[0m | time: 1.065s\n",
      "| Adam | epoch: 294 | loss: 2.08206 - acc: 0.3052 | val_loss: 1.84116 - val_acc: 0.4688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m2.06935\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 295 | loss: 2.06935 - acc: 0.3184 | val_loss: 1.83974 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m2.09451\u001b[0m\u001b[0m | time: 1.063s\n",
      "| Adam | epoch: 296 | loss: 2.09451 - acc: 0.3022 | val_loss: 1.83817 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m2.07981\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 297 | loss: 2.07981 - acc: 0.3142 | val_loss: 1.83684 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m2.10354\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 298 | loss: 2.10354 - acc: 0.2952 | val_loss: 1.83533 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m2.08825\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 299 | loss: 2.08825 - acc: 0.3017 | val_loss: 1.83396 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m2.09969\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 300 | loss: 2.09969 - acc: 0.2902 | val_loss: 1.83242 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: CQXARG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m2.08383\u001b[0m\u001b[0m | time: 1.198s\n",
      "| Adam | epoch: 301 | loss: 2.08383 - acc: 0.3018 | val_loss: 1.83076 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m2.06926\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 302 | loss: 2.06926 - acc: 0.3154 | val_loss: 1.82933 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m2.09008\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 303 | loss: 2.09008 - acc: 0.2979 | val_loss: 1.82776 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m2.07193\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 304 | loss: 2.07193 - acc: 0.3135 | val_loss: 1.82605 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m2.05880\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 305 | loss: 2.05880 - acc: 0.3243 | val_loss: 1.82419 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m2.04488\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 306 | loss: 2.04488 - acc: 0.3372 | val_loss: 1.82258 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m2.07089\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 307 | loss: 2.07089 - acc: 0.3113 | val_loss: 1.82124 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m2.08923\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 308 | loss: 2.08923 - acc: 0.2926 | val_loss: 1.81972 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m2.07316\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 309 | loss: 2.07316 - acc: 0.3056 | val_loss: 1.81808 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m2.05822\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 310 | loss: 2.05822 - acc: 0.3219 | val_loss: 1.81652 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: V73OBW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m2.06634\u001b[0m\u001b[0m | time: 1.194s\n",
      "| Adam | epoch: 311 | loss: 2.06634 - acc: 0.3163 | val_loss: 1.81520 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m2.09064\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 312 | loss: 2.09064 - acc: 0.2924 | val_loss: 1.81368 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m2.07188\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 313 | loss: 2.07188 - acc: 0.3085 | val_loss: 1.81235 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m2.09089\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 314 | loss: 2.09089 - acc: 0.2917 | val_loss: 1.81082 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m2.07448\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 315 | loss: 2.07448 - acc: 0.3047 | val_loss: 1.80917 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m2.05638\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 316 | loss: 2.05638 - acc: 0.3227 | val_loss: 1.80782 - val_acc: 0.4844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m2.08762\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 317 | loss: 2.08762 - acc: 0.3014 | val_loss: 1.80657 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m2.10469\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 318 | loss: 2.10469 - acc: 0.2884 | val_loss: 1.80514 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m2.08455\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 319 | loss: 2.08455 - acc: 0.3049 | val_loss: 1.80371 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m2.08692\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 320 | loss: 2.08692 - acc: 0.2978 | val_loss: 1.80213 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: GPAP0C\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m2.07006\u001b[0m\u001b[0m | time: 1.198s\n",
      "| Adam | epoch: 321 | loss: 2.07006 - acc: 0.3134 | val_loss: 1.80036 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m2.05508\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 322 | loss: 2.05508 - acc: 0.3273 | val_loss: 1.79843 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m2.03889\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 323 | loss: 2.03889 - acc: 0.3399 | val_loss: 1.79640 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m2.02595\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 324 | loss: 2.02595 - acc: 0.3512 | val_loss: 1.79426 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m2.01434\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 325 | loss: 2.01434 - acc: 0.3630 | val_loss: 1.79204 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m2.00241\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 326 | loss: 2.00241 - acc: 0.3783 | val_loss: 1.79002 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m2.02277\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 327 | loss: 2.02277 - acc: 0.3592 | val_loss: 1.78831 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m2.04911\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 328 | loss: 2.04911 - acc: 0.3405 | val_loss: 1.78646 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m2.03417\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 329 | loss: 2.03417 - acc: 0.3470 | val_loss: 1.78463 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m2.03461\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 330 | loss: 2.03461 - acc: 0.3530 | val_loss: 1.78264 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: BCPKGG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m2.02004\u001b[0m\u001b[0m | time: 1.214s\n",
      "| Adam | epoch: 331 | loss: 2.02004 - acc: 0.3614 | val_loss: 1.78079 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m2.03054\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 332 | loss: 2.03054 - acc: 0.3503 | val_loss: 1.77884 - val_acc: 0.5000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m2.01810\u001b[0m\u001b[0m | time: 1.066s\n",
      "| Adam | epoch: 333 | loss: 2.01810 - acc: 0.3590 | val_loss: 1.77696 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m2.02576\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 334 | loss: 2.02576 - acc: 0.3512 | val_loss: 1.77495 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m2.01384\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 335 | loss: 2.01384 - acc: 0.3614 | val_loss: 1.77317 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m2.04455\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 336 | loss: 2.04455 - acc: 0.3331 | val_loss: 1.77130 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m2.02969\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 337 | loss: 2.02969 - acc: 0.3420 | val_loss: 1.76970 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m2.05107\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 338 | loss: 2.05107 - acc: 0.3218 | val_loss: 1.76794 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m2.03360\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 339 | loss: 2.03360 - acc: 0.3381 | val_loss: 1.76624 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m2.03654\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 340 | loss: 2.03654 - acc: 0.3355 | val_loss: 1.76441 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: RZHX5E\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m2.02024\u001b[0m\u001b[0m | time: 1.193s\n",
      "| Adam | epoch: 341 | loss: 2.02024 - acc: 0.3488 | val_loss: 1.76244 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m2.00879\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 342 | loss: 2.00879 - acc: 0.3546 | val_loss: 1.76039 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m1.99321\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 343 | loss: 1.99321 - acc: 0.3707 | val_loss: 1.75837 - val_acc: 0.5156 -- iter: 64/64\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m1.99861\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 344 | loss: 1.99861 - acc: 0.3742 | val_loss: 1.75624 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m1.98794\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 345 | loss: 1.98794 - acc: 0.3806 | val_loss: 1.75401 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m1.97748\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 346 | loss: 1.97748 - acc: 0.3910 | val_loss: 1.75208 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m2.01356\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 347 | loss: 2.01356 - acc: 0.3612 | val_loss: 1.75044 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m2.04245\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 348 | loss: 2.04245 - acc: 0.3329 | val_loss: 1.74864 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m2.02722\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 349 | loss: 2.02722 - acc: 0.3449 | val_loss: 1.74722 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m2.06326\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 350 | loss: 2.06326 - acc: 0.3198 | val_loss: 1.74570 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: DZTO59\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m2.04530\u001b[0m\u001b[0m | time: 1.221s\n",
      "| Adam | epoch: 351 | loss: 2.04530 - acc: 0.3300 | val_loss: 1.74401 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m2.02689\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 352 | loss: 2.02689 - acc: 0.3470 | val_loss: 1.74250 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m2.04585\u001b[0m\u001b[0m | time: 1.068s\n",
      "| Adam | epoch: 353 | loss: 2.04585 - acc: 0.3342 | val_loss: 1.74082 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m2.02646\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 354 | loss: 2.02646 - acc: 0.3430 | val_loss: 1.73924 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m2.03061\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 355 | loss: 2.03061 - acc: 0.3368 | val_loss: 1.73754 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m2.01451\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 356 | loss: 2.01451 - acc: 0.3469 | val_loss: 1.73603 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m2.03724\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 357 | loss: 2.03724 - acc: 0.3309 | val_loss: 1.73442 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m2.01913\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 358 | loss: 2.01913 - acc: 0.3447 | val_loss: 1.73267 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m2.00248\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 359 | loss: 2.00248 - acc: 0.3540 | val_loss: 1.73105 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m2.01455\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 360 | loss: 2.01455 - acc: 0.3483 | val_loss: 1.72933 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 23WWK0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m2.00054\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 361 | loss: 2.00054 - acc: 0.3666 | val_loss: 1.72766 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m2.00195\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 362 | loss: 2.00195 - acc: 0.3643 | val_loss: 1.72580 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m1.98571\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 363 | loss: 1.98571 - acc: 0.3763 | val_loss: 1.72384 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m1.97018\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 364 | loss: 1.97018 - acc: 0.3934 | val_loss: 1.72178 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m1.95744\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 365 | loss: 1.95744 - acc: 0.4025 | val_loss: 1.72003 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m1.99693\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 366 | loss: 1.99693 - acc: 0.3810 | val_loss: 1.71810 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m1.98174\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 367 | loss: 1.98174 - acc: 0.3866 | val_loss: 1.71653 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m2.02133\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 368 | loss: 2.02133 - acc: 0.3558 | val_loss: 1.71485 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m2.00483\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 369 | loss: 2.00483 - acc: 0.3608 | val_loss: 1.71318 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m2.01752\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 370 | loss: 2.01752 - acc: 0.3607 | val_loss: 1.71134 - val_acc: 0.5312 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: B8U1Y6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m2.00010\u001b[0m\u001b[0m | time: 1.197s\n",
      "| Adam | epoch: 371 | loss: 2.00010 - acc: 0.3746 | val_loss: 1.70936 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m1.98276\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 372 | loss: 1.98276 - acc: 0.3856 | val_loss: 1.70726 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m1.96764\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 373 | loss: 1.96764 - acc: 0.3939 | val_loss: 1.70525 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m1.97655\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 374 | loss: 1.97655 - acc: 0.3842 | val_loss: 1.70315 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m1.96110\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 375 | loss: 1.96110 - acc: 0.3958 | val_loss: 1.70126 - val_acc: 0.5469 -- iter: 64/64\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m1.99362\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 376 | loss: 1.99362 - acc: 0.3687 | val_loss: 1.69923 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m1.97667\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 377 | loss: 1.97667 - acc: 0.3818 | val_loss: 1.69749 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m2.01195\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 378 | loss: 2.01195 - acc: 0.3515 | val_loss: 1.69559 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m1.99082\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 379 | loss: 1.99082 - acc: 0.3710 | val_loss: 1.69383 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m1.99960\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 380 | loss: 1.99960 - acc: 0.3667 | val_loss: 1.69192 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: HE8RI9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m1.98245\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 381 | loss: 1.98245 - acc: 0.3847 | val_loss: 1.68986 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m1.96712\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 382 | loss: 1.96712 - acc: 0.4009 | val_loss: 1.68774 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m1.95173\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 383 | loss: 1.95173 - acc: 0.4124 | val_loss: 1.68590 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m1.98505\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 384 | loss: 1.98505 - acc: 0.3837 | val_loss: 1.68392 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m1.96630\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 385 | loss: 1.96630 - acc: 0.3984 | val_loss: 1.68222 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m1.99851\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 386 | loss: 1.99851 - acc: 0.3726 | val_loss: 1.68033 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m1.98037\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 387 | loss: 1.98037 - acc: 0.3854 | val_loss: 1.67851 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m1.98336\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 388 | loss: 1.98336 - acc: 0.3797 | val_loss: 1.67655 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m1.96546\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 389 | loss: 1.96546 - acc: 0.3917 | val_loss: 1.67497 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m2.00746\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 390 | loss: 2.00746 - acc: 0.3619 | val_loss: 1.67321 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: N24QS2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m1.99040\u001b[0m\u001b[0m | time: 1.274s\n",
      "| Adam | epoch: 391 | loss: 1.99040 - acc: 0.3788 | val_loss: 1.67126 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m1.96959\u001b[0m\u001b[0m | time: 1.073s\n",
      "| Adam | epoch: 392 | loss: 1.96959 - acc: 0.3909 | val_loss: 1.66948 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m1.99152\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 393 | loss: 1.99152 - acc: 0.3737 | val_loss: 1.66759 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m1.97587\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 394 | loss: 1.97587 - acc: 0.3864 | val_loss: 1.66556 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m1.95748\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 395 | loss: 1.95748 - acc: 0.3962 | val_loss: 1.66382 - val_acc: 0.5625 -- iter: 64/64\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m1.99726\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 396 | loss: 1.99726 - acc: 0.3722 | val_loss: 1.66192 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m1.97678\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 397 | loss: 1.97678 - acc: 0.3896 | val_loss: 1.66027 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m2.00430\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 398 | loss: 2.00430 - acc: 0.3725 | val_loss: 1.65841 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m1.98294\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 399 | loss: 1.98294 - acc: 0.3947 | val_loss: 1.65671 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m2.01045\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 400 | loss: 2.01045 - acc: 0.3661 | val_loss: 1.65486 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: P3SEXA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m1.99056\u001b[0m\u001b[0m | time: 1.198s\n",
      "| Adam | epoch: 401 | loss: 1.99056 - acc: 0.3827 | val_loss: 1.65288 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m1.97108\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 402 | loss: 1.97108 - acc: 0.3944 | val_loss: 1.65116 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m2.00032\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 403 | loss: 2.00032 - acc: 0.3721 | val_loss: 1.64966 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m2.02717\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 404 | loss: 2.02717 - acc: 0.3505 | val_loss: 1.64799 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m2.00479\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 405 | loss: 2.00479 - acc: 0.3733 | val_loss: 1.64617 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m1.98191\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 406 | loss: 1.98191 - acc: 0.3953 | val_loss: 1.64463 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m2.01268\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 407 | loss: 2.01268 - acc: 0.3730 | val_loss: 1.64336 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m2.04333\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 408 | loss: 2.04333 - acc: 0.3529 | val_loss: 1.64187 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m2.01712\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 409 | loss: 2.01712 - acc: 0.3660 | val_loss: 1.64057 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m2.04315\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 410 | loss: 2.04315 - acc: 0.3466 | val_loss: 1.63907 - val_acc: 0.5781 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 7O10NR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m2.01782\u001b[0m\u001b[0m | time: 1.193s\n",
      "| Adam | epoch: 411 | loss: 2.01782 - acc: 0.3588 | val_loss: 1.63755 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m2.02542\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 412 | loss: 2.02542 - acc: 0.3526 | val_loss: 1.63584 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m1.99811\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 413 | loss: 1.99811 - acc: 0.3721 | val_loss: 1.63445 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m2.04088\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 414 | loss: 2.04088 - acc: 0.3411 | val_loss: 1.63289 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m2.01762\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 415 | loss: 2.01762 - acc: 0.3586 | val_loss: 1.63121 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m1.99479\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 416 | loss: 1.99479 - acc: 0.3727 | val_loss: 1.62932 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m1.97160\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 417 | loss: 1.97160 - acc: 0.3886 | val_loss: 1.62769 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m2.00131\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 418 | loss: 2.00131 - acc: 0.3685 | val_loss: 1.62594 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m1.97920\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 419 | loss: 1.97920 - acc: 0.3910 | val_loss: 1.62423 - val_acc: 0.5938 -- iter: 64/64\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m1.98587\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 420 | loss: 1.98587 - acc: 0.3878 | val_loss: 1.62240 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: S1HRQR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m1.96628\u001b[0m\u001b[0m | time: 1.205s\n",
      "| Adam | epoch: 421 | loss: 1.96628 - acc: 0.3959 | val_loss: 1.62042 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m1.94715\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 422 | loss: 1.94715 - acc: 0.4110 | val_loss: 1.61833 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m1.93007\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 423 | loss: 1.93007 - acc: 0.4246 | val_loss: 1.61617 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m1.91326\u001b[0m\u001b[0m | time: 1.071s\n",
      "| Adam | epoch: 424 | loss: 1.91326 - acc: 0.4337 | val_loss: 1.61388 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m1.90162\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 425 | loss: 1.90162 - acc: 0.4403 | val_loss: 1.61156 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m1.89200\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 426 | loss: 1.89200 - acc: 0.4432 | val_loss: 1.60958 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m1.94186\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 427 | loss: 1.94186 - acc: 0.4129 | val_loss: 1.60791 - val_acc: 0.6094 -- iter: 64/64\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m1.98580\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 428 | loss: 1.98580 - acc: 0.3779 | val_loss: 1.60609 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m1.96133\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 429 | loss: 1.96133 - acc: 0.3963 | val_loss: 1.60432 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m1.96750\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 430 | loss: 1.96750 - acc: 0.3880 | val_loss: 1.60241 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 04XHKS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m1.94264\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 431 | loss: 1.94264 - acc: 0.4038 | val_loss: 1.60092 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m1.99669\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 432 | loss: 1.99669 - acc: 0.3728 | val_loss: 1.59928 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m1.97133\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 433 | loss: 1.97133 - acc: 0.3949 | val_loss: 1.59754 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m1.94887\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 434 | loss: 1.94887 - acc: 0.4086 | val_loss: 1.59565 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m1.93024\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 435 | loss: 1.93024 - acc: 0.4177 | val_loss: 1.59398 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m1.94909\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 436 | loss: 1.94909 - acc: 0.4025 | val_loss: 1.59216 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m1.92913\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 437 | loss: 1.92913 - acc: 0.4216 | val_loss: 1.59024 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m1.90939\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 438 | loss: 1.90939 - acc: 0.4388 | val_loss: 1.58837 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m1.92349\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 439 | loss: 1.92349 - acc: 0.4293 | val_loss: 1.58665 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m1.94053\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 440 | loss: 1.94053 - acc: 0.4145 | val_loss: 1.58476 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 1Y7572\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m1.92261\u001b[0m\u001b[0m | time: 1.195s\n",
      "| Adam | epoch: 441 | loss: 1.92261 - acc: 0.4199 | val_loss: 1.58293 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m1.93259\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 442 | loss: 1.93259 - acc: 0.4154 | val_loss: 1.58093 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m1.90950\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 443 | loss: 1.90950 - acc: 0.4302 | val_loss: 1.57885 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m1.89301\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 444 | loss: 1.89301 - acc: 0.4418 | val_loss: 1.57664 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m1.87633\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 445 | loss: 1.87633 - acc: 0.4523 | val_loss: 1.57461 - val_acc: 0.6250 -- iter: 64/64\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m1.90417\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 446 | loss: 1.90417 - acc: 0.4321 | val_loss: 1.57247 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m1.88727\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 447 | loss: 1.88727 - acc: 0.4436 | val_loss: 1.57068 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m1.93166\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 448 | loss: 1.93166 - acc: 0.4102 | val_loss: 1.56885 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m1.91386\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 449 | loss: 1.91386 - acc: 0.4238 | val_loss: 1.56688 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m1.89364\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 450 | loss: 1.89364 - acc: 0.4393 | val_loss: 1.56479 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: UECJR7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m1.87572\u001b[0m\u001b[0m | time: 1.190s\n",
      "| Adam | epoch: 451 | loss: 1.87572 - acc: 0.4563 | val_loss: 1.56256 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m1.86068\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 452 | loss: 1.86068 - acc: 0.4700 | val_loss: 1.56023 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m1.84464\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 453 | loss: 1.84464 - acc: 0.4808 | val_loss: 1.55782 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m1.83165\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 454 | loss: 1.83165 - acc: 0.4874 | val_loss: 1.55536 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m1.82001\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 455 | loss: 1.82001 - acc: 0.4965 | val_loss: 1.55287 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m1.80723\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 456 | loss: 1.80723 - acc: 0.5078 | val_loss: 1.55033 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m1.79815\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 457 | loss: 1.79815 - acc: 0.5133 | val_loss: 1.54815 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m1.85969\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 458 | loss: 1.85969 - acc: 0.4760 | val_loss: 1.54582 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m1.84372\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 459 | loss: 1.84372 - acc: 0.4815 | val_loss: 1.54377 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m1.89402\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 460 | loss: 1.89402 - acc: 0.4459 | val_loss: 1.54151 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: RECC1A\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m1.87653\u001b[0m\u001b[0m | time: 1.202s\n",
      "| Adam | epoch: 461 | loss: 1.87653 - acc: 0.4560 | val_loss: 1.53919 - val_acc: 0.6406 -- iter: 64/64\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m1.88898\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 462 | loss: 1.88898 - acc: 0.4401 | val_loss: 1.53680 - val_acc: 0.6562 -- iter: 64/64\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m1.86755\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 463 | loss: 1.86755 - acc: 0.4601 | val_loss: 1.53431 - val_acc: 0.6562 -- iter: 64/64\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m1.84925\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 464 | loss: 1.84925 - acc: 0.4688 | val_loss: 1.53166 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m1.83298\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 465 | loss: 1.83298 - acc: 0.4797 | val_loss: 1.52947 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m1.89580\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 466 | loss: 1.89580 - acc: 0.4380 | val_loss: 1.52716 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m1.87351\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 467 | loss: 1.87351 - acc: 0.4536 | val_loss: 1.52511 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m1.92918\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 468 | loss: 1.92918 - acc: 0.4207 | val_loss: 1.52295 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m1.90336\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 469 | loss: 1.90336 - acc: 0.4411 | val_loss: 1.52081 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m1.91197\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 470 | loss: 1.91197 - acc: 0.4314 | val_loss: 1.51854 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: IJ1226\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m1.88466\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 471 | loss: 1.88466 - acc: 0.4508 | val_loss: 1.51616 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m1.86550\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 472 | loss: 1.86550 - acc: 0.4604 | val_loss: 1.51395 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m1.89667\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 473 | loss: 1.89667 - acc: 0.4409 | val_loss: 1.51167 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m1.87449\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 474 | loss: 1.87449 - acc: 0.4609 | val_loss: 1.50921 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m1.85382\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 475 | loss: 1.85382 - acc: 0.4710 | val_loss: 1.50705 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m1.90825\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 476 | loss: 1.90825 - acc: 0.4364 | val_loss: 1.50477 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m1.88807\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 477 | loss: 1.88807 - acc: 0.4397 | val_loss: 1.50269 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m1.90354\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 478 | loss: 1.90354 - acc: 0.4316 | val_loss: 1.50055 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m1.88121\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 479 | loss: 1.88121 - acc: 0.4463 | val_loss: 1.49866 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m1.91765\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 480 | loss: 1.91765 - acc: 0.4251 | val_loss: 1.49665 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 1SX53W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m1.89162\u001b[0m\u001b[0m | time: 1.224s\n",
      "| Adam | epoch: 481 | loss: 1.89162 - acc: 0.4435 | val_loss: 1.49479 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m1.89212\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 482 | loss: 1.89212 - acc: 0.4460 | val_loss: 1.49279 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m1.86808\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 483 | loss: 1.86808 - acc: 0.4546 | val_loss: 1.49099 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m1.88656\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 484 | loss: 1.88656 - acc: 0.4357 | val_loss: 1.48908 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m1.86139\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 485 | loss: 1.86139 - acc: 0.4484 | val_loss: 1.48751 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m1.92389\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 486 | loss: 1.92389 - acc: 0.4051 | val_loss: 1.48583 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m1.89515\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 487 | loss: 1.89515 - acc: 0.4208 | val_loss: 1.48443 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m1.94528\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 488 | loss: 1.94528 - acc: 0.3897 | val_loss: 1.48287 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m1.91503\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 489 | loss: 1.91503 - acc: 0.4116 | val_loss: 1.48133 - val_acc: 0.6719 -- iter: 64/64\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m1.91657\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 490 | loss: 1.91657 - acc: 0.4033 | val_loss: 1.47957 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: AOY1YV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m1.89112\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 491 | loss: 1.89112 - acc: 0.4223 | val_loss: 1.47759 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m1.86357\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 492 | loss: 1.86357 - acc: 0.4379 | val_loss: 1.47559 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m1.84247\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 493 | loss: 1.84247 - acc: 0.4566 | val_loss: 1.47391 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m1.90726\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 494 | loss: 1.90726 - acc: 0.4125 | val_loss: 1.47210 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m1.87852\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 495 | loss: 1.87852 - acc: 0.4338 | val_loss: 1.47065 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m1.92867\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 496 | loss: 1.92867 - acc: 0.4076 | val_loss: 1.46901 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m1.90253\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 497 | loss: 1.90253 - acc: 0.4262 | val_loss: 1.46769 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m1.94629\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 498 | loss: 1.94629 - acc: 0.3992 | val_loss: 1.46622 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m1.91415\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 499 | loss: 1.91415 - acc: 0.4187 | val_loss: 1.46505 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m1.95848\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 500 | loss: 1.95848 - acc: 0.3924 | val_loss: 1.46358 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: C9SA94\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m1.92604\u001b[0m\u001b[0m | time: 1.207s\n",
      "| Adam | epoch: 501 | loss: 1.92604 - acc: 0.4172 | val_loss: 1.46223 - val_acc: 0.6875 -- iter: 64/64\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m1.96956\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 502 | loss: 1.96956 - acc: 0.3974 | val_loss: 1.46073 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m1.93806\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 503 | loss: 1.93806 - acc: 0.4233 | val_loss: 1.45936 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m1.94404\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 504 | loss: 1.94404 - acc: 0.4184 | val_loss: 1.45781 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m1.91260\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 505 | loss: 1.91260 - acc: 0.4391 | val_loss: 1.45596 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m1.88404\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 506 | loss: 1.88404 - acc: 0.4514 | val_loss: 1.45444 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m1.94840\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 507 | loss: 1.94840 - acc: 0.4110 | val_loss: 1.45311 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m1.97246\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 508 | loss: 1.97246 - acc: 0.3855 | val_loss: 1.45164 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m1.94192\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 509 | loss: 1.94192 - acc: 0.4048 | val_loss: 1.45027 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m1.97696\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 510 | loss: 1.97696 - acc: 0.3799 | val_loss: 1.44873 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: Z31G6O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m1.93817\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 511 | loss: 1.93817 - acc: 0.4076 | val_loss: 1.44706 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m1.91333\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 512 | loss: 1.91333 - acc: 0.4262 | val_loss: 1.44515 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m1.88284\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 513 | loss: 1.88284 - acc: 0.4476 | val_loss: 1.44365 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m1.93600\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 514 | loss: 1.93600 - acc: 0.4154 | val_loss: 1.44192 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m1.90480\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 515 | loss: 1.90480 - acc: 0.4410 | val_loss: 1.43998 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m1.87696\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 516 | loss: 1.87696 - acc: 0.4547 | val_loss: 1.43837 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m1.92990\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 517 | loss: 1.92990 - acc: 0.4186 | val_loss: 1.43706 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m1.97222\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 518 | loss: 1.97222 - acc: 0.3861 | val_loss: 1.43551 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m1.93703\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 519 | loss: 1.93703 - acc: 0.4163 | val_loss: 1.43397 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m1.93515\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 520 | loss: 1.93515 - acc: 0.4153 | val_loss: 1.43222 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: KTFEEH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m1.90180\u001b[0m\u001b[0m | time: 1.200s\n",
      "| Adam | epoch: 521 | loss: 1.90180 - acc: 0.4362 | val_loss: 1.43084 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m1.96696\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 522 | loss: 1.96696 - acc: 0.3989 | val_loss: 1.42925 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m1.93150\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 523 | loss: 1.93150 - acc: 0.4246 | val_loss: 1.42771 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m1.94120\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 524 | loss: 1.94120 - acc: 0.4196 | val_loss: 1.42589 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m1.90814\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 525 | loss: 1.90814 - acc: 0.4402 | val_loss: 1.42390 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m1.87748\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 526 | loss: 1.87748 - acc: 0.4602 | val_loss: 1.42180 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m1.84948\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 527 | loss: 1.84948 - acc: 0.4798 | val_loss: 1.42007 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m1.89539\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 528 | loss: 1.89539 - acc: 0.4443 | val_loss: 1.41811 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m1.86868\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 529 | loss: 1.86868 - acc: 0.4577 | val_loss: 1.41652 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m1.92061\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 530 | loss: 1.92061 - acc: 0.4213 | val_loss: 1.41471 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: SVO4F1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m1.88696\u001b[0m\u001b[0m | time: 1.199s\n",
      "| Adam | epoch: 531 | loss: 1.88696 - acc: 0.4464 | val_loss: 1.41275 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m1.86144\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 532 | loss: 1.86144 - acc: 0.4596 | val_loss: 1.41131 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m1.91660\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 533 | loss: 1.91660 - acc: 0.4214 | val_loss: 1.40988 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m1.92857\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 534 | loss: 1.92857 - acc: 0.4183 | val_loss: 1.40816 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m1.89429\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 535 | loss: 1.89429 - acc: 0.4374 | val_loss: 1.40626 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m1.86293\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 536 | loss: 1.86293 - acc: 0.4531 | val_loss: 1.40468 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m1.92110\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 537 | loss: 1.92110 - acc: 0.4124 | val_loss: 1.40322 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m1.94640\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 538 | loss: 1.94640 - acc: 0.3931 | val_loss: 1.40157 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m1.91116\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 539 | loss: 1.91116 - acc: 0.4147 | val_loss: 1.40001 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m1.92842\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 540 | loss: 1.92842 - acc: 0.4045 | val_loss: 1.39839 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: I7R30W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m1.89447\u001b[0m\u001b[0m | time: 1.202s\n",
      "| Adam | epoch: 541 | loss: 1.89447 - acc: 0.4297 | val_loss: 1.39687 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m1.89731\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 542 | loss: 1.89731 - acc: 0.4320 | val_loss: 1.39507 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m1.86636\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 543 | loss: 1.86636 - acc: 0.4513 | val_loss: 1.39332 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m1.88087\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 544 | loss: 1.88087 - acc: 0.4452 | val_loss: 1.39139 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m1.85176\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 545 | loss: 1.85176 - acc: 0.4679 | val_loss: 1.38969 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m1.87285\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 546 | loss: 1.87285 - acc: 0.4508 | val_loss: 1.38784 - val_acc: 0.7031 -- iter: 64/64\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m1.84112\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 547 | loss: 1.84112 - acc: 0.4729 | val_loss: 1.38620 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m1.87597\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 548 | loss: 1.87597 - acc: 0.4522 | val_loss: 1.38429 - val_acc: 0.7188 -- iter: 64/64\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m1.84677\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 549 | loss: 1.84677 - acc: 0.4695 | val_loss: 1.38278 - val_acc: 0.7344 -- iter: 64/64\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m1.90787\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 550 | loss: 1.90787 - acc: 0.4303 | val_loss: 1.38102 - val_acc: 0.7344 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 6XUIKS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m1.87559\u001b[0m\u001b[0m | time: 1.194s\n",
      "| Adam | epoch: 551 | loss: 1.87559 - acc: 0.4545 | val_loss: 1.37955 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m1.92347\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 552 | loss: 1.92347 - acc: 0.4200 | val_loss: 1.37794 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m1.88816\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 553 | loss: 1.88816 - acc: 0.4405 | val_loss: 1.37654 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m1.92981\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 554 | loss: 1.92981 - acc: 0.4136 | val_loss: 1.37492 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m1.89324\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 555 | loss: 1.89324 - acc: 0.4363 | val_loss: 1.37350 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m1.94706\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 556 | loss: 1.94706 - acc: 0.4021 | val_loss: 1.37191 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m1.91095\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 557 | loss: 1.91095 - acc: 0.4228 | val_loss: 1.37050 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m1.93056\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 558 | loss: 1.93056 - acc: 0.4071 | val_loss: 1.36897 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m1.89332\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 559 | loss: 1.89332 - acc: 0.4257 | val_loss: 1.36750 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m1.90239\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 560 | loss: 1.90239 - acc: 0.4238 | val_loss: 1.36592 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: YYGJGQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m1.86541\u001b[0m\u001b[0m | time: 1.204s\n",
      "| Adam | epoch: 561 | loss: 1.86541 - acc: 0.4564 | val_loss: 1.36460 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m1.90957\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 562 | loss: 1.90957 - acc: 0.4233 | val_loss: 1.36307 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m1.87515\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 563 | loss: 1.87515 - acc: 0.4403 | val_loss: 1.36127 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m1.83850\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 564 | loss: 1.83850 - acc: 0.4650 | val_loss: 1.35934 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m1.81148\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 565 | loss: 1.81148 - acc: 0.4873 | val_loss: 1.35743 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m1.82748\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 566 | loss: 1.82748 - acc: 0.4745 | val_loss: 1.35533 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m1.80251\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 567 | loss: 1.80251 - acc: 0.4880 | val_loss: 1.35363 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m1.85721\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 568 | loss: 1.85721 - acc: 0.4564 | val_loss: 1.35182 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m1.82864\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 569 | loss: 1.82864 - acc: 0.4764 | val_loss: 1.35013 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m1.85214\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 570 | loss: 1.85214 - acc: 0.4631 | val_loss: 1.34827 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: GHA1OG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m1.82130\u001b[0m\u001b[0m | time: 1.198s\n",
      "| Adam | epoch: 571 | loss: 1.82130 - acc: 0.4762 | val_loss: 1.34632 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m1.79208\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 572 | loss: 1.79208 - acc: 0.5020 | val_loss: 1.34466 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m1.85502\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 573 | loss: 1.85502 - acc: 0.4612 | val_loss: 1.34325 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m1.85833\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 574 | loss: 1.85833 - acc: 0.4572 | val_loss: 1.34164 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m1.82340\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 575 | loss: 1.82340 - acc: 0.4756 | val_loss: 1.34033 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m1.88033\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 576 | loss: 1.88033 - acc: 0.4436 | val_loss: 1.33879 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m1.84491\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 577 | loss: 1.84491 - acc: 0.4696 | val_loss: 1.33733 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m1.90360\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 578 | loss: 1.90360 - acc: 0.4367 | val_loss: 1.33563 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m1.86685\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 579 | loss: 1.86685 - acc: 0.4586 | val_loss: 1.33435 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m1.92183\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 580 | loss: 1.92183 - acc: 0.4206 | val_loss: 1.33271 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: N6A5L6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m1.88250\u001b[0m\u001b[0m | time: 1.198s\n",
      "| Adam | epoch: 581 | loss: 1.88250 - acc: 0.4473 | val_loss: 1.33118 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m1.92441\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 582 | loss: 1.92441 - acc: 0.4197 | val_loss: 1.32944 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m1.88802\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 583 | loss: 1.88802 - acc: 0.4387 | val_loss: 1.32793 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m1.94838\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 584 | loss: 1.94838 - acc: 0.4042 | val_loss: 1.32613 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m1.90771\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 585 | loss: 1.90771 - acc: 0.4279 | val_loss: 1.32425 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m1.87144\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 586 | loss: 1.87144 - acc: 0.4476 | val_loss: 1.32265 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m1.92192\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 587 | loss: 1.92192 - acc: 0.4169 | val_loss: 1.32143 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m1.94508\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 588 | loss: 1.94508 - acc: 0.4033 | val_loss: 1.32005 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m1.90374\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 589 | loss: 1.90374 - acc: 0.4302 | val_loss: 1.31898 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m1.93118\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 590 | loss: 1.93118 - acc: 0.4153 | val_loss: 1.31765 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 01TTUX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m1.89159\u001b[0m\u001b[0m | time: 1.197s\n",
      "| Adam | epoch: 591 | loss: 1.89159 - acc: 0.4378 | val_loss: 1.31604 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m1.85677\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 592 | loss: 1.85677 - acc: 0.4550 | val_loss: 1.31456 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m1.86688\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 593 | loss: 1.86688 - acc: 0.4470 | val_loss: 1.31325 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m1.92395\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 594 | loss: 1.92395 - acc: 0.4195 | val_loss: 1.31181 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m1.88573\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 595 | loss: 1.88573 - acc: 0.4447 | val_loss: 1.31049 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m1.90537\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 596 | loss: 1.90537 - acc: 0.4284 | val_loss: 1.30886 - val_acc: 0.7344 -- iter: 64/64\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m1.86523\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 597 | loss: 1.86523 - acc: 0.4449 | val_loss: 1.30729 - val_acc: 0.7344 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m1.90319\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 598 | loss: 1.90319 - acc: 0.4270 | val_loss: 1.30552 - val_acc: 0.7344 -- iter: 64/64\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m1.86130\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 599 | loss: 1.86130 - acc: 0.4546 | val_loss: 1.30411 - val_acc: 0.7344 -- iter: 64/64\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m1.90251\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 600 | loss: 1.90251 - acc: 0.4279 | val_loss: 1.30236 - val_acc: 0.7344 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: TEIQ5G\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m1.86502\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 601 | loss: 1.86502 - acc: 0.4507 | val_loss: 1.30071 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m1.91348\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 602 | loss: 1.91348 - acc: 0.4166 | val_loss: 1.29880 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m1.87065\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 603 | loss: 1.87065 - acc: 0.4421 | val_loss: 1.29703 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m1.89084\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 604 | loss: 1.89084 - acc: 0.4338 | val_loss: 1.29521 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m1.85543\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 605 | loss: 1.85543 - acc: 0.4514 | val_loss: 1.29390 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m1.90621\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 606 | loss: 1.90621 - acc: 0.4266 | val_loss: 1.29240 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m1.86785\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 607 | loss: 1.86785 - acc: 0.4480 | val_loss: 1.29100 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m1.92767\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 608 | loss: 1.92767 - acc: 0.4141 | val_loss: 1.28928 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m1.88770\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 609 | loss: 1.88770 - acc: 0.4383 | val_loss: 1.28791 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m1.94814\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 610 | loss: 1.94814 - acc: 0.4007 | val_loss: 1.28637 - val_acc: 0.7500 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: Q3PHWX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m1.90497\u001b[0m\u001b[0m | time: 1.200s\n",
      "| Adam | epoch: 611 | loss: 1.90497 - acc: 0.4200 | val_loss: 1.28505 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m1.95351\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 612 | loss: 1.95351 - acc: 0.3890 | val_loss: 1.28350 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m1.90549\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 613 | loss: 1.90549 - acc: 0.4204 | val_loss: 1.28222 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m1.95292\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 614 | loss: 1.95292 - acc: 0.3893 | val_loss: 1.28075 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m1.90746\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 615 | loss: 1.90746 - acc: 0.4175 | val_loss: 1.27915 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m1.90651\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 616 | loss: 1.90651 - acc: 0.4164 | val_loss: 1.27739 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m1.86884\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 617 | loss: 1.86884 - acc: 0.4373 | val_loss: 1.27593 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m1.92313\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 618 | loss: 1.92313 - acc: 0.4092 | val_loss: 1.27430 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m1.88165\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 619 | loss: 1.88165 - acc: 0.4339 | val_loss: 1.27299 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m1.93489\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 620 | loss: 1.93489 - acc: 0.4014 | val_loss: 1.27145 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: LI5NIN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m1.89058\u001b[0m\u001b[0m | time: 1.219s\n",
      "| Adam | epoch: 621 | loss: 1.89058 - acc: 0.4254 | val_loss: 1.27013 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m1.93489\u001b[0m\u001b[0m | time: 1.078s\n",
      "| Adam | epoch: 622 | loss: 1.93489 - acc: 0.3969 | val_loss: 1.26848 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m1.88922\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 623 | loss: 1.88922 - acc: 0.4275 | val_loss: 1.26698 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m1.90081\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 624 | loss: 1.90081 - acc: 0.4191 | val_loss: 1.26534 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m1.85616\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 625 | loss: 1.85616 - acc: 0.4460 | val_loss: 1.26356 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m1.81769\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 626 | loss: 1.81769 - acc: 0.4686 | val_loss: 1.26171 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m1.78174\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 627 | loss: 1.78174 - acc: 0.4904 | val_loss: 1.25974 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m1.75412\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 628 | loss: 1.75412 - acc: 0.5086 | val_loss: 1.25761 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m1.72861\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 629 | loss: 1.72861 - acc: 0.5312 | val_loss: 1.25603 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m1.80125\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 630 | loss: 1.80125 - acc: 0.4859 | val_loss: 1.25433 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: F2747K\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m1.77263\u001b[0m\u001b[0m | time: 1.237s\n",
      "| Adam | epoch: 631 | loss: 1.77263 - acc: 0.5045 | val_loss: 1.25304 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m1.83801\u001b[0m\u001b[0m | time: 1.081s\n",
      "| Adam | epoch: 632 | loss: 1.83801 - acc: 0.4665 | val_loss: 1.25167 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m1.80358\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 633 | loss: 1.80358 - acc: 0.4839 | val_loss: 1.25055 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m1.86272\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 634 | loss: 1.86272 - acc: 0.4449 | val_loss: 1.24924 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m1.82360\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 635 | loss: 1.82360 - acc: 0.4660 | val_loss: 1.24816 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m1.88632\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 636 | loss: 1.88632 - acc: 0.4319 | val_loss: 1.24694 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m1.84863\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 637 | loss: 1.84863 - acc: 0.4559 | val_loss: 1.24600 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m1.91477\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 638 | loss: 1.91477 - acc: 0.4150 | val_loss: 1.24482 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m1.87300\u001b[0m\u001b[0m | time: 1.066s\n",
      "| Adam | epoch: 639 | loss: 1.87300 - acc: 0.4470 | val_loss: 1.24380 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m1.92207\u001b[0m\u001b[0m | time: 1.124s\n",
      "| Adam | epoch: 640 | loss: 1.92207 - acc: 0.4116 | val_loss: 1.24254 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: VML171\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m1.87668\u001b[0m\u001b[0m | time: 1.275s\n",
      "| Adam | epoch: 641 | loss: 1.87668 - acc: 0.4392 | val_loss: 1.24154 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m1.93326\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 642 | loss: 1.93326 - acc: 0.4047 | val_loss: 1.24034 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m1.89155\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 643 | loss: 1.89155 - acc: 0.4345 | val_loss: 1.23934 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m1.94114\u001b[0m\u001b[0m | time: 1.066s\n",
      "| Adam | epoch: 644 | loss: 1.94114 - acc: 0.4051 | val_loss: 1.23815 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m1.89522\u001b[0m\u001b[0m | time: 1.086s\n",
      "| Adam | epoch: 645 | loss: 1.89522 - acc: 0.4287 | val_loss: 1.23672 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m1.85125\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 646 | loss: 1.85125 - acc: 0.4530 | val_loss: 1.23508 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m1.81408\u001b[0m\u001b[0m | time: 1.087s\n",
      "| Adam | epoch: 647 | loss: 1.81408 - acc: 0.4765 | val_loss: 1.23309 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m1.78283\u001b[0m\u001b[0m | time: 1.159s\n",
      "| Adam | epoch: 648 | loss: 1.78283 - acc: 0.4976 | val_loss: 1.23094 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m1.75164\u001b[0m\u001b[0m | time: 1.107s\n",
      "| Adam | epoch: 649 | loss: 1.75164 - acc: 0.5150 | val_loss: 1.22883 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m1.75738\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 650 | loss: 1.75738 - acc: 0.5057 | val_loss: 1.22653 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: S61KBO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m1.73118\u001b[0m\u001b[0m | time: 1.223s\n",
      "| Adam | epoch: 651 | loss: 1.73118 - acc: 0.5207 | val_loss: 1.22426 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m1.70473\u001b[0m\u001b[0m | time: 1.063s\n",
      "| Adam | epoch: 652 | loss: 1.70473 - acc: 0.5312 | val_loss: 1.22246 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m1.78629\u001b[0m\u001b[0m | time: 1.082s\n",
      "| Adam | epoch: 653 | loss: 1.78629 - acc: 0.4874 | val_loss: 1.22078 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m1.79699\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 654 | loss: 1.79699 - acc: 0.4840 | val_loss: 1.21901 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m1.76255\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 655 | loss: 1.76255 - acc: 0.5043 | val_loss: 1.21723 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m1.73141\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 656 | loss: 1.73141 - acc: 0.5273 | val_loss: 1.21538 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m1.70058\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 657 | loss: 1.70058 - acc: 0.5418 | val_loss: 1.21413 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m1.77598\u001b[0m\u001b[0m | time: 1.073s\n",
      "| Adam | epoch: 658 | loss: 1.77598 - acc: 0.4970 | val_loss: 1.21271 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m1.74181\u001b[0m\u001b[0m | time: 1.080s\n",
      "| Adam | epoch: 659 | loss: 1.74181 - acc: 0.5145 | val_loss: 1.21149 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m1.80606\u001b[0m\u001b[0m | time: 1.107s\n",
      "| Adam | epoch: 660 | loss: 1.80606 - acc: 0.4771 | val_loss: 1.21005 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 7XKQH3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m1.76690\u001b[0m\u001b[0m | time: 1.327s\n",
      "| Adam | epoch: 661 | loss: 1.76690 - acc: 0.4997 | val_loss: 1.20884 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m1.84623\u001b[0m\u001b[0m | time: 1.083s\n",
      "| Adam | epoch: 662 | loss: 1.84623 - acc: 0.4575 | val_loss: 1.20754 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m1.80763\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 663 | loss: 1.80763 - acc: 0.4852 | val_loss: 1.20671 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m1.87284\u001b[0m\u001b[0m | time: 1.138s\n",
      "| Adam | epoch: 664 | loss: 1.87284 - acc: 0.4476 | val_loss: 1.20567 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m1.83126\u001b[0m\u001b[0m | time: 1.071s\n",
      "| Adam | epoch: 665 | loss: 1.83126 - acc: 0.4685 | val_loss: 1.20492 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m1.88770\u001b[0m\u001b[0m | time: 1.078s\n",
      "| Adam | epoch: 666 | loss: 1.88770 - acc: 0.4388 | val_loss: 1.20391 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m1.84027\u001b[0m\u001b[0m | time: 1.065s\n",
      "| Adam | epoch: 667 | loss: 1.84027 - acc: 0.4700 | val_loss: 1.20300 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m1.89634\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 668 | loss: 1.89634 - acc: 0.4401 | val_loss: 1.20184 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m1.84720\u001b[0m\u001b[0m | time: 1.072s\n",
      "| Adam | epoch: 669 | loss: 1.84720 - acc: 0.4633 | val_loss: 1.20080 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m1.84398\u001b[0m\u001b[0m | time: 1.076s\n",
      "| Adam | epoch: 670 | loss: 1.84398 - acc: 0.4607 | val_loss: 1.19958 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 35I836\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m1.80427\u001b[0m\u001b[0m | time: 1.277s\n",
      "| Adam | epoch: 671 | loss: 1.80427 - acc: 0.4850 | val_loss: 1.19851 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m1.86897\u001b[0m\u001b[0m | time: 1.068s\n",
      "| Adam | epoch: 672 | loss: 1.86897 - acc: 0.4474 | val_loss: 1.19722 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m1.82521\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 673 | loss: 1.82521 - acc: 0.4730 | val_loss: 1.19572 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m1.78443\u001b[0m\u001b[0m | time: 1.071s\n",
      "| Adam | epoch: 674 | loss: 1.78443 - acc: 0.4929 | val_loss: 1.19405 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m1.74868\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 675 | loss: 1.74868 - acc: 0.5139 | val_loss: 1.19276 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m1.80883\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 676 | loss: 1.80883 - acc: 0.4750 | val_loss: 1.19122 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m1.76966\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 677 | loss: 1.76966 - acc: 0.4947 | val_loss: 1.18969 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m1.77471\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 678 | loss: 1.77471 - acc: 0.4859 | val_loss: 1.18813 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m1.73471\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 679 | loss: 1.73471 - acc: 0.5060 | val_loss: 1.18677 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m1.75130\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 680 | loss: 1.75130 - acc: 0.4960 | val_loss: 1.18537 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: QFJZ90\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m1.71766\u001b[0m\u001b[0m | time: 1.207s\n",
      "| Adam | epoch: 681 | loss: 1.71766 - acc: 0.5183 | val_loss: 1.18418 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m1.79284\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 682 | loss: 1.79284 - acc: 0.4790 | val_loss: 1.18283 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m1.75664\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 683 | loss: 1.75664 - acc: 0.5061 | val_loss: 1.18152 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m1.78428\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 684 | loss: 1.78428 - acc: 0.4914 | val_loss: 1.18008 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m1.74537\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 685 | loss: 1.74537 - acc: 0.5157 | val_loss: 1.17884 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m1.82853\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 686 | loss: 1.82853 - acc: 0.4719 | val_loss: 1.17760 - val_acc: 0.7656 -- iter: 64/64\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m1.78758\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 687 | loss: 1.78758 - acc: 0.4919 | val_loss: 1.17653 - val_acc: 0.7812 -- iter: 64/64\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m1.86525\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 688 | loss: 1.86525 - acc: 0.4490 | val_loss: 1.17511 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m1.81932\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 689 | loss: 1.81932 - acc: 0.4728 | val_loss: 1.17384 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m1.86775\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 690 | loss: 1.86775 - acc: 0.4412 | val_loss: 1.17245 - val_acc: 0.7969 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: AW3AGQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m1.82356\u001b[0m\u001b[0m | time: 1.218s\n",
      "| Adam | epoch: 691 | loss: 1.82356 - acc: 0.4658 | val_loss: 1.17148 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m1.90100\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 692 | loss: 1.90100 - acc: 0.4239 | val_loss: 1.17023 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m1.84845\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 693 | loss: 1.84845 - acc: 0.4503 | val_loss: 1.16887 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m1.87851\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 694 | loss: 1.87851 - acc: 0.4365 | val_loss: 1.16745 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m1.83131\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 695 | loss: 1.83131 - acc: 0.4600 | val_loss: 1.16602 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m1.84530\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 696 | loss: 1.84530 - acc: 0.4578 | val_loss: 1.16446 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m1.80035\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 697 | loss: 1.80035 - acc: 0.4823 | val_loss: 1.16267 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m1.75880\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 698 | loss: 1.75880 - acc: 0.5044 | val_loss: 1.16066 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m1.72235\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 699 | loss: 1.72235 - acc: 0.5243 | val_loss: 1.15883 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m1.79402\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 700 | loss: 1.79402 - acc: 0.4859 | val_loss: 1.15693 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: XI3WA9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m1.75464\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 701 | loss: 1.75464 - acc: 0.5123 | val_loss: 1.15522 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m1.82474\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 702 | loss: 1.82474 - acc: 0.4736 | val_loss: 1.15335 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m1.78448\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 703 | loss: 1.78448 - acc: 0.4934 | val_loss: 1.15187 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m1.86608\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 704 | loss: 1.86608 - acc: 0.4503 | val_loss: 1.15033 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m1.81996\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 705 | loss: 1.81996 - acc: 0.4772 | val_loss: 1.14896 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m1.88130\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 706 | loss: 1.88130 - acc: 0.4482 | val_loss: 1.14741 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m1.83292\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 707 | loss: 1.83292 - acc: 0.4721 | val_loss: 1.14632 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m1.88660\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 708 | loss: 1.88660 - acc: 0.4390 | val_loss: 1.14487 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m1.83216\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 709 | loss: 1.83216 - acc: 0.4716 | val_loss: 1.14335 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m1.82724\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 710 | loss: 1.82724 - acc: 0.4698 | val_loss: 1.14172 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: C2VMWC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m1.77923\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 711 | loss: 1.77923 - acc: 0.4947 | val_loss: 1.14046 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m1.85721\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 712 | loss: 1.85721 - acc: 0.4546 | val_loss: 1.13896 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m1.80884\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 713 | loss: 1.80884 - acc: 0.4810 | val_loss: 1.13753 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m1.87662\u001b[0m\u001b[0m | time: 1.066s\n",
      "| Adam | epoch: 714 | loss: 1.87662 - acc: 0.4470 | val_loss: 1.13612 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m1.82737\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 715 | loss: 1.82737 - acc: 0.4773 | val_loss: 1.13497 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m1.88742\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 716 | loss: 1.88742 - acc: 0.4389 | val_loss: 1.13353 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m1.83784\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 717 | loss: 1.83784 - acc: 0.4716 | val_loss: 1.13271 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m1.90233\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 718 | loss: 1.90233 - acc: 0.4385 | val_loss: 1.13160 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m1.84528\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 719 | loss: 1.84528 - acc: 0.4712 | val_loss: 1.13098 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m1.85063\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 720 | loss: 1.85063 - acc: 0.4538 | val_loss: 1.12992 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: EFAYS5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m1.80423\u001b[0m\u001b[0m | time: 1.205s\n",
      "| Adam | epoch: 721 | loss: 1.80423 - acc: 0.4803 | val_loss: 1.12904 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m1.86863\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 722 | loss: 1.86863 - acc: 0.4447 | val_loss: 1.12797 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m1.81260\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 723 | loss: 1.81260 - acc: 0.4831 | val_loss: 1.12669 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m1.76741\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 724 | loss: 1.76741 - acc: 0.5082 | val_loss: 1.12585 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m1.83495\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 725 | loss: 1.83495 - acc: 0.4699 | val_loss: 1.12483 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m1.78898\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 726 | loss: 1.78898 - acc: 0.4917 | val_loss: 1.12372 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m1.84304\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 727 | loss: 1.84304 - acc: 0.4612 | val_loss: 1.12277 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m1.84718\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 728 | loss: 1.84718 - acc: 0.4682 | val_loss: 1.12164 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m1.79947\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 729 | loss: 1.79947 - acc: 0.4949 | val_loss: 1.12079 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m1.83875\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 730 | loss: 1.83875 - acc: 0.4813 | val_loss: 1.11962 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: FXL75I\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m1.78970\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 731 | loss: 1.78970 - acc: 0.5144 | val_loss: 1.11868 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m1.85426\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 732 | loss: 1.85426 - acc: 0.4739 | val_loss: 1.11754 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m1.80245\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 733 | loss: 1.80245 - acc: 0.5031 | val_loss: 1.11696 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m1.87348\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 734 | loss: 1.87348 - acc: 0.4606 | val_loss: 1.11610 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m1.82207\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 735 | loss: 1.82207 - acc: 0.4864 | val_loss: 1.11497 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m1.77694\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 736 | loss: 1.77694 - acc: 0.5128 | val_loss: 1.11355 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m1.73555\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 737 | loss: 1.73555 - acc: 0.5334 | val_loss: 1.11245 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m1.80354\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 738 | loss: 1.80354 - acc: 0.4941 | val_loss: 1.11107 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m1.75717\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 739 | loss: 1.75717 - acc: 0.5228 | val_loss: 1.10963 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m1.76769\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 740 | loss: 1.76769 - acc: 0.5158 | val_loss: 1.10814 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 6VGXH2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m1.72376\u001b[0m\u001b[0m | time: 1.196s\n",
      "| Adam | epoch: 741 | loss: 1.72376 - acc: 0.5424 | val_loss: 1.10640 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m1.68412\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 742 | loss: 1.68412 - acc: 0.5678 | val_loss: 1.10456 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m1.64959\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 743 | loss: 1.64959 - acc: 0.5923 | val_loss: 1.10299 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m1.67389\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 744 | loss: 1.67389 - acc: 0.5784 | val_loss: 1.10148 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m1.64133\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 745 | loss: 1.64133 - acc: 0.6002 | val_loss: 1.10013 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m1.73047\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 746 | loss: 1.73047 - acc: 0.5558 | val_loss: 1.09868 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m1.69138\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 747 | loss: 1.69138 - acc: 0.5737 | val_loss: 1.09735 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m1.74387\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 748 | loss: 1.74387 - acc: 0.5382 | val_loss: 1.09591 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m1.69840\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 749 | loss: 1.69840 - acc: 0.5687 | val_loss: 1.09504 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m1.76306\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 750 | loss: 1.76306 - acc: 0.5275 | val_loss: 1.09388 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: WSRYL5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m1.72025\u001b[0m\u001b[0m | time: 1.246s\n",
      "| Adam | epoch: 751 | loss: 1.72025 - acc: 0.5513 | val_loss: 1.09318 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m1.79319\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 752 | loss: 1.79319 - acc: 0.5149 | val_loss: 1.09219 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m1.74760\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 753 | loss: 1.74760 - acc: 0.5416 | val_loss: 1.09124 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m1.81670\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 754 | loss: 1.81670 - acc: 0.4999 | val_loss: 1.08988 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m1.76834\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 755 | loss: 1.76834 - acc: 0.5234 | val_loss: 1.08856 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m1.72590\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 756 | loss: 1.72590 - acc: 0.5476 | val_loss: 1.08724 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m1.68537\u001b[0m\u001b[0m | time: 1.074s\n",
      "| Adam | epoch: 757 | loss: 1.68537 - acc: 0.5647 | val_loss: 1.08575 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m1.72109\u001b[0m\u001b[0m | time: 1.063s\n",
      "| Adam | epoch: 758 | loss: 1.72109 - acc: 0.5410 | val_loss: 1.08398 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m1.67750\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 759 | loss: 1.67750 - acc: 0.5666 | val_loss: 1.08207 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m1.64179\u001b[0m\u001b[0m | time: 1.073s\n",
      "| Adam | epoch: 760 | loss: 1.64179 - acc: 0.5787 | val_loss: 1.08010 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 47NK4F\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m1.60435\u001b[0m\u001b[0m | time: 1.314s\n",
      "| Adam | epoch: 761 | loss: 1.60435 - acc: 0.6005 | val_loss: 1.07854 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m1.69351\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 762 | loss: 1.69351 - acc: 0.5530 | val_loss: 1.07674 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m1.65922\u001b[0m\u001b[0m | time: 1.063s\n",
      "| Adam | epoch: 763 | loss: 1.65922 - acc: 0.5742 | val_loss: 1.07482 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m1.62172\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 764 | loss: 1.62172 - acc: 0.5996 | val_loss: 1.07293 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m1.59081\u001b[0m\u001b[0m | time: 1.087s\n",
      "| Adam | epoch: 765 | loss: 1.59081 - acc: 0.6178 | val_loss: 1.07108 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m1.67241\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 766 | loss: 1.67241 - acc: 0.5748 | val_loss: 1.06911 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m1.63752\u001b[0m\u001b[0m | time: 1.072s\n",
      "| Adam | epoch: 767 | loss: 1.63752 - acc: 0.5907 | val_loss: 1.06735 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m1.73391\u001b[0m\u001b[0m | time: 1.178s\n",
      "| Adam | epoch: 768 | loss: 1.73391 - acc: 0.5395 | val_loss: 1.06555 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m1.69365\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 769 | loss: 1.69365 - acc: 0.5574 | val_loss: 1.06348 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m1.65521\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 770 | loss: 1.65521 - acc: 0.5720 | val_loss: 1.06151 - val_acc: 0.8125 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: FM9EVA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m1.62768\u001b[0m\u001b[0m | time: 1.303s\n",
      "| Adam | epoch: 771 | loss: 1.62768 - acc: 0.5882 | val_loss: 1.06001 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m1.69431\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 772 | loss: 1.69431 - acc: 0.5481 | val_loss: 1.05847 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m1.65453\u001b[0m\u001b[0m | time: 1.089s\n",
      "| Adam | epoch: 773 | loss: 1.65453 - acc: 0.5714 | val_loss: 1.05660 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m1.61659\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 774 | loss: 1.61659 - acc: 0.5924 | val_loss: 1.05474 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m1.58953\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 775 | loss: 1.58953 - acc: 0.6082 | val_loss: 1.05292 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m1.55930\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 776 | loss: 1.55930 - acc: 0.6255 | val_loss: 1.05145 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m1.62713\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 777 | loss: 1.62713 - acc: 0.5817 | val_loss: 1.05025 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m1.70792\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 778 | loss: 1.70792 - acc: 0.5391 | val_loss: 1.04903 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m1.67078\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 779 | loss: 1.67078 - acc: 0.5618 | val_loss: 1.04763 - val_acc: 0.8281 -- iter: 64/64\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m1.69727\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 780 | loss: 1.69727 - acc: 0.5541 | val_loss: 1.04600 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 3NLBFU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m1.65903\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 781 | loss: 1.65903 - acc: 0.5674 | val_loss: 1.04448 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m1.62188\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 782 | loss: 1.62188 - acc: 0.5825 | val_loss: 1.04306 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m1.66870\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 783 | loss: 1.66870 - acc: 0.5602 | val_loss: 1.04214 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m1.74811\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 784 | loss: 1.74811 - acc: 0.5151 | val_loss: 1.04118 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m1.70217\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 785 | loss: 1.70217 - acc: 0.5355 | val_loss: 1.03988 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m1.65939\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 786 | loss: 1.65939 - acc: 0.5585 | val_loss: 1.03864 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m1.74254\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 787 | loss: 1.74254 - acc: 0.5183 | val_loss: 1.03739 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m1.82297\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 788 | loss: 1.82297 - acc: 0.4727 | val_loss: 1.03611 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m1.77176\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 789 | loss: 1.77176 - acc: 0.4973 | val_loss: 1.03474 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m1.77463\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 790 | loss: 1.77463 - acc: 0.4945 | val_loss: 1.03338 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: UIB6R9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m1.72332\u001b[0m\u001b[0m | time: 1.198s\n",
      "| Adam | epoch: 791 | loss: 1.72332 - acc: 0.5231 | val_loss: 1.03236 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m1.79133\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 792 | loss: 1.79133 - acc: 0.4880 | val_loss: 1.03098 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m1.74647\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 793 | loss: 1.74647 - acc: 0.5064 | val_loss: 1.02911 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m1.69723\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 794 | loss: 1.69723 - acc: 0.5339 | val_loss: 1.02716 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m1.65854\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 795 | loss: 1.65854 - acc: 0.5539 | val_loss: 1.02515 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m1.62572\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 796 | loss: 1.62572 - acc: 0.5595 | val_loss: 1.02315 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m1.59604\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 797 | loss: 1.59604 - acc: 0.5801 | val_loss: 1.02151 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m1.68523\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 798 | loss: 1.68523 - acc: 0.5346 | val_loss: 1.01974 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m1.63678\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 799 | loss: 1.63678 - acc: 0.5608 | val_loss: 1.01836 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m1.72014\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 800 | loss: 1.72014 - acc: 0.5219 | val_loss: 1.01696 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: HVV1HZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m1.67676\u001b[0m\u001b[0m | time: 1.202s\n",
      "| Adam | epoch: 801 | loss: 1.67676 - acc: 0.5463 | val_loss: 1.01556 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m1.75655\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 802 | loss: 1.75655 - acc: 0.5057 | val_loss: 1.01389 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m1.70973\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 803 | loss: 1.70973 - acc: 0.5270 | val_loss: 1.01249 - val_acc: 0.8438 -- iter: 64/64\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m1.78201\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 804 | loss: 1.78201 - acc: 0.4868 | val_loss: 1.01093 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m1.72985\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 805 | loss: 1.72985 - acc: 0.5131 | val_loss: 1.00945 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m1.67985\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 806 | loss: 1.67985 - acc: 0.5446 | val_loss: 1.00780 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m1.63849\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 807 | loss: 1.63849 - acc: 0.5652 | val_loss: 1.00660 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m1.70590\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 808 | loss: 1.70590 - acc: 0.5243 | val_loss: 1.00509 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m1.65755\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 809 | loss: 1.65755 - acc: 0.5500 | val_loss: 1.00391 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m1.74332\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 810 | loss: 1.74332 - acc: 0.5106 | val_loss: 1.00238 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: NPYT62\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m1.69107\u001b[0m\u001b[0m | time: 1.219s\n",
      "| Adam | epoch: 811 | loss: 1.69107 - acc: 0.5377 | val_loss: 1.00126 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m1.78400\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 812 | loss: 1.78400 - acc: 0.4948 | val_loss: 1.00025 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m1.73028\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 813 | loss: 1.73028 - acc: 0.5219 | val_loss: 0.99952 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m1.80612\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 814 | loss: 1.80612 - acc: 0.4838 | val_loss: 0.99855 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m1.75300\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 815 | loss: 1.75300 - acc: 0.5135 | val_loss: 0.99754 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m1.70143\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 816 | loss: 1.70143 - acc: 0.5450 | val_loss: 0.99645 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m1.65676\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 817 | loss: 1.65676 - acc: 0.5686 | val_loss: 0.99588 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m1.74465\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 818 | loss: 1.74465 - acc: 0.5227 | val_loss: 0.99503 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m1.69564\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 819 | loss: 1.69564 - acc: 0.5486 | val_loss: 0.99431 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m1.72141\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 820 | loss: 1.72141 - acc: 0.5343 | val_loss: 0.99354 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: UQ2BBI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m1.67069\u001b[0m\u001b[0m | time: 1.207s\n",
      "| Adam | epoch: 821 | loss: 1.67069 - acc: 0.5621 | val_loss: 0.99318 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m1.70168\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 822 | loss: 1.70168 - acc: 0.5512 | val_loss: 0.99268 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m1.65685\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 823 | loss: 1.65685 - acc: 0.5696 | val_loss: 0.99248 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m1.73412\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 824 | loss: 1.73412 - acc: 0.5235 | val_loss: 0.99249 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m1.68206\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 825 | loss: 1.68206 - acc: 0.5587 | val_loss: 0.99226 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m1.75343\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 826 | loss: 1.75343 - acc: 0.5231 | val_loss: 0.99206 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m1.70630\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 827 | loss: 1.70630 - acc: 0.5427 | val_loss: 0.99167 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m1.74097\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 828 | loss: 1.74097 - acc: 0.5228 | val_loss: 0.99106 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m1.68911\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 829 | loss: 1.68911 - acc: 0.5471 | val_loss: 0.99074 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m1.71341\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 830 | loss: 1.71341 - acc: 0.5377 | val_loss: 0.98957 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 2ZVI8I\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m1.66849\u001b[0m\u001b[0m | time: 1.207s\n",
      "| Adam | epoch: 831 | loss: 1.66849 - acc: 0.5558 | val_loss: 0.98832 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m1.77221\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 832 | loss: 1.77221 - acc: 0.5096 | val_loss: 0.98660 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m1.71560\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 833 | loss: 1.71560 - acc: 0.5383 | val_loss: 0.98492 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m1.74088\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 834 | loss: 1.74088 - acc: 0.5220 | val_loss: 0.98330 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m1.68932\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 835 | loss: 1.68932 - acc: 0.5479 | val_loss: 0.98104 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m1.64568\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 836 | loss: 1.64568 - acc: 0.5666 | val_loss: 0.97869 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m1.60010\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 837 | loss: 1.60010 - acc: 0.5896 | val_loss: 0.97687 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m1.68873\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 838 | loss: 1.68873 - acc: 0.5416 | val_loss: 0.97511 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m1.64157\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 839 | loss: 1.64157 - acc: 0.5718 | val_loss: 0.97339 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m1.64261\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 840 | loss: 1.64261 - acc: 0.5693 | val_loss: 0.97143 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: BV6MK7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m1.60076\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 841 | loss: 1.60076 - acc: 0.5967 | val_loss: 0.96939 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m1.69992\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 842 | loss: 1.69992 - acc: 0.5496 | val_loss: 0.96728 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m1.65247\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 843 | loss: 1.65247 - acc: 0.5665 | val_loss: 0.96499 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m1.65920\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 844 | loss: 1.65920 - acc: 0.5645 | val_loss: 0.96273 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m1.61818\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 845 | loss: 1.61818 - acc: 0.5862 | val_loss: 0.96135 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m1.69491\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 846 | loss: 1.69491 - acc: 0.5526 | val_loss: 0.96011 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m1.64803\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 847 | loss: 1.64803 - acc: 0.5770 | val_loss: 0.95897 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m1.73375\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 848 | loss: 1.73375 - acc: 0.5318 | val_loss: 0.95798 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m1.68218\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 849 | loss: 1.68218 - acc: 0.5552 | val_loss: 0.95679 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m1.75649\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 850 | loss: 1.75649 - acc: 0.5184 | val_loss: 0.95526 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: XLZLDE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m1.70234\u001b[0m\u001b[0m | time: 1.202s\n",
      "| Adam | epoch: 851 | loss: 1.70234 - acc: 0.5431 | val_loss: 0.95400 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m1.79759\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 852 | loss: 1.79759 - acc: 0.4935 | val_loss: 0.95293 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m1.73712\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 853 | loss: 1.73712 - acc: 0.5223 | val_loss: 0.95182 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m1.77351\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 854 | loss: 1.77351 - acc: 0.5029 | val_loss: 0.95087 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m1.71739\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 855 | loss: 1.71739 - acc: 0.5338 | val_loss: 0.95001 - val_acc: 0.8594 -- iter: 64/64\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m1.66295\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 856 | loss: 1.66295 - acc: 0.5664 | val_loss: 0.94884 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m1.74909\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 857 | loss: 1.74909 - acc: 0.5254 | val_loss: 0.94770 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m1.82652\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 858 | loss: 1.82652 - acc: 0.4885 | val_loss: 0.94627 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m1.76371\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 859 | loss: 1.76371 - acc: 0.5240 | val_loss: 0.94487 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m1.84534\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 860 | loss: 1.84534 - acc: 0.4841 | val_loss: 0.94366 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: FVZ8J0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m1.78560\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 861 | loss: 1.78560 - acc: 0.5185 | val_loss: 0.94311 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m1.85930\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 862 | loss: 1.85930 - acc: 0.4807 | val_loss: 0.94239 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m1.79359\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 863 | loss: 1.79359 - acc: 0.5108 | val_loss: 0.94221 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m1.88373\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 864 | loss: 1.88373 - acc: 0.4659 | val_loss: 0.94226 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m1.81703\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 865 | loss: 1.81703 - acc: 0.5037 | val_loss: 0.94191 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m1.75513\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 866 | loss: 1.75513 - acc: 0.5330 | val_loss: 0.94135 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m1.70119\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 867 | loss: 1.70119 - acc: 0.5579 | val_loss: 0.94056 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m1.65094\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 868 | loss: 1.65094 - acc: 0.5833 | val_loss: 0.94010 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m1.74528\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 869 | loss: 1.74528 - acc: 0.5359 | val_loss: 0.94011 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m1.80683\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 870 | loss: 1.80683 - acc: 0.5026 | val_loss: 0.93957 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 1PF2HQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m1.74528\u001b[0m\u001b[0m | time: 1.214s\n",
      "| Adam | epoch: 871 | loss: 1.74528 - acc: 0.5289 | val_loss: 0.93875 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m1.68689\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 872 | loss: 1.68689 - acc: 0.5589 | val_loss: 0.93802 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m1.63853\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 873 | loss: 1.63853 - acc: 0.5842 | val_loss: 0.93783 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m1.73919\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 874 | loss: 1.73919 - acc: 0.5414 | val_loss: 0.93771 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m1.67910\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 875 | loss: 1.67910 - acc: 0.5717 | val_loss: 0.93747 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m1.75568\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 876 | loss: 1.75568 - acc: 0.5301 | val_loss: 0.93681 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m1.69942\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 877 | loss: 1.69942 - acc: 0.5552 | val_loss: 0.93620 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m1.76041\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 878 | loss: 1.76041 - acc: 0.5185 | val_loss: 0.93553 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m1.70301\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 879 | loss: 1.70301 - acc: 0.5494 | val_loss: 0.93509 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m1.71945\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 880 | loss: 1.71945 - acc: 0.5476 | val_loss: 0.93409 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: V25GYA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m1.66953\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 881 | loss: 1.66953 - acc: 0.5694 | val_loss: 0.93290 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m1.62205\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 882 | loss: 1.62205 - acc: 0.5875 | val_loss: 0.93086 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m1.64456\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 883 | loss: 1.64456 - acc: 0.5787 | val_loss: 0.92877 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m1.68403\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 884 | loss: 1.68403 - acc: 0.5583 | val_loss: 0.92673 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m1.63414\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 885 | loss: 1.63414 - acc: 0.5806 | val_loss: 0.92488 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m1.72329\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 886 | loss: 1.72329 - acc: 0.5335 | val_loss: 0.92241 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m1.67021\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 887 | loss: 1.67021 - acc: 0.5567 | val_loss: 0.91981 - val_acc: 0.8750 -- iter: 64/64\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m1.74205\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 888 | loss: 1.74205 - acc: 0.5167 | val_loss: 0.91714 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m1.68772\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 889 | loss: 1.68772 - acc: 0.5400 | val_loss: 0.91530 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m1.76789\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 890 | loss: 1.76789 - acc: 0.4985 | val_loss: 0.91349 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: KQU7NP\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m1.71059\u001b[0m\u001b[0m | time: 1.212s\n",
      "| Adam | epoch: 891 | loss: 1.71059 - acc: 0.5283 | val_loss: 0.91126 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m1.66372\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 892 | loss: 1.66372 - acc: 0.5536 | val_loss: 0.90902 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m1.61628\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 893 | loss: 1.61628 - acc: 0.5748 | val_loss: 0.90704 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m1.57713\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 894 | loss: 1.57713 - acc: 0.5970 | val_loss: 0.90507 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m1.53814\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 895 | loss: 1.53814 - acc: 0.6201 | val_loss: 0.90309 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m1.64664\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 896 | loss: 1.64664 - acc: 0.5659 | val_loss: 0.90138 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m1.59988\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 897 | loss: 1.59988 - acc: 0.5969 | val_loss: 0.89998 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m1.69680\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 898 | loss: 1.69680 - acc: 0.5497 | val_loss: 0.89865 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m1.64693\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 899 | loss: 1.64693 - acc: 0.5744 | val_loss: 0.89749 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m1.66814\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 900 | loss: 1.66814 - acc: 0.5669 | val_loss: 0.89629 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: MZUUWY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m1.61304\u001b[0m\u001b[0m | time: 1.199s\n",
      "| Adam | epoch: 901 | loss: 1.61304 - acc: 0.5946 | val_loss: 0.89499 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m1.56153\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 902 | loss: 1.56153 - acc: 0.6164 | val_loss: 0.89392 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m1.62175\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 903 | loss: 1.62175 - acc: 0.5845 | val_loss: 0.89287 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m1.58042\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 904 | loss: 1.58042 - acc: 0.6041 | val_loss: 0.89174 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m1.54087\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 905 | loss: 1.54087 - acc: 0.6219 | val_loss: 0.89084 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m1.64570\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 906 | loss: 1.64570 - acc: 0.5659 | val_loss: 0.88981 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m1.60744\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 907 | loss: 1.60744 - acc: 0.5843 | val_loss: 0.88891 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m1.69940\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 908 | loss: 1.69940 - acc: 0.5415 | val_loss: 0.88793 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m1.64352\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 909 | loss: 1.64352 - acc: 0.5702 | val_loss: 0.88671 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m1.66718\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 910 | loss: 1.66718 - acc: 0.5585 | val_loss: 0.88534 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: UX125G\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m1.62133\u001b[0m\u001b[0m | time: 1.209s\n",
      "| Adam | epoch: 911 | loss: 1.62133 - acc: 0.5823 | val_loss: 0.88390 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m1.57548\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 912 | loss: 1.57548 - acc: 0.6006 | val_loss: 0.88261 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m1.68500\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 913 | loss: 1.68500 - acc: 0.5500 | val_loss: 0.88133 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m1.63396\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 914 | loss: 1.63396 - acc: 0.5778 | val_loss: 0.88030 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m1.71788\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 915 | loss: 1.71788 - acc: 0.5325 | val_loss: 0.87915 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m1.66188\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 916 | loss: 1.66188 - acc: 0.5605 | val_loss: 0.87798 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m1.60941\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 917 | loss: 1.60941 - acc: 0.5841 | val_loss: 0.87688 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m1.72556\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 918 | loss: 1.72556 - acc: 0.5320 | val_loss: 0.87585 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m1.67725\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 919 | loss: 1.67725 - acc: 0.5475 | val_loss: 0.87494 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m1.77916\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 920 | loss: 1.77916 - acc: 0.4959 | val_loss: 0.87395 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 3ZMATJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m1.71518\u001b[0m\u001b[0m | time: 1.223s\n",
      "| Adam | epoch: 921 | loss: 1.71518 - acc: 0.5291 | val_loss: 0.87359 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m1.80546\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 922 | loss: 1.80546 - acc: 0.4825 | val_loss: 0.87323 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m1.74314\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 923 | loss: 1.74314 - acc: 0.5108 | val_loss: 0.87304 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m1.68489\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 924 | loss: 1.68489 - acc: 0.5394 | val_loss: 0.87279 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m1.62845\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 925 | loss: 1.62845 - acc: 0.5604 | val_loss: 0.87291 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m1.70983\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 926 | loss: 1.70983 - acc: 0.5216 | val_loss: 0.87299 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m1.64954\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 927 | loss: 1.64954 - acc: 0.5507 | val_loss: 0.87267 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m1.71365\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 928 | loss: 1.71365 - acc: 0.5222 | val_loss: 0.87214 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m1.65610\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 929 | loss: 1.65610 - acc: 0.5559 | val_loss: 0.87115 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m1.67323\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 930 | loss: 1.67323 - acc: 0.5472 | val_loss: 0.87014 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: CNG3HD\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m1.61857\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 931 | loss: 1.61857 - acc: 0.5800 | val_loss: 0.86971 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m1.71156\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 932 | loss: 1.71156 - acc: 0.5392 | val_loss: 0.86931 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m1.65458\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 933 | loss: 1.65458 - acc: 0.5696 | val_loss: 0.86860 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m1.60434\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 934 | loss: 1.60434 - acc: 0.5939 | val_loss: 0.86755 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m1.69584\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 935 | loss: 1.69584 - acc: 0.5454 | val_loss: 0.86633 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m1.64594\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 936 | loss: 1.64594 - acc: 0.5690 | val_loss: 0.86506 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m1.59311\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 937 | loss: 1.59311 - acc: 0.5887 | val_loss: 0.86449 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m1.67985\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 938 | loss: 1.67985 - acc: 0.5470 | val_loss: 0.86347 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m1.62586\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 939 | loss: 1.62586 - acc: 0.5751 | val_loss: 0.86254 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m1.68541\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 940 | loss: 1.68541 - acc: 0.5379 | val_loss: 0.86161 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: ANFO8O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m1.63351\u001b[0m\u001b[0m | time: 1.224s\n",
      "| Adam | epoch: 941 | loss: 1.63351 - acc: 0.5623 | val_loss: 0.86107 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m1.72283\u001b[0m\u001b[0m | time: 1.084s\n",
      "| Adam | epoch: 942 | loss: 1.72283 - acc: 0.5154 | val_loss: 0.86032 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m1.66230\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 943 | loss: 1.66230 - acc: 0.5498 | val_loss: 0.85936 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m1.61206\u001b[0m\u001b[0m | time: 1.069s\n",
      "| Adam | epoch: 944 | loss: 1.61206 - acc: 0.5714 | val_loss: 0.85877 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m1.56187\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 945 | loss: 1.56187 - acc: 0.5924 | val_loss: 0.85809 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m1.66890\u001b[0m\u001b[0m | time: 1.065s\n",
      "| Adam | epoch: 946 | loss: 1.66890 - acc: 0.5409 | val_loss: 0.85725 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m1.61586\u001b[0m\u001b[0m | time: 1.094s\n",
      "| Adam | epoch: 947 | loss: 1.61586 - acc: 0.5681 | val_loss: 0.85623 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m1.70296\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 948 | loss: 1.70296 - acc: 0.5285 | val_loss: 0.85530 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m1.64661\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 949 | loss: 1.64661 - acc: 0.5553 | val_loss: 0.85431 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m1.74047\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 950 | loss: 1.74047 - acc: 0.5123 | val_loss: 0.85331 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: DG150P\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m1.67682\u001b[0m\u001b[0m | time: 1.205s\n",
      "| Adam | epoch: 951 | loss: 1.67682 - acc: 0.5376 | val_loss: 0.85246 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m1.77652\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 952 | loss: 1.77652 - acc: 0.4932 | val_loss: 0.85169 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m1.71437\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 953 | loss: 1.71437 - acc: 0.5236 | val_loss: 0.85059 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m1.74409\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 954 | loss: 1.74409 - acc: 0.5072 | val_loss: 0.84965 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m1.68122\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 955 | loss: 1.68122 - acc: 0.5361 | val_loss: 0.84893 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m1.75534\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 956 | loss: 1.75534 - acc: 0.4950 | val_loss: 0.84815 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m1.69428\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 957 | loss: 1.69428 - acc: 0.5252 | val_loss: 0.84770 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m1.77591\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 958 | loss: 1.77591 - acc: 0.4899 | val_loss: 0.84706 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m1.70616\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 959 | loss: 1.70616 - acc: 0.5268 | val_loss: 0.84656 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m1.76610\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 960 | loss: 1.76610 - acc: 0.4991 | val_loss: 0.84587 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: DG0490\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m1.69747\u001b[0m\u001b[0m | time: 1.203s\n",
      "| Adam | epoch: 961 | loss: 1.69747 - acc: 0.5352 | val_loss: 0.84491 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m1.64428\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 962 | loss: 1.64428 - acc: 0.5660 | val_loss: 0.84375 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m1.69892\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 963 | loss: 1.69892 - acc: 0.5407 | val_loss: 0.84247 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m1.64769\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 964 | loss: 1.64769 - acc: 0.5632 | val_loss: 0.84112 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m1.59904\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 965 | loss: 1.59904 - acc: 0.5850 | val_loss: 0.83970 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m1.55490\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 966 | loss: 1.55490 - acc: 0.6062 | val_loss: 0.83824 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m1.51109\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 967 | loss: 1.51109 - acc: 0.6252 | val_loss: 0.83724 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m1.62218\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 968 | loss: 1.62218 - acc: 0.5737 | val_loss: 0.83609 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m1.57002\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 969 | loss: 1.57002 - acc: 0.5991 | val_loss: 0.83504 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m1.61965\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 970 | loss: 1.61965 - acc: 0.5751 | val_loss: 0.83388 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: JZNOGN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m1.57457\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 971 | loss: 1.57457 - acc: 0.6020 | val_loss: 0.83281 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m1.60654\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 972 | loss: 1.60654 - acc: 0.5887 | val_loss: 0.83163 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m1.55747\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 973 | loss: 1.55747 - acc: 0.6079 | val_loss: 0.83028 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m1.60385\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 974 | loss: 1.60385 - acc: 0.5862 | val_loss: 0.82889 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m1.55829\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 975 | loss: 1.55829 - acc: 0.6057 | val_loss: 0.82735 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m1.51107\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 976 | loss: 1.51107 - acc: 0.6279 | val_loss: 0.82612 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m1.60432\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 977 | loss: 1.60432 - acc: 0.5823 | val_loss: 0.82505 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m1.63972\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 978 | loss: 1.63972 - acc: 0.5725 | val_loss: 0.82398 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m1.58571\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 979 | loss: 1.58571 - acc: 0.5934 | val_loss: 0.82322 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m1.69031\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 980 | loss: 1.69031 - acc: 0.5434 | val_loss: 0.82250 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: TCDL9R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m1.62881\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 981 | loss: 1.62881 - acc: 0.5735 | val_loss: 0.82170 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m1.73759\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 982 | loss: 1.73759 - acc: 0.5239 | val_loss: 0.82090 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m1.66905\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 983 | loss: 1.66905 - acc: 0.5528 | val_loss: 0.82019 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m1.69714\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 984 | loss: 1.69714 - acc: 0.5428 | val_loss: 0.81942 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m1.63478\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 985 | loss: 1.63478 - acc: 0.5729 | val_loss: 0.81862 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m1.58467\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 986 | loss: 1.58467 - acc: 0.6031 | val_loss: 0.81794 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m1.53749\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 987 | loss: 1.53749 - acc: 0.6303 | val_loss: 0.81726 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m1.65209\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 988 | loss: 1.65209 - acc: 0.5735 | val_loss: 0.81673 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m1.59472\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 989 | loss: 1.59472 - acc: 0.5990 | val_loss: 0.81640 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m1.69978\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 990 | loss: 1.69978 - acc: 0.5485 | val_loss: 0.81606 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: S9DR36\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m1.63619\u001b[0m\u001b[0m | time: 1.218s\n",
      "| Adam | epoch: 991 | loss: 1.63619 - acc: 0.5842 | val_loss: 0.81540 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m1.58476\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 992 | loss: 1.58476 - acc: 0.6024 | val_loss: 0.81478 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m1.62984\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 993 | loss: 1.62984 - acc: 0.5718 | val_loss: 0.81417 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m1.67751\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 994 | loss: 1.67751 - acc: 0.5490 | val_loss: 0.81343 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m1.61886\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 995 | loss: 1.61886 - acc: 0.5816 | val_loss: 0.81311 - val_acc: 0.8906 -- iter: 64/64\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m1.69760\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 996 | loss: 1.69760 - acc: 0.5453 | val_loss: 0.81266 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m1.63556\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 997 | loss: 1.63556 - acc: 0.5736 | val_loss: 0.81255 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m1.71559\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 998 | loss: 1.71559 - acc: 0.5319 | val_loss: 0.81229 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m1.65279\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 999 | loss: 1.65279 - acc: 0.5615 | val_loss: 0.81195 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m1.65992\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1000 | loss: 1.65992 - acc: 0.5600 | val_loss: 0.81126 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: O40KWW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1001  | total loss: \u001b[1m\u001b[32m1.60121\u001b[0m\u001b[0m | time: 1.206s\n",
      "| Adam | epoch: 1001 | loss: 1.60121 - acc: 0.5853 | val_loss: 0.81043 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1002  | total loss: \u001b[1m\u001b[32m1.55310\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1002 | loss: 1.55310 - acc: 0.6111 | val_loss: 0.80935 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1003  | total loss: \u001b[1m\u001b[32m1.50755\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1003 | loss: 1.50755 - acc: 0.6313 | val_loss: 0.80793 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1004  | total loss: \u001b[1m\u001b[32m1.53182\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1004 | loss: 1.53182 - acc: 0.6197 | val_loss: 0.80658 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1005  | total loss: \u001b[1m\u001b[32m1.49283\u001b[0m\u001b[0m | time: 1.063s\n",
      "| Adam | epoch: 1005 | loss: 1.49283 - acc: 0.6437 | val_loss: 0.80529 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1006  | total loss: \u001b[1m\u001b[32m1.54385\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1006 | loss: 1.54385 - acc: 0.6168 | val_loss: 0.80390 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1007  | total loss: \u001b[1m\u001b[32m1.49877\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1007 | loss: 1.49877 - acc: 0.6348 | val_loss: 0.80252 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1008  | total loss: \u001b[1m\u001b[32m1.60006\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1008 | loss: 1.60006 - acc: 0.5838 | val_loss: 0.80101 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1009  | total loss: \u001b[1m\u001b[32m1.54445\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1009 | loss: 1.54445 - acc: 0.6114 | val_loss: 0.80031 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1010  | total loss: \u001b[1m\u001b[32m1.64697\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1010 | loss: 1.64697 - acc: 0.5674 | val_loss: 0.79964 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: L6OVC0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1011  | total loss: \u001b[1m\u001b[32m1.59486\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 1011 | loss: 1.59486 - acc: 0.5966 | val_loss: 0.79885 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1012  | total loss: \u001b[1m\u001b[32m1.69828\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1012 | loss: 1.69828 - acc: 0.5510 | val_loss: 0.79774 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1013  | total loss: \u001b[1m\u001b[32m1.63805\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1013 | loss: 1.63805 - acc: 0.5819 | val_loss: 0.79674 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1014  | total loss: \u001b[1m\u001b[32m1.72560\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1014 | loss: 1.72560 - acc: 0.5471 | val_loss: 0.79524 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1015  | total loss: \u001b[1m\u001b[32m1.65830\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1015 | loss: 1.65830 - acc: 0.5783 | val_loss: 0.79371 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1016  | total loss: \u001b[1m\u001b[32m1.77185\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1016 | loss: 1.77185 - acc: 0.5252 | val_loss: 0.79227 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1017  | total loss: \u001b[1m\u001b[32m1.70467\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1017 | loss: 1.70467 - acc: 0.5555 | val_loss: 0.79133 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1018  | total loss: \u001b[1m\u001b[32m1.77150\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1018 | loss: 1.77150 - acc: 0.5203 | val_loss: 0.78999 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1019  | total loss: \u001b[1m\u001b[32m1.70212\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1019 | loss: 1.70212 - acc: 0.5542 | val_loss: 0.78854 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1020  | total loss: \u001b[1m\u001b[32m1.71009\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1020 | loss: 1.71009 - acc: 0.5503 | val_loss: 0.78727 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 6KI4XH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1021  | total loss: \u001b[1m\u001b[32m1.65103\u001b[0m\u001b[0m | time: 1.216s\n",
      "| Adam | epoch: 1021 | loss: 1.65103 - acc: 0.5750 | val_loss: 0.78642 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1022  | total loss: \u001b[1m\u001b[32m1.73806\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1022 | loss: 1.73806 - acc: 0.5331 | val_loss: 0.78562 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1023  | total loss: \u001b[1m\u001b[32m1.67088\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1023 | loss: 1.67088 - acc: 0.5673 | val_loss: 0.78490 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1024  | total loss: \u001b[1m\u001b[32m1.77703\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1024 | loss: 1.77703 - acc: 0.5199 | val_loss: 0.78408 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1025  | total loss: \u001b[1m\u001b[32m1.71110\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1025 | loss: 1.71110 - acc: 0.5554 | val_loss: 0.78341 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1026  | total loss: \u001b[1m\u001b[32m1.79630\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1026 | loss: 1.79630 - acc: 0.5108 | val_loss: 0.78254 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1027  | total loss: \u001b[1m\u001b[32m1.72107\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1027 | loss: 1.72107 - acc: 0.5457 | val_loss: 0.78199 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1028  | total loss: \u001b[1m\u001b[32m1.79594\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1028 | loss: 1.79594 - acc: 0.5130 | val_loss: 0.78158 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1029  | total loss: \u001b[1m\u001b[32m1.72176\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1029 | loss: 1.72176 - acc: 0.5508 | val_loss: 0.78096 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1030  | total loss: \u001b[1m\u001b[32m1.72103\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1030 | loss: 1.72103 - acc: 0.5504 | val_loss: 0.78032 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 1UHBD9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1031  | total loss: \u001b[1m\u001b[32m1.64917\u001b[0m\u001b[0m | time: 1.212s\n",
      "| Adam | epoch: 1031 | loss: 1.64917 - acc: 0.5797 | val_loss: 0.77981 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1032  | total loss: \u001b[1m\u001b[32m1.73616\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1032 | loss: 1.73616 - acc: 0.5342 | val_loss: 0.77933 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1033  | total loss: \u001b[1m\u001b[32m1.66793\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1033 | loss: 1.66793 - acc: 0.5636 | val_loss: 0.77942 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1034  | total loss: \u001b[1m\u001b[32m1.76705\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1034 | loss: 1.76705 - acc: 0.5135 | val_loss: 0.77922 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1035  | total loss: \u001b[1m\u001b[32m1.69755\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1035 | loss: 1.69755 - acc: 0.5465 | val_loss: 0.77882 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1036  | total loss: \u001b[1m\u001b[32m1.72833\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1036 | loss: 1.72833 - acc: 0.5356 | val_loss: 0.77853 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1037  | total loss: \u001b[1m\u001b[32m1.65781\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1037 | loss: 1.65781 - acc: 0.5696 | val_loss: 0.77829 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1038  | total loss: \u001b[1m\u001b[32m1.74533\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1038 | loss: 1.74533 - acc: 0.5235 | val_loss: 0.77789 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1039  | total loss: \u001b[1m\u001b[32m1.67524\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1039 | loss: 1.67524 - acc: 0.5556 | val_loss: 0.77750 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1040  | total loss: \u001b[1m\u001b[32m1.76990\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1040 | loss: 1.76990 - acc: 0.5094 | val_loss: 0.77715 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: JZLMY0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1041  | total loss: \u001b[1m\u001b[32m1.70017\u001b[0m\u001b[0m | time: 1.230s\n",
      "| Adam | epoch: 1041 | loss: 1.70017 - acc: 0.5366 | val_loss: 0.77710 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1042  | total loss: \u001b[1m\u001b[32m1.79928\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1042 | loss: 1.79928 - acc: 0.4907 | val_loss: 0.77684 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1043  | total loss: \u001b[1m\u001b[32m1.72426\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1043 | loss: 1.72426 - acc: 0.5276 | val_loss: 0.77653 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1044  | total loss: \u001b[1m\u001b[32m1.65997\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1044 | loss: 1.65997 - acc: 0.5639 | val_loss: 0.77642 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1045  | total loss: \u001b[1m\u001b[32m1.74790\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1045 | loss: 1.74790 - acc: 0.5216 | val_loss: 0.77604 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1046  | total loss: \u001b[1m\u001b[32m1.67698\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1046 | loss: 1.67698 - acc: 0.5538 | val_loss: 0.77544 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1047  | total loss: \u001b[1m\u001b[32m1.61028\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1047 | loss: 1.61028 - acc: 0.5906 | val_loss: 0.77531 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1048  | total loss: \u001b[1m\u001b[32m1.67561\u001b[0m\u001b[0m | time: 1.074s\n",
      "| Adam | epoch: 1048 | loss: 1.67561 - acc: 0.5612 | val_loss: 0.77528 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1049  | total loss: \u001b[1m\u001b[32m1.60645\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1049 | loss: 1.60645 - acc: 0.6004 | val_loss: 0.77539 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1050  | total loss: \u001b[1m\u001b[32m1.70151\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1050 | loss: 1.70151 - acc: 0.5560 | val_loss: 0.77528 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: AH1LGI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1051  | total loss: \u001b[1m\u001b[32m1.63831\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 1051 | loss: 1.63831 - acc: 0.5848 | val_loss: 0.77498 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1052  | total loss: \u001b[1m\u001b[32m1.72578\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1052 | loss: 1.72578 - acc: 0.5419 | val_loss: 0.77486 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1053  | total loss: \u001b[1m\u001b[32m1.65381\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1053 | loss: 1.65381 - acc: 0.5815 | val_loss: 0.77477 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1054  | total loss: \u001b[1m\u001b[32m1.68778\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1054 | loss: 1.68778 - acc: 0.5655 | val_loss: 0.77432 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1055  | total loss: \u001b[1m\u001b[32m1.62686\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1055 | loss: 1.62686 - acc: 0.5949 | val_loss: 0.77325 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1056  | total loss: \u001b[1m\u001b[32m1.57262\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1056 | loss: 1.57262 - acc: 0.6182 | val_loss: 0.77241 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1057  | total loss: \u001b[1m\u001b[32m1.52194\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1057 | loss: 1.52194 - acc: 0.6423 | val_loss: 0.77142 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1058  | total loss: \u001b[1m\u001b[32m1.52763\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1058 | loss: 1.52763 - acc: 0.6359 | val_loss: 0.76997 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1059  | total loss: \u001b[1m\u001b[32m1.47772\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 1059 | loss: 1.47772 - acc: 0.6598 | val_loss: 0.76811 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1060  | total loss: \u001b[1m\u001b[32m1.53533\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1060 | loss: 1.53533 - acc: 0.6267 | val_loss: 0.76614 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: U0U2W9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1061  | total loss: \u001b[1m\u001b[32m1.48473\u001b[0m\u001b[0m | time: 1.217s\n",
      "| Adam | epoch: 1061 | loss: 1.48473 - acc: 0.6452 | val_loss: 0.76432 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1062  | total loss: \u001b[1m\u001b[32m1.58060\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1062 | loss: 1.58060 - acc: 0.5932 | val_loss: 0.76247 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1063  | total loss: \u001b[1m\u001b[32m1.52910\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1063 | loss: 1.52910 - acc: 0.6167 | val_loss: 0.76102 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1064  | total loss: \u001b[1m\u001b[32m1.47779\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1064 | loss: 1.47779 - acc: 0.6425 | val_loss: 0.75947 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1065  | total loss: \u001b[1m\u001b[32m1.43171\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1065 | loss: 1.43171 - acc: 0.6689 | val_loss: 0.75799 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1066  | total loss: \u001b[1m\u001b[32m1.39382\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1066 | loss: 1.39382 - acc: 0.6911 | val_loss: 0.75691 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1067  | total loss: \u001b[1m\u001b[32m1.47860\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1067 | loss: 1.47860 - acc: 0.6532 | val_loss: 0.75609 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1068  | total loss: \u001b[1m\u001b[32m1.48986\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1068 | loss: 1.48986 - acc: 0.6473 | val_loss: 0.75514 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1069  | total loss: \u001b[1m\u001b[32m1.44395\u001b[0m\u001b[0m | time: 1.065s\n",
      "| Adam | epoch: 1069 | loss: 1.44395 - acc: 0.6700 | val_loss: 0.75469 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1070  | total loss: \u001b[1m\u001b[32m1.45893\u001b[0m\u001b[0m | time: 1.074s\n",
      "| Adam | epoch: 1070 | loss: 1.45893 - acc: 0.6593 | val_loss: 0.75411 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: S1W8IV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1071  | total loss: \u001b[1m\u001b[32m1.41798\u001b[0m\u001b[0m | time: 1.270s\n",
      "| Adam | epoch: 1071 | loss: 1.41798 - acc: 0.6809 | val_loss: 0.75316 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1072  | total loss: \u001b[1m\u001b[32m1.53941\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1072 | loss: 1.53941 - acc: 0.6284 | val_loss: 0.75195 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1073  | total loss: \u001b[1m\u001b[32m1.48829\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1073 | loss: 1.48829 - acc: 0.6531 | val_loss: 0.75045 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1074  | total loss: \u001b[1m\u001b[32m1.44026\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1074 | loss: 1.44026 - acc: 0.6721 | val_loss: 0.74889 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1075  | total loss: \u001b[1m\u001b[32m1.40210\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1075 | loss: 1.40210 - acc: 0.6877 | val_loss: 0.74755 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1076  | total loss: \u001b[1m\u001b[32m1.46365\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1076 | loss: 1.46365 - acc: 0.6580 | val_loss: 0.74609 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1077  | total loss: \u001b[1m\u001b[32m1.42222\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1077 | loss: 1.42222 - acc: 0.6766 | val_loss: 0.74440 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1078  | total loss: \u001b[1m\u001b[32m1.54050\u001b[0m\u001b[0m | time: 1.065s\n",
      "| Adam | epoch: 1078 | loss: 1.54050 - acc: 0.6214 | val_loss: 0.74310 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1079  | total loss: \u001b[1m\u001b[32m1.49050\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1079 | loss: 1.49050 - acc: 0.6437 | val_loss: 0.74196 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1080  | total loss: \u001b[1m\u001b[32m1.51216\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1080 | loss: 1.51216 - acc: 0.6340 | val_loss: 0.74090 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 679QBL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1081  | total loss: \u001b[1m\u001b[32m1.45875\u001b[0m\u001b[0m | time: 1.207s\n",
      "| Adam | epoch: 1081 | loss: 1.45875 - acc: 0.6565 | val_loss: 0.73936 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1082  | total loss: \u001b[1m\u001b[32m1.50813\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1082 | loss: 1.50813 - acc: 0.6315 | val_loss: 0.73772 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1083  | total loss: \u001b[1m\u001b[32m1.46068\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1083 | loss: 1.46068 - acc: 0.6527 | val_loss: 0.73624 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1084  | total loss: \u001b[1m\u001b[32m1.48887\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1084 | loss: 1.48887 - acc: 0.6437 | val_loss: 0.73474 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1085  | total loss: \u001b[1m\u001b[32m1.44305\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1085 | loss: 1.44305 - acc: 0.6653 | val_loss: 0.73327 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1086  | total loss: \u001b[1m\u001b[32m1.39749\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1086 | loss: 1.39749 - acc: 0.6847 | val_loss: 0.73209 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1087  | total loss: \u001b[1m\u001b[32m1.35843\u001b[0m\u001b[0m | time: 1.069s\n",
      "| Adam | epoch: 1087 | loss: 1.35843 - acc: 0.7037 | val_loss: 0.73146 - val_acc: 0.9062 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1088  | total loss: \u001b[1m\u001b[32m1.50323\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1088 | loss: 1.50323 - acc: 0.6396 | val_loss: 0.73091 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1089  | total loss: \u001b[1m\u001b[32m1.45262\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1089 | loss: 1.45262 - acc: 0.6647 | val_loss: 0.73001 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1090  | total loss: \u001b[1m\u001b[32m1.56348\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1090 | loss: 1.56348 - acc: 0.6138 | val_loss: 0.72920 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 480R2W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1091  | total loss: \u001b[1m\u001b[32m1.50633\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1091 | loss: 1.50633 - acc: 0.6400 | val_loss: 0.72808 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1092  | total loss: \u001b[1m\u001b[32m1.45926\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1092 | loss: 1.45926 - acc: 0.6588 | val_loss: 0.72679 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1093  | total loss: \u001b[1m\u001b[32m1.41174\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1093 | loss: 1.41174 - acc: 0.6804 | val_loss: 0.72497 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1094  | total loss: \u001b[1m\u001b[32m1.36964\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1094 | loss: 1.36964 - acc: 0.6999 | val_loss: 0.72302 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1095  | total loss: \u001b[1m\u001b[32m1.33423\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1095 | loss: 1.33423 - acc: 0.7143 | val_loss: 0.72132 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1096  | total loss: \u001b[1m\u001b[32m1.29836\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1096 | loss: 1.29836 - acc: 0.7319 | val_loss: 0.71969 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1097  | total loss: \u001b[1m\u001b[32m1.26987\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1097 | loss: 1.26987 - acc: 0.7446 | val_loss: 0.71800 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1098  | total loss: \u001b[1m\u001b[32m1.23609\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1098 | loss: 1.23609 - acc: 0.7592 | val_loss: 0.71615 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1099  | total loss: \u001b[1m\u001b[32m1.21348\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1099 | loss: 1.21348 - acc: 0.7708 | val_loss: 0.71453 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1100  | total loss: \u001b[1m\u001b[32m1.19773\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1100 | loss: 1.19773 - acc: 0.7734 | val_loss: 0.71297 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: YR40ET\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1101  | total loss: \u001b[1m\u001b[32m1.16922\u001b[0m\u001b[0m | time: 1.225s\n",
      "| Adam | epoch: 1101 | loss: 1.16922 - acc: 0.7867 | val_loss: 0.71155 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1102  | total loss: \u001b[1m\u001b[32m1.15427\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1102 | loss: 1.15427 - acc: 0.7908 | val_loss: 0.71057 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1103  | total loss: \u001b[1m\u001b[32m1.28504\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1103 | loss: 1.28504 - acc: 0.7258 | val_loss: 0.70990 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1104  | total loss: \u001b[1m\u001b[32m1.41756\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1104 | loss: 1.41756 - acc: 0.6704 | val_loss: 0.70900 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1105  | total loss: \u001b[1m\u001b[32m1.37203\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1105 | loss: 1.37203 - acc: 0.6878 | val_loss: 0.70793 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1106  | total loss: \u001b[1m\u001b[32m1.52335\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1106 | loss: 1.52335 - acc: 0.6205 | val_loss: 0.70657 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1107  | total loss: \u001b[1m\u001b[32m1.46482\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1107 | loss: 1.46482 - acc: 0.6491 | val_loss: 0.70530 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1108  | total loss: \u001b[1m\u001b[32m1.57624\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1108 | loss: 1.57624 - acc: 0.6014 | val_loss: 0.70463 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1109  | total loss: \u001b[1m\u001b[32m1.51397\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1109 | loss: 1.51397 - acc: 0.6288 | val_loss: 0.70354 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1110  | total loss: \u001b[1m\u001b[32m1.62936\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1110 | loss: 1.62936 - acc: 0.5753 | val_loss: 0.70267 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: S54HER\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1111  | total loss: \u001b[1m\u001b[32m1.55961\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 1111 | loss: 1.55961 - acc: 0.6068 | val_loss: 0.70171 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1112  | total loss: \u001b[1m\u001b[32m1.66151\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1112 | loss: 1.66151 - acc: 0.5602 | val_loss: 0.70061 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1113  | total loss: \u001b[1m\u001b[32m1.59710\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1113 | loss: 1.59710 - acc: 0.5885 | val_loss: 0.69983 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1114  | total loss: \u001b[1m\u001b[32m1.53272\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1114 | loss: 1.53272 - acc: 0.6156 | val_loss: 0.69878 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1115  | total loss: \u001b[1m\u001b[32m1.64251\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1115 | loss: 1.64251 - acc: 0.5650 | val_loss: 0.69739 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1116  | total loss: \u001b[1m\u001b[32m1.57161\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1116 | loss: 1.57161 - acc: 0.5991 | val_loss: 0.69553 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1117  | total loss: \u001b[1m\u001b[32m1.68492\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1117 | loss: 1.68492 - acc: 0.5455 | val_loss: 0.69420 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1118  | total loss: \u001b[1m\u001b[32m1.72125\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1118 | loss: 1.72125 - acc: 0.5284 | val_loss: 0.69289 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1119  | total loss: \u001b[1m\u001b[32m1.64316\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1119 | loss: 1.64316 - acc: 0.5615 | val_loss: 0.69202 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1120  | total loss: \u001b[1m\u001b[32m1.74349\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1120 | loss: 1.74349 - acc: 0.5225 | val_loss: 0.69112 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: ZUJEBQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1121  | total loss: \u001b[1m\u001b[32m1.66090\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1121 | loss: 1.66090 - acc: 0.5625 | val_loss: 0.69024 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1122  | total loss: \u001b[1m\u001b[32m1.59179\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1122 | loss: 1.59179 - acc: 0.5906 | val_loss: 0.69005 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1123  | total loss: \u001b[1m\u001b[32m1.60378\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1123 | loss: 1.60378 - acc: 0.5862 | val_loss: 0.68986 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1124  | total loss: \u001b[1m\u001b[32m1.70436\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1124 | loss: 1.70436 - acc: 0.5432 | val_loss: 0.68955 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1125  | total loss: \u001b[1m\u001b[32m1.63132\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1125 | loss: 1.63132 - acc: 0.5795 | val_loss: 0.68913 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1126  | total loss: \u001b[1m\u001b[32m1.56403\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1126 | loss: 1.56403 - acc: 0.6044 | val_loss: 0.68860 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1127  | total loss: \u001b[1m\u001b[32m1.63980\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1127 | loss: 1.63980 - acc: 0.5768 | val_loss: 0.68813 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1128  | total loss: \u001b[1m\u001b[32m1.67361\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1128 | loss: 1.67361 - acc: 0.5550 | val_loss: 0.68757 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1129  | total loss: \u001b[1m\u001b[32m1.60323\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1129 | loss: 1.60323 - acc: 0.5855 | val_loss: 0.68701 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1130  | total loss: \u001b[1m\u001b[32m1.62112\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1130 | loss: 1.62112 - acc: 0.5722 | val_loss: 0.68625 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: JNJF9N\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1131  | total loss: \u001b[1m\u001b[32m1.55657\u001b[0m\u001b[0m | time: 1.219s\n",
      "| Adam | epoch: 1131 | loss: 1.55657 - acc: 0.5978 | val_loss: 0.68516 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1132  | total loss: \u001b[1m\u001b[32m1.49881\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1132 | loss: 1.49881 - acc: 0.6287 | val_loss: 0.68394 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1133  | total loss: \u001b[1m\u001b[32m1.53349\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1133 | loss: 1.53349 - acc: 0.6095 | val_loss: 0.68267 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1134  | total loss: \u001b[1m\u001b[32m1.47716\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1134 | loss: 1.47716 - acc: 0.6314 | val_loss: 0.68170 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1135  | total loss: \u001b[1m\u001b[32m1.51258\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1135 | loss: 1.51258 - acc: 0.6167 | val_loss: 0.68062 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1136  | total loss: \u001b[1m\u001b[32m1.63263\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1136 | loss: 1.63263 - acc: 0.5660 | val_loss: 0.67958 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1137  | total loss: \u001b[1m\u001b[32m1.56567\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1137 | loss: 1.56567 - acc: 0.5953 | val_loss: 0.67826 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1138  | total loss: \u001b[1m\u001b[32m1.67914\u001b[0m\u001b[0m | time: 1.063s\n",
      "| Adam | epoch: 1138 | loss: 1.67914 - acc: 0.5498 | val_loss: 0.67690 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1139  | total loss: \u001b[1m\u001b[32m1.60772\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1139 | loss: 1.60772 - acc: 0.5808 | val_loss: 0.67572 - val_acc: 0.9219 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1140  | total loss: \u001b[1m\u001b[32m1.62062\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1140 | loss: 1.62062 - acc: 0.5743 | val_loss: 0.67445 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: OEJOBP\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1141  | total loss: \u001b[1m\u001b[32m1.55550\u001b[0m\u001b[0m | time: 1.209s\n",
      "| Adam | epoch: 1141 | loss: 1.55550 - acc: 0.5981 | val_loss: 0.67363 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1142  | total loss: \u001b[1m\u001b[32m1.66567\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 1142 | loss: 1.66567 - acc: 0.5539 | val_loss: 0.67270 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1143  | total loss: \u001b[1m\u001b[32m1.58854\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1143 | loss: 1.58854 - acc: 0.5907 | val_loss: 0.67165 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1144  | total loss: \u001b[1m\u001b[32m1.51849\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1144 | loss: 1.51849 - acc: 0.6191 | val_loss: 0.67081 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1145  | total loss: \u001b[1m\u001b[32m1.45736\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1145 | loss: 1.45736 - acc: 0.6494 | val_loss: 0.67020 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1146  | total loss: \u001b[1m\u001b[32m1.51356\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1146 | loss: 1.51356 - acc: 0.6298 | val_loss: 0.66928 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1147  | total loss: \u001b[1m\u001b[32m1.46084\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1147 | loss: 1.46084 - acc: 0.6496 | val_loss: 0.66862 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1148  | total loss: \u001b[1m\u001b[32m1.58679\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1148 | loss: 1.58679 - acc: 0.5925 | val_loss: 0.66783 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1149  | total loss: \u001b[1m\u001b[32m1.52795\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1149 | loss: 1.52795 - acc: 0.6145 | val_loss: 0.66755 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1150  | total loss: \u001b[1m\u001b[32m1.60710\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1150 | loss: 1.60710 - acc: 0.5796 | val_loss: 0.66725 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 0IXTXY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1151  | total loss: \u001b[1m\u001b[32m1.53900\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 1151 | loss: 1.53900 - acc: 0.6138 | val_loss: 0.66669 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1152  | total loss: \u001b[1m\u001b[32m1.48045\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1152 | loss: 1.48045 - acc: 0.6446 | val_loss: 0.66615 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1153  | total loss: \u001b[1m\u001b[32m1.42434\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1153 | loss: 1.42434 - acc: 0.6723 | val_loss: 0.66593 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1154  | total loss: \u001b[1m\u001b[32m1.56795\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1154 | loss: 1.56795 - acc: 0.6161 | val_loss: 0.66555 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1155  | total loss: \u001b[1m\u001b[32m1.50514\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1155 | loss: 1.50514 - acc: 0.6404 | val_loss: 0.66528 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1156  | total loss: \u001b[1m\u001b[32m1.59767\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1156 | loss: 1.59767 - acc: 0.6013 | val_loss: 0.66495 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1157  | total loss: \u001b[1m\u001b[32m1.53296\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1157 | loss: 1.53296 - acc: 0.6271 | val_loss: 0.66451 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1158  | total loss: \u001b[1m\u001b[32m1.55236\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1158 | loss: 1.55236 - acc: 0.6160 | val_loss: 0.66401 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1159  | total loss: \u001b[1m\u001b[32m1.48928\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1159 | loss: 1.48928 - acc: 0.6435 | val_loss: 0.66364 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1160  | total loss: \u001b[1m\u001b[32m1.52115\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1160 | loss: 1.52115 - acc: 0.6307 | val_loss: 0.66318 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: BXGVI7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1161  | total loss: \u001b[1m\u001b[32m1.45860\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 1161 | loss: 1.45860 - acc: 0.6582 | val_loss: 0.66268 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1162  | total loss: \u001b[1m\u001b[32m1.58359\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1162 | loss: 1.58359 - acc: 0.6080 | val_loss: 0.66216 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1163  | total loss: \u001b[1m\u001b[32m1.51849\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1163 | loss: 1.51849 - acc: 0.6394 | val_loss: 0.66155 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1164  | total loss: \u001b[1m\u001b[32m1.45869\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1164 | loss: 1.45869 - acc: 0.6645 | val_loss: 0.66090 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1165  | total loss: \u001b[1m\u001b[32m1.40388\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1165 | loss: 1.40388 - acc: 0.6918 | val_loss: 0.66012 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1166  | total loss: \u001b[1m\u001b[32m1.51745\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1166 | loss: 1.51745 - acc: 0.6398 | val_loss: 0.65916 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1167  | total loss: \u001b[1m\u001b[32m1.46267\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1167 | loss: 1.46267 - acc: 0.6602 | val_loss: 0.65816 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1168  | total loss: \u001b[1m\u001b[32m1.59249\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1168 | loss: 1.59249 - acc: 0.6083 | val_loss: 0.65691 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1169  | total loss: \u001b[1m\u001b[32m1.52620\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1169 | loss: 1.52620 - acc: 0.6349 | val_loss: 0.65621 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1170  | total loss: \u001b[1m\u001b[32m1.55158\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1170 | loss: 1.55158 - acc: 0.6261 | val_loss: 0.65549 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: XJ8ET6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1171  | total loss: \u001b[1m\u001b[32m1.49112\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1171 | loss: 1.49112 - acc: 0.6510 | val_loss: 0.65539 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1172  | total loss: \u001b[1m\u001b[32m1.62358\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1172 | loss: 1.62358 - acc: 0.5922 | val_loss: 0.65495 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1173  | total loss: \u001b[1m\u001b[32m1.55238\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1173 | loss: 1.55238 - acc: 0.6236 | val_loss: 0.65444 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1174  | total loss: \u001b[1m\u001b[32m1.49667\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1174 | loss: 1.49667 - acc: 0.6487 | val_loss: 0.65373 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1175  | total loss: \u001b[1m\u001b[32m1.44534\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1175 | loss: 1.44534 - acc: 0.6682 | val_loss: 0.65303 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1176  | total loss: \u001b[1m\u001b[32m1.57092\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1176 | loss: 1.57092 - acc: 0.6077 | val_loss: 0.65229 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1177  | total loss: \u001b[1m\u001b[32m1.51484\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1177 | loss: 1.51484 - acc: 0.6328 | val_loss: 0.65168 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1178  | total loss: \u001b[1m\u001b[32m1.64197\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1178 | loss: 1.64197 - acc: 0.5805 | val_loss: 0.65107 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1179  | total loss: \u001b[1m\u001b[32m1.57000\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1179 | loss: 1.57000 - acc: 0.6115 | val_loss: 0.65052 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1180  | total loss: \u001b[1m\u001b[32m1.58138\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1180 | loss: 1.58138 - acc: 0.6066 | val_loss: 0.64967 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 2HVUIG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1181  | total loss: \u001b[1m\u001b[32m1.51844\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 1181 | loss: 1.51844 - acc: 0.6350 | val_loss: 0.64943 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1182  | total loss: \u001b[1m\u001b[32m1.64642\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1182 | loss: 1.64642 - acc: 0.5809 | val_loss: 0.64933 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1183  | total loss: \u001b[1m\u001b[32m1.57785\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1183 | loss: 1.57785 - acc: 0.6056 | val_loss: 0.64916 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1184  | total loss: \u001b[1m\u001b[32m1.68083\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1184 | loss: 1.68083 - acc: 0.5607 | val_loss: 0.64905 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1185  | total loss: \u001b[1m\u001b[32m1.60393\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1185 | loss: 1.60393 - acc: 0.5968 | val_loss: 0.64872 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1186  | total loss: \u001b[1m\u001b[32m1.71531\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1186 | loss: 1.71531 - acc: 0.5465 | val_loss: 0.64820 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1187  | total loss: \u001b[1m\u001b[32m1.63500\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1187 | loss: 1.63500 - acc: 0.5809 | val_loss: 0.64739 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1188  | total loss: \u001b[1m\u001b[32m1.67325\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1188 | loss: 1.67325 - acc: 0.5650 | val_loss: 0.64643 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1189  | total loss: \u001b[1m\u001b[32m1.60237\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1189 | loss: 1.60237 - acc: 0.5944 | val_loss: 0.64582 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1190  | total loss: \u001b[1m\u001b[32m1.71011\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1190 | loss: 1.71011 - acc: 0.5444 | val_loss: 0.64515 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 1PPJ36\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1191  | total loss: \u001b[1m\u001b[32m1.63443\u001b[0m\u001b[0m | time: 1.207s\n",
      "| Adam | epoch: 1191 | loss: 1.63443 - acc: 0.5790 | val_loss: 0.64475 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1192  | total loss: \u001b[1m\u001b[32m1.65311\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1192 | loss: 1.65311 - acc: 0.5727 | val_loss: 0.64428 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1193  | total loss: \u001b[1m\u001b[32m1.57554\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1193 | loss: 1.57554 - acc: 0.6107 | val_loss: 0.64406 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1194  | total loss: \u001b[1m\u001b[32m1.62386\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1194 | loss: 1.62386 - acc: 0.5887 | val_loss: 0.64378 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1195  | total loss: \u001b[1m\u001b[32m1.55433\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 1195 | loss: 1.55433 - acc: 0.6204 | val_loss: 0.64332 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1196  | total loss: \u001b[1m\u001b[32m1.66380\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1196 | loss: 1.66380 - acc: 0.5756 | val_loss: 0.64267 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1197  | total loss: \u001b[1m\u001b[32m1.59446\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 1197 | loss: 1.59446 - acc: 0.6055 | val_loss: 0.64210 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1198  | total loss: \u001b[1m\u001b[32m1.52449\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1198 | loss: 1.52449 - acc: 0.6372 | val_loss: 0.64120 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1199  | total loss: \u001b[1m\u001b[32m1.46869\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1199 | loss: 1.46869 - acc: 0.6578 | val_loss: 0.64063 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1200  | total loss: \u001b[1m\u001b[32m1.49546\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1200 | loss: 1.49546 - acc: 0.6436 | val_loss: 0.64033 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 9VXRP1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1201  | total loss: \u001b[1m\u001b[32m1.43938\u001b[0m\u001b[0m | time: 1.219s\n",
      "| Adam | epoch: 1201 | loss: 1.43938 - acc: 0.6699 | val_loss: 0.63988 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1202  | total loss: \u001b[1m\u001b[32m1.38987\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1202 | loss: 1.38987 - acc: 0.6966 | val_loss: 0.63923 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1203  | total loss: \u001b[1m\u001b[32m1.50035\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1203 | loss: 1.50035 - acc: 0.6473 | val_loss: 0.63959 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1204  | total loss: \u001b[1m\u001b[32m1.62409\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1204 | loss: 1.62409 - acc: 0.5919 | val_loss: 0.63977 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1205  | total loss: \u001b[1m\u001b[32m1.55566\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1205 | loss: 1.55566 - acc: 0.6202 | val_loss: 0.63981 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1206  | total loss: \u001b[1m\u001b[32m1.65987\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1206 | loss: 1.65987 - acc: 0.5738 | val_loss: 0.63910 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1207  | total loss: \u001b[1m\u001b[32m1.58804\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1207 | loss: 1.58804 - acc: 0.6055 | val_loss: 0.63845 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1208  | total loss: \u001b[1m\u001b[32m1.65591\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1208 | loss: 1.65591 - acc: 0.5747 | val_loss: 0.63774 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1209  | total loss: \u001b[1m\u001b[32m1.58153\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1209 | loss: 1.58153 - acc: 0.6078 | val_loss: 0.63684 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1210  | total loss: \u001b[1m\u001b[32m1.69186\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1210 | loss: 1.69186 - acc: 0.5548 | val_loss: 0.63575 - val_acc: 0.9375 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: XSAQK5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1211  | total loss: \u001b[1m\u001b[32m1.61824\u001b[0m\u001b[0m | time: 1.224s\n",
      "| Adam | epoch: 1211 | loss: 1.61824 - acc: 0.5884 | val_loss: 0.63530 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1212  | total loss: \u001b[1m\u001b[32m1.73180\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1212 | loss: 1.73180 - acc: 0.5390 | val_loss: 0.63480 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1213  | total loss: \u001b[1m\u001b[32m1.64961\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1213 | loss: 1.64961 - acc: 0.5741 | val_loss: 0.63441 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1214  | total loss: \u001b[1m\u001b[32m1.76183\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1214 | loss: 1.76183 - acc: 0.5245 | val_loss: 0.63389 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1215  | total loss: \u001b[1m\u001b[32m1.68096\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1215 | loss: 1.68096 - acc: 0.5580 | val_loss: 0.63339 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1216  | total loss: \u001b[1m\u001b[32m1.60518\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1216 | loss: 1.60518 - acc: 0.5913 | val_loss: 0.63313 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1217  | total loss: \u001b[1m\u001b[32m1.70102\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1217 | loss: 1.70102 - acc: 0.5509 | val_loss: 0.63299 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1218  | total loss: \u001b[1m\u001b[32m1.70091\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1218 | loss: 1.70091 - acc: 0.5521 | val_loss: 0.63249 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1219  | total loss: \u001b[1m\u001b[32m1.63063\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1219 | loss: 1.63063 - acc: 0.5812 | val_loss: 0.63257 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1220  | total loss: \u001b[1m\u001b[32m1.74676\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1220 | loss: 1.74676 - acc: 0.5309 | val_loss: 0.63233 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: W6NGMJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1221  | total loss: \u001b[1m\u001b[32m1.66816\u001b[0m\u001b[0m | time: 1.218s\n",
      "| Adam | epoch: 1221 | loss: 1.66816 - acc: 0.5638 | val_loss: 0.63228 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1222  | total loss: \u001b[1m\u001b[32m1.78306\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1222 | loss: 1.78306 - acc: 0.5183 | val_loss: 0.63214 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1223  | total loss: \u001b[1m\u001b[32m1.69428\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1223 | loss: 1.69428 - acc: 0.5571 | val_loss: 0.63190 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1224  | total loss: \u001b[1m\u001b[32m1.71964\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1224 | loss: 1.71964 - acc: 0.5436 | val_loss: 0.63142 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1225  | total loss: \u001b[1m\u001b[32m1.64314\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 1225 | loss: 1.64314 - acc: 0.5752 | val_loss: 0.63113 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1226  | total loss: \u001b[1m\u001b[32m1.75697\u001b[0m\u001b[0m | time: 1.071s\n",
      "| Adam | epoch: 1226 | loss: 1.75697 - acc: 0.5208 | val_loss: 0.63064 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1227  | total loss: \u001b[1m\u001b[32m1.68163\u001b[0m\u001b[0m | time: 1.069s\n",
      "| Adam | epoch: 1227 | loss: 1.68163 - acc: 0.5562 | val_loss: 0.63011 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1228  | total loss: \u001b[1m\u001b[32m1.74569\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1228 | loss: 1.74569 - acc: 0.5318 | val_loss: 0.62936 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1229  | total loss: \u001b[1m\u001b[32m1.66462\u001b[0m\u001b[0m | time: 1.068s\n",
      "| Adam | epoch: 1229 | loss: 1.66462 - acc: 0.5693 | val_loss: 0.62902 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1230  | total loss: \u001b[1m\u001b[32m1.75948\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 1230 | loss: 1.75948 - acc: 0.5248 | val_loss: 0.62839 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: WY2YWB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1231  | total loss: \u001b[1m\u001b[32m1.67344\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1231 | loss: 1.67344 - acc: 0.5614 | val_loss: 0.62763 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1232  | total loss: \u001b[1m\u001b[32m1.59904\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1232 | loss: 1.59904 - acc: 0.5975 | val_loss: 0.62743 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1233  | total loss: \u001b[1m\u001b[32m1.73322\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1233 | loss: 1.73322 - acc: 0.5424 | val_loss: 0.62750 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1234  | total loss: \u001b[1m\u001b[32m1.84874\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1234 | loss: 1.84874 - acc: 0.4913 | val_loss: 0.62744 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1235  | total loss: \u001b[1m\u001b[32m1.75632\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1235 | loss: 1.75632 - acc: 0.5297 | val_loss: 0.62724 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1236  | total loss: \u001b[1m\u001b[32m1.66916\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1236 | loss: 1.66916 - acc: 0.5704 | val_loss: 0.62690 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1237  | total loss: \u001b[1m\u001b[32m1.59413\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1237 | loss: 1.59413 - acc: 0.6025 | val_loss: 0.62707 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1238  | total loss: \u001b[1m\u001b[32m1.70347\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1238 | loss: 1.70347 - acc: 0.5516 | val_loss: 0.62723 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1239  | total loss: \u001b[1m\u001b[32m1.62755\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1239 | loss: 1.62755 - acc: 0.5902 | val_loss: 0.62742 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1240  | total loss: \u001b[1m\u001b[32m1.62444\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1240 | loss: 1.62444 - acc: 0.5937 | val_loss: 0.62750 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 2JWTF3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1241  | total loss: \u001b[1m\u001b[32m1.55425\u001b[0m\u001b[0m | time: 1.206s\n",
      "| Adam | epoch: 1241 | loss: 1.55425 - acc: 0.6249 | val_loss: 0.62784 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1242  | total loss: \u001b[1m\u001b[32m1.66120\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1242 | loss: 1.66120 - acc: 0.5781 | val_loss: 0.62805 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1243  | total loss: \u001b[1m\u001b[32m1.58610\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1243 | loss: 1.58610 - acc: 0.6109 | val_loss: 0.62810 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1244  | total loss: \u001b[1m\u001b[32m1.70303\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1244 | loss: 1.70303 - acc: 0.5576 | val_loss: 0.62761 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1245  | total loss: \u001b[1m\u001b[32m1.62644\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1245 | loss: 1.62644 - acc: 0.5909 | val_loss: 0.62789 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1246  | total loss: \u001b[1m\u001b[32m1.74502\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1246 | loss: 1.74502 - acc: 0.5365 | val_loss: 0.62758 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1247  | total loss: \u001b[1m\u001b[32m1.66252\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1247 | loss: 1.66252 - acc: 0.5750 | val_loss: 0.62749 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1248  | total loss: \u001b[1m\u001b[32m1.77374\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1248 | loss: 1.77374 - acc: 0.5238 | val_loss: 0.62718 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1249  | total loss: \u001b[1m\u001b[32m1.69282\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1249 | loss: 1.69282 - acc: 0.5589 | val_loss: 0.62676 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1250  | total loss: \u001b[1m\u001b[32m1.78441\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1250 | loss: 1.78441 - acc: 0.5202 | val_loss: 0.62605 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 4A4FQO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1251  | total loss: \u001b[1m\u001b[32m1.69634\u001b[0m\u001b[0m | time: 1.218s\n",
      "| Adam | epoch: 1251 | loss: 1.69634 - acc: 0.5572 | val_loss: 0.62554 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1252  | total loss: \u001b[1m\u001b[32m1.79722\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1252 | loss: 1.79722 - acc: 0.5109 | val_loss: 0.62495 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1253  | total loss: \u001b[1m\u001b[32m1.71143\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1253 | loss: 1.71143 - acc: 0.5504 | val_loss: 0.62414 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1254  | total loss: \u001b[1m\u001b[32m1.63317\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1254 | loss: 1.63317 - acc: 0.5813 | val_loss: 0.62298 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1255  | total loss: \u001b[1m\u001b[32m1.56194\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1255 | loss: 1.56194 - acc: 0.6107 | val_loss: 0.62200 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1256  | total loss: \u001b[1m\u001b[32m1.50090\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1256 | loss: 1.50090 - acc: 0.6324 | val_loss: 0.62142 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1257  | total loss: \u001b[1m\u001b[32m1.62593\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1257 | loss: 1.62593 - acc: 0.5801 | val_loss: 0.62147 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1258  | total loss: \u001b[1m\u001b[32m1.72784\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1258 | loss: 1.72784 - acc: 0.5362 | val_loss: 0.62155 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1259  | total loss: \u001b[1m\u001b[32m1.64760\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1259 | loss: 1.64760 - acc: 0.5716 | val_loss: 0.62153 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1260  | total loss: \u001b[1m\u001b[32m1.64636\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1260 | loss: 1.64636 - acc: 0.5723 | val_loss: 0.62134 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: JZNG8O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1261  | total loss: \u001b[1m\u001b[32m1.56724\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 1261 | loss: 1.56724 - acc: 0.6104 | val_loss: 0.62146 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1262  | total loss: \u001b[1m\u001b[32m1.67950\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1262 | loss: 1.67950 - acc: 0.5618 | val_loss: 0.62145 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1263  | total loss: \u001b[1m\u001b[32m1.60091\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1263 | loss: 1.60091 - acc: 0.5978 | val_loss: 0.62136 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1264  | total loss: \u001b[1m\u001b[32m1.53186\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1264 | loss: 1.53186 - acc: 0.6287 | val_loss: 0.62090 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1265  | total loss: \u001b[1m\u001b[32m1.46970\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1265 | loss: 1.46970 - acc: 0.6580 | val_loss: 0.62048 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1266  | total loss: \u001b[1m\u001b[32m1.40879\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1266 | loss: 1.40879 - acc: 0.6859 | val_loss: 0.62079 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1267  | total loss: \u001b[1m\u001b[32m1.54056\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1267 | loss: 1.54056 - acc: 0.6298 | val_loss: 0.62134 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1268  | total loss: \u001b[1m\u001b[32m1.62053\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1268 | loss: 1.62053 - acc: 0.5950 | val_loss: 0.62149 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1269  | total loss: \u001b[1m\u001b[32m1.54787\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1269 | loss: 1.54787 - acc: 0.6277 | val_loss: 0.62222 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1270  | total loss: \u001b[1m\u001b[32m1.66118\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1270 | loss: 1.66118 - acc: 0.5774 | val_loss: 0.62252 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 64MY3R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1271  | total loss: \u001b[1m\u001b[32m1.59088\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1271 | loss: 1.59088 - acc: 0.6103 | val_loss: 0.62287 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1272  | total loss: \u001b[1m\u001b[32m1.70257\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1272 | loss: 1.70257 - acc: 0.5571 | val_loss: 0.62231 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1273  | total loss: \u001b[1m\u001b[32m1.62655\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1273 | loss: 1.62655 - acc: 0.5920 | val_loss: 0.62198 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1274  | total loss: \u001b[1m\u001b[32m1.73351\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1274 | loss: 1.73351 - acc: 0.5453 | val_loss: 0.62147 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1275  | total loss: \u001b[1m\u001b[32m1.65594\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1275 | loss: 1.65594 - acc: 0.5798 | val_loss: 0.62093 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1276  | total loss: \u001b[1m\u001b[32m1.58408\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1276 | loss: 1.58408 - acc: 0.6093 | val_loss: 0.61953 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1277  | total loss: \u001b[1m\u001b[32m1.52234\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1277 | loss: 1.52234 - acc: 0.6312 | val_loss: 0.61854 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1278  | total loss: \u001b[1m\u001b[32m1.61881\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1278 | loss: 1.61881 - acc: 0.5915 | val_loss: 0.61692 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1279  | total loss: \u001b[1m\u001b[32m1.54610\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1279 | loss: 1.54610 - acc: 0.6230 | val_loss: 0.61531 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1280  | total loss: \u001b[1m\u001b[32m1.62614\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1280 | loss: 1.62614 - acc: 0.5873 | val_loss: 0.61348 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: MTGV4S\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1281  | total loss: \u001b[1m\u001b[32m1.55412\u001b[0m\u001b[0m | time: 1.212s\n",
      "| Adam | epoch: 1281 | loss: 1.55412 - acc: 0.6176 | val_loss: 0.61139 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1282  | total loss: \u001b[1m\u001b[32m1.48500\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1282 | loss: 1.48500 - acc: 0.6480 | val_loss: 0.60931 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1283  | total loss: \u001b[1m\u001b[32m1.43129\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1283 | loss: 1.43129 - acc: 0.6739 | val_loss: 0.60724 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1284  | total loss: \u001b[1m\u001b[32m1.37591\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1284 | loss: 1.37591 - acc: 0.7018 | val_loss: 0.60529 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1285  | total loss: \u001b[1m\u001b[32m1.33013\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1285 | loss: 1.33013 - acc: 0.7222 | val_loss: 0.60362 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1286  | total loss: \u001b[1m\u001b[32m1.46059\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1286 | loss: 1.46059 - acc: 0.6656 | val_loss: 0.60208 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1287  | total loss: \u001b[1m\u001b[32m1.40239\u001b[0m\u001b[0m | time: 1.070s\n",
      "| Adam | epoch: 1287 | loss: 1.40239 - acc: 0.6959 | val_loss: 0.60066 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1288  | total loss: \u001b[1m\u001b[32m1.44043\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1288 | loss: 1.44043 - acc: 0.6779 | val_loss: 0.59941 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1289  | total loss: \u001b[1m\u001b[32m1.38532\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1289 | loss: 1.38532 - acc: 0.7039 | val_loss: 0.59842 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1290  | total loss: \u001b[1m\u001b[32m1.41615\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1290 | loss: 1.41615 - acc: 0.6929 | val_loss: 0.59719 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: TMK86W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1291  | total loss: \u001b[1m\u001b[32m1.36459\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 1291 | loss: 1.36459 - acc: 0.7158 | val_loss: 0.59618 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1292  | total loss: \u001b[1m\u001b[32m1.31676\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1292 | loss: 1.31676 - acc: 0.7332 | val_loss: 0.59533 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1293  | total loss: \u001b[1m\u001b[32m1.45347\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1293 | loss: 1.45347 - acc: 0.6724 | val_loss: 0.59444 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1294  | total loss: \u001b[1m\u001b[32m1.51251\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1294 | loss: 1.51251 - acc: 0.6489 | val_loss: 0.59353 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1295  | total loss: \u001b[1m\u001b[32m1.44604\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1295 | loss: 1.44604 - acc: 0.6793 | val_loss: 0.59270 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1296  | total loss: \u001b[1m\u001b[32m1.57806\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1296 | loss: 1.57806 - acc: 0.6224 | val_loss: 0.59204 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1297  | total loss: \u001b[1m\u001b[32m1.50666\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1297 | loss: 1.50666 - acc: 0.6523 | val_loss: 0.59095 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1298  | total loss: \u001b[1m\u001b[32m1.62768\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1298 | loss: 1.62768 - acc: 0.5949 | val_loss: 0.58982 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1299  | total loss: \u001b[1m\u001b[32m1.55183\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1299 | loss: 1.55183 - acc: 0.6260 | val_loss: 0.58870 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1300  | total loss: \u001b[1m\u001b[32m1.57840\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1300 | loss: 1.57840 - acc: 0.6087 | val_loss: 0.58787 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 3MLCZ1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1301  | total loss: \u001b[1m\u001b[32m1.50985\u001b[0m\u001b[0m | time: 1.207s\n",
      "| Adam | epoch: 1301 | loss: 1.50985 - acc: 0.6400 | val_loss: 0.58692 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1302  | total loss: \u001b[1m\u001b[32m1.62253\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1302 | loss: 1.62253 - acc: 0.5901 | val_loss: 0.58606 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1303  | total loss: \u001b[1m\u001b[32m1.54962\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1303 | loss: 1.54962 - acc: 0.6233 | val_loss: 0.58518 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1304  | total loss: \u001b[1m\u001b[32m1.67758\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1304 | loss: 1.67758 - acc: 0.5688 | val_loss: 0.58414 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1305  | total loss: \u001b[1m\u001b[32m1.59793\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1305 | loss: 1.59793 - acc: 0.6010 | val_loss: 0.58310 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1306  | total loss: \u001b[1m\u001b[32m1.52356\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1306 | loss: 1.52356 - acc: 0.6362 | val_loss: 0.58255 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1307  | total loss: \u001b[1m\u001b[32m1.63859\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1307 | loss: 1.63859 - acc: 0.5835 | val_loss: 0.58200 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1308  | total loss: \u001b[1m\u001b[32m1.56175\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1308 | loss: 1.56175 - acc: 0.6205 | val_loss: 0.58159 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1309  | total loss: \u001b[1m\u001b[32m1.61608\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1309 | loss: 1.61608 - acc: 0.6006 | val_loss: 0.58167 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1310  | total loss: \u001b[1m\u001b[32m1.70274\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1310 | loss: 1.70274 - acc: 0.5655 | val_loss: 0.58149 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 3QS60K\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1311  | total loss: \u001b[1m\u001b[32m1.61741\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 1311 | loss: 1.61741 - acc: 0.6027 | val_loss: 0.58234 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1312  | total loss: \u001b[1m\u001b[32m1.73300\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1312 | loss: 1.73300 - acc: 0.5503 | val_loss: 0.58319 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1313  | total loss: \u001b[1m\u001b[32m1.64833\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1313 | loss: 1.64833 - acc: 0.5906 | val_loss: 0.58358 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1314  | total loss: \u001b[1m\u001b[32m1.65568\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1314 | loss: 1.65568 - acc: 0.5831 | val_loss: 0.58384 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1315  | total loss: \u001b[1m\u001b[32m1.57649\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1315 | loss: 1.57649 - acc: 0.6169 | val_loss: 0.58424 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1316  | total loss: \u001b[1m\u001b[32m1.50466\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1316 | loss: 1.50466 - acc: 0.6474 | val_loss: 0.58489 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1317  | total loss: \u001b[1m\u001b[32m1.62521\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1317 | loss: 1.62521 - acc: 0.5921 | val_loss: 0.58540 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1318  | total loss: \u001b[1m\u001b[32m1.73603\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1318 | loss: 1.73603 - acc: 0.5454 | val_loss: 0.58541 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1319  | total loss: \u001b[1m\u001b[32m1.65658\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1319 | loss: 1.65658 - acc: 0.5815 | val_loss: 0.58524 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1320  | total loss: \u001b[1m\u001b[32m1.77318\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1320 | loss: 1.77318 - acc: 0.5280 | val_loss: 0.58487 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: F9J665\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1321  | total loss: \u001b[1m\u001b[32m1.68372\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 1321 | loss: 1.68372 - acc: 0.5658 | val_loss: 0.58423 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1322  | total loss: \u001b[1m\u001b[32m1.61011\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1322 | loss: 1.61011 - acc: 0.5983 | val_loss: 0.58319 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1323  | total loss: \u001b[1m\u001b[32m1.53449\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1323 | loss: 1.53449 - acc: 0.6307 | val_loss: 0.58229 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1324  | total loss: \u001b[1m\u001b[32m1.52463\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1324 | loss: 1.52463 - acc: 0.6379 | val_loss: 0.58104 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1325  | total loss: \u001b[1m\u001b[32m1.45882\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1325 | loss: 1.45882 - acc: 0.6616 | val_loss: 0.57961 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1326  | total loss: \u001b[1m\u001b[32m1.40507\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1326 | loss: 1.40507 - acc: 0.6845 | val_loss: 0.57802 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1327  | total loss: \u001b[1m\u001b[32m1.35220\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1327 | loss: 1.35220 - acc: 0.7067 | val_loss: 0.57724 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1328  | total loss: \u001b[1m\u001b[32m1.50318\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1328 | loss: 1.50318 - acc: 0.6407 | val_loss: 0.57621 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1329  | total loss: \u001b[1m\u001b[32m1.44201\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1329 | loss: 1.44201 - acc: 0.6657 | val_loss: 0.57590 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1330  | total loss: \u001b[1m\u001b[32m1.57001\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1330 | loss: 1.57001 - acc: 0.6054 | val_loss: 0.57542 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: SNFDNZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1331  | total loss: \u001b[1m\u001b[32m1.49979\u001b[0m\u001b[0m | time: 1.221s\n",
      "| Adam | epoch: 1331 | loss: 1.49979 - acc: 0.6386 | val_loss: 0.57488 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1332  | total loss: \u001b[1m\u001b[32m1.53458\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1332 | loss: 1.53458 - acc: 0.6247 | val_loss: 0.57403 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1333  | total loss: \u001b[1m\u001b[32m1.46557\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 1333 | loss: 1.46557 - acc: 0.6544 | val_loss: 0.57293 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1334  | total loss: \u001b[1m\u001b[32m1.51567\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1334 | loss: 1.51567 - acc: 0.6343 | val_loss: 0.57174 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1335  | total loss: \u001b[1m\u001b[32m1.45257\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1335 | loss: 1.45257 - acc: 0.6599 | val_loss: 0.57098 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1336  | total loss: \u001b[1m\u001b[32m1.48774\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1336 | loss: 1.48774 - acc: 0.6486 | val_loss: 0.57029 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1337  | total loss: \u001b[1m\u001b[32m1.42668\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1337 | loss: 1.42668 - acc: 0.6791 | val_loss: 0.56971 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1338  | total loss: \u001b[1m\u001b[32m1.54333\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1338 | loss: 1.54333 - acc: 0.6268 | val_loss: 0.56891 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1339  | total loss: \u001b[1m\u001b[32m1.47437\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1339 | loss: 1.47437 - acc: 0.6547 | val_loss: 0.56841 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1340  | total loss: \u001b[1m\u001b[32m1.50392\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1340 | loss: 1.50392 - acc: 0.6455 | val_loss: 0.56767 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: GQ4MYX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1341  | total loss: \u001b[1m\u001b[32m1.44270\u001b[0m\u001b[0m | time: 1.223s\n",
      "| Adam | epoch: 1341 | loss: 1.44270 - acc: 0.6747 | val_loss: 0.56686 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1342  | total loss: \u001b[1m\u001b[32m1.39034\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1342 | loss: 1.39034 - acc: 0.6932 | val_loss: 0.56604 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1343  | total loss: \u001b[1m\u001b[32m1.33727\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1343 | loss: 1.33727 - acc: 0.7161 | val_loss: 0.56535 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1344  | total loss: \u001b[1m\u001b[32m1.49050\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1344 | loss: 1.49050 - acc: 0.6476 | val_loss: 0.56470 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1345  | total loss: \u001b[1m\u001b[32m1.43260\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1345 | loss: 1.43260 - acc: 0.6734 | val_loss: 0.56404 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1346  | total loss: \u001b[1m\u001b[32m1.56032\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1346 | loss: 1.56032 - acc: 0.6155 | val_loss: 0.56360 - val_acc: 0.9531 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1347  | total loss: \u001b[1m\u001b[32m1.49051\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1347 | loss: 1.49051 - acc: 0.6446 | val_loss: 0.56312 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1348  | total loss: \u001b[1m\u001b[32m1.60016\u001b[0m\u001b[0m | time: 1.063s\n",
      "| Adam | epoch: 1348 | loss: 1.60016 - acc: 0.5973 | val_loss: 0.56264 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1349  | total loss: \u001b[1m\u001b[32m1.52659\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1349 | loss: 1.52659 - acc: 0.6297 | val_loss: 0.56209 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1350  | total loss: \u001b[1m\u001b[32m1.54290\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1350 | loss: 1.54290 - acc: 0.6168 | val_loss: 0.56148 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 85LBI6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1351  | total loss: \u001b[1m\u001b[32m1.47244\u001b[0m\u001b[0m | time: 1.221s\n",
      "| Adam | epoch: 1351 | loss: 1.47244 - acc: 0.6473 | val_loss: 0.56136 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1352  | total loss: \u001b[1m\u001b[32m1.60746\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1352 | loss: 1.60746 - acc: 0.5919 | val_loss: 0.56133 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1353  | total loss: \u001b[1m\u001b[32m1.52970\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1353 | loss: 1.52970 - acc: 0.6265 | val_loss: 0.56122 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1354  | total loss: \u001b[1m\u001b[32m1.63515\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1354 | loss: 1.63515 - acc: 0.5826 | val_loss: 0.56096 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1355  | total loss: \u001b[1m\u001b[32m1.55660\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1355 | loss: 1.55660 - acc: 0.6165 | val_loss: 0.56094 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1356  | total loss: \u001b[1m\u001b[32m1.48532\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1356 | loss: 1.48532 - acc: 0.6502 | val_loss: 0.56096 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1357  | total loss: \u001b[1m\u001b[32m1.61389\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1357 | loss: 1.61389 - acc: 0.5961 | val_loss: 0.56107 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1358  | total loss: \u001b[1m\u001b[32m1.63948\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1358 | loss: 1.63948 - acc: 0.5834 | val_loss: 0.56131 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1359  | total loss: \u001b[1m\u001b[32m1.55687\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1359 | loss: 1.55687 - acc: 0.6188 | val_loss: 0.56130 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1360  | total loss: \u001b[1m\u001b[32m1.65403\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1360 | loss: 1.65403 - acc: 0.5756 | val_loss: 0.56134 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: XZJFP0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1361  | total loss: \u001b[1m\u001b[32m1.57486\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1361 | loss: 1.57486 - acc: 0.6087 | val_loss: 0.56094 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1362  | total loss: \u001b[1m\u001b[32m1.49842\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1362 | loss: 1.49842 - acc: 0.6431 | val_loss: 0.55995 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1363  | total loss: \u001b[1m\u001b[32m1.43859\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1363 | loss: 1.43859 - acc: 0.6663 | val_loss: 0.55870 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1364  | total loss: \u001b[1m\u001b[32m1.38049\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1364 | loss: 1.38049 - acc: 0.6950 | val_loss: 0.55747 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1365  | total loss: \u001b[1m\u001b[32m1.39733\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1365 | loss: 1.39733 - acc: 0.6818 | val_loss: 0.55652 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1366  | total loss: \u001b[1m\u001b[32m1.38505\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1366 | loss: 1.38505 - acc: 0.6870 | val_loss: 0.55552 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1367  | total loss: \u001b[1m\u001b[32m1.33486\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1367 | loss: 1.33486 - acc: 0.7089 | val_loss: 0.55442 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1368  | total loss: \u001b[1m\u001b[32m1.38340\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1368 | loss: 1.38340 - acc: 0.6849 | val_loss: 0.55340 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1369  | total loss: \u001b[1m\u001b[32m1.33453\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1369 | loss: 1.33453 - acc: 0.7071 | val_loss: 0.55259 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1370  | total loss: \u001b[1m\u001b[32m1.37927\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1370 | loss: 1.37927 - acc: 0.6879 | val_loss: 0.55182 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: MTRETA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1371  | total loss: \u001b[1m\u001b[32m1.32747\u001b[0m\u001b[0m | time: 1.212s\n",
      "| Adam | epoch: 1371 | loss: 1.32747 - acc: 0.7160 | val_loss: 0.55091 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1372  | total loss: \u001b[1m\u001b[32m1.27993\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1372 | loss: 1.27993 - acc: 0.7335 | val_loss: 0.54989 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1373  | total loss: \u001b[1m\u001b[32m1.42366\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1373 | loss: 1.42366 - acc: 0.6679 | val_loss: 0.54882 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1374  | total loss: \u001b[1m\u001b[32m1.54755\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1374 | loss: 1.54755 - acc: 0.6105 | val_loss: 0.54770 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1375  | total loss: \u001b[1m\u001b[32m1.47969\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1375 | loss: 1.47969 - acc: 0.6370 | val_loss: 0.54682 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1376  | total loss: \u001b[1m\u001b[32m1.41915\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1376 | loss: 1.41915 - acc: 0.6623 | val_loss: 0.54563 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1377  | total loss: \u001b[1m\u001b[32m1.53299\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1377 | loss: 1.53299 - acc: 0.6180 | val_loss: 0.54456 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1378  | total loss: \u001b[1m\u001b[32m1.57366\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1378 | loss: 1.57366 - acc: 0.6046 | val_loss: 0.54345 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1379  | total loss: \u001b[1m\u001b[32m1.50046\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1379 | loss: 1.50046 - acc: 0.6332 | val_loss: 0.54257 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1380  | total loss: \u001b[1m\u001b[32m1.52359\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1380 | loss: 1.52359 - acc: 0.6215 | val_loss: 0.54181 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: E01DGH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1381  | total loss: \u001b[1m\u001b[32m1.45775\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 1381 | loss: 1.45775 - acc: 0.6531 | val_loss: 0.54116 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1382  | total loss: \u001b[1m\u001b[32m1.39372\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1382 | loss: 1.39372 - acc: 0.6831 | val_loss: 0.54050 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1383  | total loss: \u001b[1m\u001b[32m1.34892\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1383 | loss: 1.34892 - acc: 0.7054 | val_loss: 0.53990 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1384  | total loss: \u001b[1m\u001b[32m1.50625\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1384 | loss: 1.50625 - acc: 0.6442 | val_loss: 0.53924 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1385  | total loss: \u001b[1m\u001b[32m1.43929\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1385 | loss: 1.43929 - acc: 0.6735 | val_loss: 0.53871 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1386  | total loss: \u001b[1m\u001b[32m1.57453\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1386 | loss: 1.57453 - acc: 0.6140 | val_loss: 0.53820 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1387  | total loss: \u001b[1m\u001b[32m1.50262\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1387 | loss: 1.50262 - acc: 0.6417 | val_loss: 0.53788 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1388  | total loss: \u001b[1m\u001b[32m1.51360\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1388 | loss: 1.51360 - acc: 0.6369 | val_loss: 0.53738 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1389  | total loss: \u001b[1m\u001b[32m1.44576\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1389 | loss: 1.44576 - acc: 0.6638 | val_loss: 0.53676 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1390  | total loss: \u001b[1m\u001b[32m1.46574\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1390 | loss: 1.46574 - acc: 0.6615 | val_loss: 0.53576 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: C3JXMM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1391  | total loss: \u001b[1m\u001b[32m1.40502\u001b[0m\u001b[0m | time: 1.214s\n",
      "| Adam | epoch: 1391 | loss: 1.40502 - acc: 0.6828 | val_loss: 0.53464 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1392  | total loss: \u001b[1m\u001b[32m1.54416\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1392 | loss: 1.54416 - acc: 0.6255 | val_loss: 0.53354 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1393  | total loss: \u001b[1m\u001b[32m1.47349\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1393 | loss: 1.47349 - acc: 0.6567 | val_loss: 0.53271 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1394  | total loss: \u001b[1m\u001b[32m1.59706\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1394 | loss: 1.59706 - acc: 0.6020 | val_loss: 0.53186 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1395  | total loss: \u001b[1m\u001b[32m1.52076\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1395 | loss: 1.52076 - acc: 0.6308 | val_loss: 0.53125 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1396  | total loss: \u001b[1m\u001b[32m1.65584\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1396 | loss: 1.65584 - acc: 0.5724 | val_loss: 0.53037 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1397  | total loss: \u001b[1m\u001b[32m1.57883\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1397 | loss: 1.57883 - acc: 0.6043 | val_loss: 0.52929 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1398  | total loss: \u001b[1m\u001b[32m1.64844\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1398 | loss: 1.64844 - acc: 0.5704 | val_loss: 0.52820 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1399  | total loss: \u001b[1m\u001b[32m1.56845\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1399 | loss: 1.56845 - acc: 0.6024 | val_loss: 0.52681 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1400  | total loss: \u001b[1m\u001b[32m1.69462\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1400 | loss: 1.69462 - acc: 0.5484 | val_loss: 0.52569 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: GCC5AK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1401  | total loss: \u001b[1m\u001b[32m1.61042\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1401 | loss: 1.61042 - acc: 0.5858 | val_loss: 0.52487 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1402  | total loss: \u001b[1m\u001b[32m1.70722\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 1402 | loss: 1.70722 - acc: 0.5459 | val_loss: 0.52414 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1403  | total loss: \u001b[1m\u001b[32m1.62189\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1403 | loss: 1.62189 - acc: 0.5820 | val_loss: 0.52358 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1404  | total loss: \u001b[1m\u001b[32m1.74459\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1404 | loss: 1.74459 - acc: 0.5300 | val_loss: 0.52322 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1405  | total loss: \u001b[1m\u001b[32m1.65268\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1405 | loss: 1.65268 - acc: 0.5692 | val_loss: 0.52312 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1406  | total loss: \u001b[1m\u001b[32m1.67191\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1406 | loss: 1.67191 - acc: 0.5592 | val_loss: 0.52293 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1407  | total loss: \u001b[1m\u001b[32m1.59212\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1407 | loss: 1.59212 - acc: 0.5923 | val_loss: 0.52272 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1408  | total loss: \u001b[1m\u001b[32m1.64630\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1408 | loss: 1.64630 - acc: 0.5737 | val_loss: 0.52278 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1409  | total loss: \u001b[1m\u001b[32m1.56493\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1409 | loss: 1.56493 - acc: 0.6132 | val_loss: 0.52288 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1410  | total loss: \u001b[1m\u001b[32m1.66579\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1410 | loss: 1.66579 - acc: 0.5691 | val_loss: 0.52304 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: RW338Y\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1411  | total loss: \u001b[1m\u001b[32m1.58403\u001b[0m\u001b[0m | time: 1.212s\n",
      "| Adam | epoch: 1411 | loss: 1.58403 - acc: 0.6044 | val_loss: 0.52321 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1412  | total loss: \u001b[1m\u001b[32m1.50592\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1412 | loss: 1.50592 - acc: 0.6408 | val_loss: 0.52291 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1413  | total loss: \u001b[1m\u001b[32m1.56454\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1413 | loss: 1.56454 - acc: 0.6158 | val_loss: 0.52322 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1414  | total loss: \u001b[1m\u001b[32m1.68384\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1414 | loss: 1.68384 - acc: 0.5620 | val_loss: 0.52354 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1415  | total loss: \u001b[1m\u001b[32m1.60038\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1415 | loss: 1.60038 - acc: 0.5964 | val_loss: 0.52420 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1416  | total loss: \u001b[1m\u001b[32m1.72162\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1416 | loss: 1.72162 - acc: 0.5462 | val_loss: 0.52460 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1417  | total loss: \u001b[1m\u001b[32m1.63512\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1417 | loss: 1.63512 - acc: 0.5869 | val_loss: 0.52504 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1418  | total loss: \u001b[1m\u001b[32m1.72156\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1418 | loss: 1.72156 - acc: 0.5501 | val_loss: 0.52503 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1419  | total loss: \u001b[1m\u001b[32m1.63563\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1419 | loss: 1.63563 - acc: 0.5841 | val_loss: 0.52538 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1420  | total loss: \u001b[1m\u001b[32m1.76244\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1420 | loss: 1.76244 - acc: 0.5304 | val_loss: 0.52540 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: IVU6B4\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1421  | total loss: \u001b[1m\u001b[32m1.67714\u001b[0m\u001b[0m | time: 1.210s\n",
      "| Adam | epoch: 1421 | loss: 1.67714 - acc: 0.5680 | val_loss: 0.52545 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1422  | total loss: \u001b[1m\u001b[32m1.59587\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1422 | loss: 1.59587 - acc: 0.6018 | val_loss: 0.52604 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1423  | total loss: \u001b[1m\u001b[32m1.68802\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1423 | loss: 1.68802 - acc: 0.5635 | val_loss: 0.52638 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1424  | total loss: \u001b[1m\u001b[32m1.70153\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1424 | loss: 1.70153 - acc: 0.5587 | val_loss: 0.52702 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1425  | total loss: \u001b[1m\u001b[32m1.61539\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1425 | loss: 1.61539 - acc: 0.5981 | val_loss: 0.52728 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1426  | total loss: \u001b[1m\u001b[32m1.53781\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1426 | loss: 1.53781 - acc: 0.6321 | val_loss: 0.52733 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1427  | total loss: \u001b[1m\u001b[32m1.47076\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 1427 | loss: 1.47076 - acc: 0.6642 | val_loss: 0.52751 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1428  | total loss: \u001b[1m\u001b[32m1.58778\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1428 | loss: 1.58778 - acc: 0.6103 | val_loss: 0.52741 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1429  | total loss: \u001b[1m\u001b[32m1.51545\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1429 | loss: 1.51545 - acc: 0.6399 | val_loss: 0.52735 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1430  | total loss: \u001b[1m\u001b[32m1.56315\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1430 | loss: 1.56315 - acc: 0.6165 | val_loss: 0.52746 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: ZUS157\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1431  | total loss: \u001b[1m\u001b[32m1.48632\u001b[0m\u001b[0m | time: 1.214s\n",
      "| Adam | epoch: 1431 | loss: 1.48632 - acc: 0.6470 | val_loss: 0.52721 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1432  | total loss: \u001b[1m\u001b[32m1.43254\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1432 | loss: 1.43254 - acc: 0.6730 | val_loss: 0.52671 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1433  | total loss: \u001b[1m\u001b[32m1.57362\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1433 | loss: 1.57362 - acc: 0.6104 | val_loss: 0.52611 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1434  | total loss: \u001b[1m\u001b[32m1.49717\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1434 | loss: 1.49717 - acc: 0.6462 | val_loss: 0.52563 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1435  | total loss: \u001b[1m\u001b[32m1.50665\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1435 | loss: 1.50665 - acc: 0.6441 | val_loss: 0.52489 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1436  | total loss: \u001b[1m\u001b[32m1.44520\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1436 | loss: 1.44520 - acc: 0.6734 | val_loss: 0.52392 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1437  | total loss: \u001b[1m\u001b[32m1.38580\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1437 | loss: 1.38580 - acc: 0.6967 | val_loss: 0.52356 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1438  | total loss: \u001b[1m\u001b[32m1.49334\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1438 | loss: 1.49334 - acc: 0.6505 | val_loss: 0.52368 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1439  | total loss: \u001b[1m\u001b[32m1.42836\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1439 | loss: 1.42836 - acc: 0.6792 | val_loss: 0.52398 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1440  | total loss: \u001b[1m\u001b[32m1.46747\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1440 | loss: 1.46747 - acc: 0.6644 | val_loss: 0.52392 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 6FKFOG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1441  | total loss: \u001b[1m\u001b[32m1.40206\u001b[0m\u001b[0m | time: 1.219s\n",
      "| Adam | epoch: 1441 | loss: 1.40206 - acc: 0.6917 | val_loss: 0.52360 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1442  | total loss: \u001b[1m\u001b[32m1.34397\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1442 | loss: 1.34397 - acc: 0.7147 | val_loss: 0.52334 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1443  | total loss: \u001b[1m\u001b[32m1.29355\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1443 | loss: 1.29355 - acc: 0.7386 | val_loss: 0.52262 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1444  | total loss: \u001b[1m\u001b[32m1.24689\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1444 | loss: 1.24689 - acc: 0.7538 | val_loss: 0.52129 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1445  | total loss: \u001b[1m\u001b[32m1.20677\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1445 | loss: 1.20677 - acc: 0.7690 | val_loss: 0.52056 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1446  | total loss: \u001b[1m\u001b[32m1.36279\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1446 | loss: 1.36279 - acc: 0.7030 | val_loss: 0.51994 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1447  | total loss: \u001b[1m\u001b[32m1.31052\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1447 | loss: 1.31052 - acc: 0.7249 | val_loss: 0.51927 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1448  | total loss: \u001b[1m\u001b[32m1.44374\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1448 | loss: 1.44374 - acc: 0.6727 | val_loss: 0.51866 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1449  | total loss: \u001b[1m\u001b[32m1.38340\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1449 | loss: 1.38340 - acc: 0.7008 | val_loss: 0.51846 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1450  | total loss: \u001b[1m\u001b[32m1.53008\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1450 | loss: 1.53008 - acc: 0.6416 | val_loss: 0.51821 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 67P0HT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1451  | total loss: \u001b[1m\u001b[32m1.45680\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1451 | loss: 1.45680 - acc: 0.6712 | val_loss: 0.51840 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1452  | total loss: \u001b[1m\u001b[32m1.60214\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1452 | loss: 1.60214 - acc: 0.6135 | val_loss: 0.51868 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1453  | total loss: \u001b[1m\u001b[32m1.52216\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1453 | loss: 1.52216 - acc: 0.6443 | val_loss: 0.51919 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1454  | total loss: \u001b[1m\u001b[32m1.64766\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1454 | loss: 1.64766 - acc: 0.5924 | val_loss: 0.51961 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1455  | total loss: \u001b[1m\u001b[32m1.55900\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1455 | loss: 1.55900 - acc: 0.6316 | val_loss: 0.51983 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1456  | total loss: \u001b[1m\u001b[32m1.48482\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1456 | loss: 1.48482 - acc: 0.6575 | val_loss: 0.52020 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1457  | total loss: \u001b[1m\u001b[32m1.42236\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1457 | loss: 1.42236 - acc: 0.6808 | val_loss: 0.52002 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1458  | total loss: \u001b[1m\u001b[32m1.55557\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1458 | loss: 1.55557 - acc: 0.6205 | val_loss: 0.51925 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1459  | total loss: \u001b[1m\u001b[32m1.48629\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1459 | loss: 1.48629 - acc: 0.6538 | val_loss: 0.51774 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1460  | total loss: \u001b[1m\u001b[32m1.51797\u001b[0m\u001b[0m | time: 1.076s\n",
      "| Adam | epoch: 1460 | loss: 1.51797 - acc: 0.6431 | val_loss: 0.51629 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: VKTP9E\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1461  | total loss: \u001b[1m\u001b[32m1.44348\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1461 | loss: 1.44348 - acc: 0.6772 | val_loss: 0.51571 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1462  | total loss: \u001b[1m\u001b[32m1.56425\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1462 | loss: 1.56425 - acc: 0.6283 | val_loss: 0.51505 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1463  | total loss: \u001b[1m\u001b[32m1.48581\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1463 | loss: 1.48581 - acc: 0.6623 | val_loss: 0.51518 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1464  | total loss: \u001b[1m\u001b[32m1.52145\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1464 | loss: 1.52145 - acc: 0.6445 | val_loss: 0.51412 - val_acc: 0.9688 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1465  | total loss: \u001b[1m\u001b[32m1.45327\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1465 | loss: 1.45327 - acc: 0.6707 | val_loss: 0.51259 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1466  | total loss: \u001b[1m\u001b[32m1.54811\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1466 | loss: 1.54811 - acc: 0.6271 | val_loss: 0.51118 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1467  | total loss: \u001b[1m\u001b[32m1.47478\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1467 | loss: 1.47478 - acc: 0.6581 | val_loss: 0.50976 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1468  | total loss: \u001b[1m\u001b[32m1.60466\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1468 | loss: 1.60466 - acc: 0.6032 | val_loss: 0.50834 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1469  | total loss: \u001b[1m\u001b[32m1.52455\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1469 | loss: 1.52455 - acc: 0.6367 | val_loss: 0.50723 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1470  | total loss: \u001b[1m\u001b[32m1.53416\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1470 | loss: 1.53416 - acc: 0.6355 | val_loss: 0.50613 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 7XZV0V\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1471  | total loss: \u001b[1m\u001b[32m1.46178\u001b[0m\u001b[0m | time: 1.216s\n",
      "| Adam | epoch: 1471 | loss: 1.46178 - acc: 0.6688 | val_loss: 0.50541 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1472  | total loss: \u001b[1m\u001b[32m1.57913\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1472 | loss: 1.57913 - acc: 0.6129 | val_loss: 0.50443 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1473  | total loss: \u001b[1m\u001b[32m1.50495\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1473 | loss: 1.50495 - acc: 0.6438 | val_loss: 0.50408 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1474  | total loss: \u001b[1m\u001b[32m1.63833\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1474 | loss: 1.63833 - acc: 0.5872 | val_loss: 0.50369 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1475  | total loss: \u001b[1m\u001b[32m1.55180\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1475 | loss: 1.55180 - acc: 0.6254 | val_loss: 0.50324 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1476  | total loss: \u001b[1m\u001b[32m1.47677\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1476 | loss: 1.47677 - acc: 0.6597 | val_loss: 0.50302 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1477  | total loss: \u001b[1m\u001b[32m1.60284\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1477 | loss: 1.60284 - acc: 0.6047 | val_loss: 0.50248 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1478  | total loss: \u001b[1m\u001b[32m1.69593\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1478 | loss: 1.69593 - acc: 0.5661 | val_loss: 0.50212 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1479  | total loss: \u001b[1m\u001b[32m1.60465\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1479 | loss: 1.60465 - acc: 0.6032 | val_loss: 0.50226 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1480  | total loss: \u001b[1m\u001b[32m1.71022\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1480 | loss: 1.71022 - acc: 0.5491 | val_loss: 0.50203 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 65ZVA8\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1481  | total loss: \u001b[1m\u001b[32m1.62115\u001b[0m\u001b[0m | time: 1.229s\n",
      "| Adam | epoch: 1481 | loss: 1.62115 - acc: 0.5927 | val_loss: 0.50174 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1482  | total loss: \u001b[1m\u001b[32m1.54401\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 1482 | loss: 1.54401 - acc: 0.6225 | val_loss: 0.50140 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1483  | total loss: \u001b[1m\u001b[32m1.47425\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1483 | loss: 1.47425 - acc: 0.6477 | val_loss: 0.50068 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1484  | total loss: \u001b[1m\u001b[32m1.58716\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1484 | loss: 1.58716 - acc: 0.5970 | val_loss: 0.49984 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1485  | total loss: \u001b[1m\u001b[32m1.50841\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1485 | loss: 1.50841 - acc: 0.6357 | val_loss: 0.49919 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1486  | total loss: \u001b[1m\u001b[32m1.43961\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1486 | loss: 1.43961 - acc: 0.6644 | val_loss: 0.49868 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1487  | total loss: \u001b[1m\u001b[32m1.37762\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1487 | loss: 1.37762 - acc: 0.6932 | val_loss: 0.49826 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1488  | total loss: \u001b[1m\u001b[32m1.51089\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1488 | loss: 1.51089 - acc: 0.6364 | val_loss: 0.49790 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1489  | total loss: \u001b[1m\u001b[32m1.43796\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1489 | loss: 1.43796 - acc: 0.6728 | val_loss: 0.49753 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1490  | total loss: \u001b[1m\u001b[32m1.45092\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1490 | loss: 1.45092 - acc: 0.6664 | val_loss: 0.49733 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: TY93YQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1491  | total loss: \u001b[1m\u001b[32m1.38581\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1491 | loss: 1.38581 - acc: 0.6935 | val_loss: 0.49735 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1492  | total loss: \u001b[1m\u001b[32m1.53079\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1492 | loss: 1.53079 - acc: 0.6320 | val_loss: 0.49746 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1493  | total loss: \u001b[1m\u001b[32m1.45945\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1493 | loss: 1.45945 - acc: 0.6641 | val_loss: 0.49792 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1494  | total loss: \u001b[1m\u001b[32m1.51953\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1494 | loss: 1.51953 - acc: 0.6383 | val_loss: 0.49864 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1495  | total loss: \u001b[1m\u001b[32m1.44827\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1495 | loss: 1.44827 - acc: 0.6682 | val_loss: 0.49919 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1496  | total loss: \u001b[1m\u001b[32m1.54492\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1496 | loss: 1.54492 - acc: 0.6327 | val_loss: 0.49970 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1497  | total loss: \u001b[1m\u001b[32m1.46614\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1497 | loss: 1.46614 - acc: 0.6600 | val_loss: 0.49988 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1498  | total loss: \u001b[1m\u001b[32m1.58845\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1498 | loss: 1.58845 - acc: 0.6128 | val_loss: 0.49989 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1499  | total loss: \u001b[1m\u001b[32m1.51060\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1499 | loss: 1.51060 - acc: 0.6437 | val_loss: 0.49990 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1500  | total loss: \u001b[1m\u001b[32m1.60794\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1500 | loss: 1.60794 - acc: 0.6028 | val_loss: 0.49950 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: HV3PD5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1501  | total loss: \u001b[1m\u001b[32m1.52851\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1501 | loss: 1.52851 - acc: 0.6331 | val_loss: 0.49956 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1502  | total loss: \u001b[1m\u001b[32m1.62764\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1502 | loss: 1.62764 - acc: 0.5870 | val_loss: 0.49954 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1503  | total loss: \u001b[1m\u001b[32m1.54913\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1503 | loss: 1.54913 - acc: 0.6236 | val_loss: 0.49922 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1504  | total loss: \u001b[1m\u001b[32m1.68287\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1504 | loss: 1.68287 - acc: 0.5706 | val_loss: 0.49862 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1505  | total loss: \u001b[1m\u001b[32m1.59591\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1505 | loss: 1.59591 - acc: 0.6073 | val_loss: 0.49790 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1506  | total loss: \u001b[1m\u001b[32m1.51016\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1506 | loss: 1.51016 - acc: 0.6434 | val_loss: 0.49767 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1507  | total loss: \u001b[1m\u001b[32m1.64988\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1507 | loss: 1.64988 - acc: 0.5885 | val_loss: 0.49802 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1508  | total loss: \u001b[1m\u001b[32m1.76277\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1508 | loss: 1.76277 - acc: 0.5390 | val_loss: 0.49807 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1509  | total loss: \u001b[1m\u001b[32m1.66585\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1509 | loss: 1.66585 - acc: 0.5789 | val_loss: 0.49818 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1510  | total loss: \u001b[1m\u001b[32m1.75339\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1510 | loss: 1.75339 - acc: 0.5366 | val_loss: 0.49848 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: J2YFSK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1511  | total loss: \u001b[1m\u001b[32m1.65876\u001b[0m\u001b[0m | time: 1.223s\n",
      "| Adam | epoch: 1511 | loss: 1.65876 - acc: 0.5782 | val_loss: 0.49881 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1512  | total loss: \u001b[1m\u001b[32m1.76363\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1512 | loss: 1.76363 - acc: 0.5329 | val_loss: 0.49913 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1513  | total loss: \u001b[1m\u001b[32m1.66983\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1513 | loss: 1.66983 - acc: 0.5734 | val_loss: 0.49945 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1514  | total loss: \u001b[1m\u001b[32m1.77989\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 1514 | loss: 1.77989 - acc: 0.5223 | val_loss: 0.49973 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1515  | total loss: \u001b[1m\u001b[32m1.67797\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1515 | loss: 1.67797 - acc: 0.5638 | val_loss: 0.50006 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1516  | total loss: \u001b[1m\u001b[32m1.59417\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1516 | loss: 1.59417 - acc: 0.5996 | val_loss: 0.50059 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1517  | total loss: \u001b[1m\u001b[32m1.69382\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1517 | loss: 1.69382 - acc: 0.5553 | val_loss: 0.50111 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1518  | total loss: \u001b[1m\u001b[32m1.71401\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1518 | loss: 1.71401 - acc: 0.5466 | val_loss: 0.50154 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1519  | total loss: \u001b[1m\u001b[32m1.62666\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1519 | loss: 1.62666 - acc: 0.5857 | val_loss: 0.50189 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1520  | total loss: \u001b[1m\u001b[32m1.71586\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1520 | loss: 1.71586 - acc: 0.5475 | val_loss: 0.50204 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: EPTBWW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1521  | total loss: \u001b[1m\u001b[32m1.62446\u001b[0m\u001b[0m | time: 1.222s\n",
      "| Adam | epoch: 1521 | loss: 1.62446 - acc: 0.5849 | val_loss: 0.50236 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1522  | total loss: \u001b[1m\u001b[32m1.63173\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1522 | loss: 1.63173 - acc: 0.5858 | val_loss: 0.50275 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1523  | total loss: \u001b[1m\u001b[32m1.55043\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1523 | loss: 1.55043 - acc: 0.6241 | val_loss: 0.50349 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1524  | total loss: \u001b[1m\u001b[32m1.67195\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1524 | loss: 1.67195 - acc: 0.5757 | val_loss: 0.50376 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1525  | total loss: \u001b[1m\u001b[32m1.58395\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1525 | loss: 1.58395 - acc: 0.6135 | val_loss: 0.50340 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1526  | total loss: \u001b[1m\u001b[32m1.50698\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1526 | loss: 1.50698 - acc: 0.6443 | val_loss: 0.50327 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1527  | total loss: \u001b[1m\u001b[32m1.62934\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1527 | loss: 1.62934 - acc: 0.5971 | val_loss: 0.50314 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1528  | total loss: \u001b[1m\u001b[32m1.65325\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1528 | loss: 1.65325 - acc: 0.5874 | val_loss: 0.50302 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1529  | total loss: \u001b[1m\u001b[32m1.56904\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1529 | loss: 1.56904 - acc: 0.6224 | val_loss: 0.50250 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1530  | total loss: \u001b[1m\u001b[32m1.60589\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1530 | loss: 1.60589 - acc: 0.6086 | val_loss: 0.50176 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: J4RJIR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1531  | total loss: \u001b[1m\u001b[32m1.52776\u001b[0m\u001b[0m | time: 1.218s\n",
      "| Adam | epoch: 1531 | loss: 1.52776 - acc: 0.6399 | val_loss: 0.50078 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1532  | total loss: \u001b[1m\u001b[32m1.64227\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1532 | loss: 1.64227 - acc: 0.5900 | val_loss: 0.49967 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1533  | total loss: \u001b[1m\u001b[32m1.55596\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1533 | loss: 1.55596 - acc: 0.6279 | val_loss: 0.49903 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1534  | total loss: \u001b[1m\u001b[32m1.59622\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1534 | loss: 1.59622 - acc: 0.6104 | val_loss: 0.49834 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1535  | total loss: \u001b[1m\u001b[32m1.51469\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1535 | loss: 1.51469 - acc: 0.6447 | val_loss: 0.49772 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1536  | total loss: \u001b[1m\u001b[32m1.43741\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1536 | loss: 1.43741 - acc: 0.6786 | val_loss: 0.49687 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1537  | total loss: \u001b[1m\u001b[32m1.37357\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1537 | loss: 1.37357 - acc: 0.7061 | val_loss: 0.49639 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1538  | total loss: \u001b[1m\u001b[32m1.49357\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1538 | loss: 1.49357 - acc: 0.6495 | val_loss: 0.49586 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1539  | total loss: \u001b[1m\u001b[32m1.42743\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1539 | loss: 1.42743 - acc: 0.6799 | val_loss: 0.49587 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1540  | total loss: \u001b[1m\u001b[32m1.55905\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1540 | loss: 1.55905 - acc: 0.6244 | val_loss: 0.49566 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: GLTPN0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1541  | total loss: \u001b[1m\u001b[32m1.48495\u001b[0m\u001b[0m | time: 1.206s\n",
      "| Adam | epoch: 1541 | loss: 1.48495 - acc: 0.6588 | val_loss: 0.49548 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1542  | total loss: \u001b[1m\u001b[32m1.51231\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1542 | loss: 1.51231 - acc: 0.6445 | val_loss: 0.49480 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1543  | total loss: \u001b[1m\u001b[32m1.44650\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1543 | loss: 1.44650 - acc: 0.6738 | val_loss: 0.49441 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1544  | total loss: \u001b[1m\u001b[32m1.49098\u001b[0m\u001b[0m | time: 1.070s\n",
      "| Adam | epoch: 1544 | loss: 1.49098 - acc: 0.6533 | val_loss: 0.49395 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1545  | total loss: \u001b[1m\u001b[32m1.42239\u001b[0m\u001b[0m | time: 1.067s\n",
      "| Adam | epoch: 1545 | loss: 1.42239 - acc: 0.6833 | val_loss: 0.49338 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1546  | total loss: \u001b[1m\u001b[32m1.35782\u001b[0m\u001b[0m | time: 1.073s\n",
      "| Adam | epoch: 1546 | loss: 1.35782 - acc: 0.7056 | val_loss: 0.49252 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1547  | total loss: \u001b[1m\u001b[32m1.29774\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1547 | loss: 1.29774 - acc: 0.7303 | val_loss: 0.49173 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1548  | total loss: \u001b[1m\u001b[32m1.44877\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 1548 | loss: 1.44877 - acc: 0.6682 | val_loss: 0.49110 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1549  | total loss: \u001b[1m\u001b[32m1.38213\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1549 | loss: 1.38213 - acc: 0.6952 | val_loss: 0.49056 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1550  | total loss: \u001b[1m\u001b[32m1.40628\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1550 | loss: 1.40628 - acc: 0.6866 | val_loss: 0.48989 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 4B2D52\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1551  | total loss: \u001b[1m\u001b[32m1.34616\u001b[0m\u001b[0m | time: 1.214s\n",
      "| Adam | epoch: 1551 | loss: 1.34616 - acc: 0.7132 | val_loss: 0.48915 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1552  | total loss: \u001b[1m\u001b[32m1.29432\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1552 | loss: 1.29432 - acc: 0.7341 | val_loss: 0.48841 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1553  | total loss: \u001b[1m\u001b[32m1.24548\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1553 | loss: 1.24548 - acc: 0.7544 | val_loss: 0.48774 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1554  | total loss: \u001b[1m\u001b[32m1.28349\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1554 | loss: 1.28349 - acc: 0.7399 | val_loss: 0.48706 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1555  | total loss: \u001b[1m\u001b[32m1.23159\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1555 | loss: 1.23159 - acc: 0.7597 | val_loss: 0.48652 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1556  | total loss: \u001b[1m\u001b[32m1.18914\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1556 | loss: 1.18914 - acc: 0.7759 | val_loss: 0.48596 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1557  | total loss: \u001b[1m\u001b[32m1.14528\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1557 | loss: 1.14528 - acc: 0.7983 | val_loss: 0.48531 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1558  | total loss: \u001b[1m\u001b[32m1.32185\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1558 | loss: 1.32185 - acc: 0.7247 | val_loss: 0.48480 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1559  | total loss: \u001b[1m\u001b[32m1.26819\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1559 | loss: 1.26819 - acc: 0.7445 | val_loss: 0.48472 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1560  | total loss: \u001b[1m\u001b[32m1.42297\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1560 | loss: 1.42297 - acc: 0.6809 | val_loss: 0.48445 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: D38TRU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1561  | total loss: \u001b[1m\u001b[32m1.35758\u001b[0m\u001b[0m | time: 1.216s\n",
      "| Adam | epoch: 1561 | loss: 1.35758 - acc: 0.7050 | val_loss: 0.48437 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1562  | total loss: \u001b[1m\u001b[32m1.50490\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1562 | loss: 1.50490 - acc: 0.6470 | val_loss: 0.48410 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1563  | total loss: \u001b[1m\u001b[32m1.42797\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1563 | loss: 1.42797 - acc: 0.6792 | val_loss: 0.48430 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1564  | total loss: \u001b[1m\u001b[32m1.46021\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1564 | loss: 1.46021 - acc: 0.6566 | val_loss: 0.48433 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1565  | total loss: \u001b[1m\u001b[32m1.39194\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1565 | loss: 1.39194 - acc: 0.6831 | val_loss: 0.48428 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1566  | total loss: \u001b[1m\u001b[32m1.33016\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1566 | loss: 1.33016 - acc: 0.7101 | val_loss: 0.48395 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1567  | total loss: \u001b[1m\u001b[32m1.27735\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1567 | loss: 1.27735 - acc: 0.7344 | val_loss: 0.48376 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1568  | total loss: \u001b[1m\u001b[32m1.41043\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1568 | loss: 1.41043 - acc: 0.6844 | val_loss: 0.48331 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1569  | total loss: \u001b[1m\u001b[32m1.34293\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1569 | loss: 1.34293 - acc: 0.7129 | val_loss: 0.48308 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1570  | total loss: \u001b[1m\u001b[32m1.48637\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1570 | loss: 1.48637 - acc: 0.6525 | val_loss: 0.48275 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 9LDA3T\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1571  | total loss: \u001b[1m\u001b[32m1.41588\u001b[0m\u001b[0m | time: 1.226s\n",
      "| Adam | epoch: 1571 | loss: 1.41588 - acc: 0.6810 | val_loss: 0.48286 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1572  | total loss: \u001b[1m\u001b[32m1.55679\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1572 | loss: 1.55679 - acc: 0.6207 | val_loss: 0.48255 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1573  | total loss: \u001b[1m\u001b[32m1.48258\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1573 | loss: 1.48258 - acc: 0.6493 | val_loss: 0.48295 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1574  | total loss: \u001b[1m\u001b[32m1.60850\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1574 | loss: 1.60850 - acc: 0.5937 | val_loss: 0.48287 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1575  | total loss: \u001b[1m\u001b[32m1.53282\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1575 | loss: 1.53282 - acc: 0.6297 | val_loss: 0.48242 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1576  | total loss: \u001b[1m\u001b[32m1.45344\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1576 | loss: 1.45344 - acc: 0.6573 | val_loss: 0.48249 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1577  | total loss: \u001b[1m\u001b[32m1.55487\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1577 | loss: 1.55487 - acc: 0.6103 | val_loss: 0.48238 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1578  | total loss: \u001b[1m\u001b[32m1.60024\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1578 | loss: 1.60024 - acc: 0.5946 | val_loss: 0.48192 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1579  | total loss: \u001b[1m\u001b[32m1.51953\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1579 | loss: 1.51953 - acc: 0.6336 | val_loss: 0.48144 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1580  | total loss: \u001b[1m\u001b[32m1.59145\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1580 | loss: 1.59145 - acc: 0.6046 | val_loss: 0.48067 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: IGSU31\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1581  | total loss: \u001b[1m\u001b[32m1.50655\u001b[0m\u001b[0m | time: 1.225s\n",
      "| Adam | epoch: 1581 | loss: 1.50655 - acc: 0.6363 | val_loss: 0.48022 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1582  | total loss: \u001b[1m\u001b[32m1.43240\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1582 | loss: 1.43240 - acc: 0.6680 | val_loss: 0.47975 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1583  | total loss: \u001b[1m\u001b[32m1.48740\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1583 | loss: 1.48740 - acc: 0.6481 | val_loss: 0.47886 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1584  | total loss: \u001b[1m\u001b[32m1.41624\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1584 | loss: 1.41624 - acc: 0.6802 | val_loss: 0.47815 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1585  | total loss: \u001b[1m\u001b[32m1.46450\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1585 | loss: 1.46450 - acc: 0.6637 | val_loss: 0.47743 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1586  | total loss: \u001b[1m\u001b[32m1.39094\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1586 | loss: 1.39094 - acc: 0.6942 | val_loss: 0.47662 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1587  | total loss: \u001b[1m\u001b[32m1.32927\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1587 | loss: 1.32927 - acc: 0.7201 | val_loss: 0.47557 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1588  | total loss: \u001b[1m\u001b[32m1.27409\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1588 | loss: 1.27409 - acc: 0.7434 | val_loss: 0.47442 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1589  | total loss: \u001b[1m\u001b[32m1.22154\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1589 | loss: 1.22154 - acc: 0.7628 | val_loss: 0.47295 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1590  | total loss: \u001b[1m\u001b[32m1.41177\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1590 | loss: 1.41177 - acc: 0.6928 | val_loss: 0.47170 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: O7Y6K9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1591  | total loss: \u001b[1m\u001b[32m1.34441\u001b[0m\u001b[0m | time: 1.221s\n",
      "| Adam | epoch: 1591 | loss: 1.34441 - acc: 0.7188 | val_loss: 0.47049 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1592  | total loss: \u001b[1m\u001b[32m1.28838\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1592 | loss: 1.28838 - acc: 0.7360 | val_loss: 0.46993 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1593  | total loss: \u001b[1m\u001b[32m1.43834\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1593 | loss: 1.43834 - acc: 0.6671 | val_loss: 0.46918 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1594  | total loss: \u001b[1m\u001b[32m1.36855\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1594 | loss: 1.36855 - acc: 0.6972 | val_loss: 0.46868 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1595  | total loss: \u001b[1m\u001b[32m1.30425\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1595 | loss: 1.30425 - acc: 0.7197 | val_loss: 0.46756 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1596  | total loss: \u001b[1m\u001b[32m1.41363\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1596 | loss: 1.41363 - acc: 0.6790 | val_loss: 0.46647 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1597  | total loss: \u001b[1m\u001b[32m1.35152\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1597 | loss: 1.35152 - acc: 0.6986 | val_loss: 0.46607 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1598  | total loss: \u001b[1m\u001b[32m1.44705\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1598 | loss: 1.44705 - acc: 0.6615 | val_loss: 0.46536 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1599  | total loss: \u001b[1m\u001b[32m1.37894\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1599 | loss: 1.37894 - acc: 0.6876 | val_loss: 0.46468 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1600  | total loss: \u001b[1m\u001b[32m1.31613\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1600 | loss: 1.31613 - acc: 0.7141 | val_loss: 0.46393 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: NUMB6N\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1601  | total loss: \u001b[1m\u001b[32m1.25982\u001b[0m\u001b[0m | time: 1.212s\n",
      "| Adam | epoch: 1601 | loss: 1.25982 - acc: 0.7365 | val_loss: 0.46338 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1602  | total loss: \u001b[1m\u001b[32m1.42738\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1602 | loss: 1.42738 - acc: 0.6738 | val_loss: 0.46311 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1603  | total loss: \u001b[1m\u001b[32m1.36580\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1603 | loss: 1.36580 - acc: 0.7001 | val_loss: 0.46322 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1604  | total loss: \u001b[1m\u001b[32m1.51298\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1604 | loss: 1.51298 - acc: 0.6379 | val_loss: 0.46298 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1605  | total loss: \u001b[1m\u001b[32m1.44223\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1605 | loss: 1.44223 - acc: 0.6648 | val_loss: 0.46263 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1606  | total loss: \u001b[1m\u001b[32m1.56910\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1606 | loss: 1.56910 - acc: 0.6108 | val_loss: 0.46222 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1607  | total loss: \u001b[1m\u001b[32m1.48940\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1607 | loss: 1.48940 - acc: 0.6435 | val_loss: 0.46139 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1608  | total loss: \u001b[1m\u001b[32m1.62797\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1608 | loss: 1.62797 - acc: 0.5838 | val_loss: 0.46045 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1609  | total loss: \u001b[1m\u001b[32m1.53830\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1609 | loss: 1.53830 - acc: 0.6207 | val_loss: 0.46030 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1610  | total loss: \u001b[1m\u001b[32m1.64765\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1610 | loss: 1.64765 - acc: 0.5712 | val_loss: 0.45993 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: S5DXZE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1611  | total loss: \u001b[1m\u001b[32m1.55736\u001b[0m\u001b[0m | time: 1.209s\n",
      "| Adam | epoch: 1611 | loss: 1.55736 - acc: 0.6078 | val_loss: 0.45946 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1612  | total loss: \u001b[1m\u001b[32m1.68461\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1612 | loss: 1.68461 - acc: 0.5580 | val_loss: 0.45873 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1613  | total loss: \u001b[1m\u001b[32m1.59523\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1613 | loss: 1.59523 - acc: 0.5943 | val_loss: 0.45850 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1614  | total loss: \u001b[1m\u001b[32m1.61031\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1614 | loss: 1.61031 - acc: 0.5912 | val_loss: 0.45807 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1615  | total loss: \u001b[1m\u001b[32m1.52931\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1615 | loss: 1.52931 - acc: 0.6227 | val_loss: 0.45703 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1616  | total loss: \u001b[1m\u001b[32m1.62099\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1616 | loss: 1.62099 - acc: 0.5838 | val_loss: 0.45628 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1617  | total loss: \u001b[1m\u001b[32m1.54050\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1617 | loss: 1.54050 - acc: 0.6208 | val_loss: 0.45603 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1618  | total loss: \u001b[1m\u001b[32m1.66412\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1618 | loss: 1.66412 - acc: 0.5696 | val_loss: 0.45587 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1619  | total loss: \u001b[1m\u001b[32m1.57777\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1619 | loss: 1.57777 - acc: 0.6064 | val_loss: 0.45600 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1620  | total loss: \u001b[1m\u001b[32m1.58316\u001b[0m\u001b[0m | time: 1.073s\n",
      "| Adam | epoch: 1620 | loss: 1.58316 - acc: 0.6067 | val_loss: 0.45616 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: WH3IL3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1621  | total loss: \u001b[1m\u001b[32m1.49638\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1621 | loss: 1.49638 - acc: 0.6429 | val_loss: 0.45596 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1622  | total loss: \u001b[1m\u001b[32m1.42229\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1622 | loss: 1.42229 - acc: 0.6755 | val_loss: 0.45581 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1623  | total loss: \u001b[1m\u001b[32m1.35884\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1623 | loss: 1.35884 - acc: 0.7017 | val_loss: 0.45603 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1624  | total loss: \u001b[1m\u001b[32m1.49030\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1624 | loss: 1.49030 - acc: 0.6425 | val_loss: 0.45635 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1625  | total loss: \u001b[1m\u001b[32m1.41405\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1625 | loss: 1.41405 - acc: 0.6735 | val_loss: 0.45676 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1626  | total loss: \u001b[1m\u001b[32m1.52250\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1626 | loss: 1.52250 - acc: 0.6249 | val_loss: 0.45666 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1627  | total loss: \u001b[1m\u001b[32m1.44281\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1627 | loss: 1.44281 - acc: 0.6593 | val_loss: 0.45688 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1628  | total loss: \u001b[1m\u001b[32m1.57287\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1628 | loss: 1.57287 - acc: 0.6028 | val_loss: 0.45694 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1629  | total loss: \u001b[1m\u001b[32m1.48934\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1629 | loss: 1.48934 - acc: 0.6394 | val_loss: 0.45684 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1630  | total loss: \u001b[1m\u001b[32m1.63850\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1630 | loss: 1.63850 - acc: 0.5864 | val_loss: 0.45648 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 1G1N1S\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1631  | total loss: \u001b[1m\u001b[32m1.54471\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1631 | loss: 1.54471 - acc: 0.6246 | val_loss: 0.45588 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1632  | total loss: \u001b[1m\u001b[32m1.47116\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1632 | loss: 1.47116 - acc: 0.6559 | val_loss: 0.45525 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1633  | total loss: \u001b[1m\u001b[32m1.39763\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1633 | loss: 1.39763 - acc: 0.6856 | val_loss: 0.45468 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1634  | total loss: \u001b[1m\u001b[32m1.33194\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1634 | loss: 1.33194 - acc: 0.7155 | val_loss: 0.45402 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1635  | total loss: \u001b[1m\u001b[32m1.27196\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 1635 | loss: 1.27196 - acc: 0.7408 | val_loss: 0.45371 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1636  | total loss: \u001b[1m\u001b[32m1.42083\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1636 | loss: 1.42083 - acc: 0.6808 | val_loss: 0.45293 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1637  | total loss: \u001b[1m\u001b[32m1.35037\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1637 | loss: 1.35037 - acc: 0.7065 | val_loss: 0.45236 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1638  | total loss: \u001b[1m\u001b[32m1.39328\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1638 | loss: 1.39328 - acc: 0.6889 | val_loss: 0.45136 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1639  | total loss: \u001b[1m\u001b[32m1.33430\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1639 | loss: 1.33430 - acc: 0.7122 | val_loss: 0.45020 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1640  | total loss: \u001b[1m\u001b[32m1.35600\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1640 | loss: 1.35600 - acc: 0.7004 | val_loss: 0.44907 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 6V0WAY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1641  | total loss: \u001b[1m\u001b[32m1.29501\u001b[0m\u001b[0m | time: 1.217s\n",
      "| Adam | epoch: 1641 | loss: 1.29501 - acc: 0.7241 | val_loss: 0.44811 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1642  | total loss: \u001b[1m\u001b[32m1.44134\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1642 | loss: 1.44134 - acc: 0.6658 | val_loss: 0.44706 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1643  | total loss: \u001b[1m\u001b[32m1.36927\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1643 | loss: 1.36927 - acc: 0.6961 | val_loss: 0.44656 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1644  | total loss: \u001b[1m\u001b[32m1.54034\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1644 | loss: 1.54034 - acc: 0.6343 | val_loss: 0.44579 - val_acc: 0.9844 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1645  | total loss: \u001b[1m\u001b[32m1.46391\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1645 | loss: 1.46391 - acc: 0.6630 | val_loss: 0.44518 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1646  | total loss: \u001b[1m\u001b[32m1.59616\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1646 | loss: 1.59616 - acc: 0.6108 | val_loss: 0.44474 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1647  | total loss: \u001b[1m\u001b[32m1.50853\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1647 | loss: 1.50853 - acc: 0.6450 | val_loss: 0.44468 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1648  | total loss: \u001b[1m\u001b[32m1.62776\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1648 | loss: 1.62776 - acc: 0.5915 | val_loss: 0.44442 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1649  | total loss: \u001b[1m\u001b[32m1.54207\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1649 | loss: 1.54207 - acc: 0.6276 | val_loss: 0.44399 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1650  | total loss: \u001b[1m\u001b[32m1.69565\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 1650 | loss: 1.69565 - acc: 0.5742 | val_loss: 0.44337 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: KUMR2J\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1651  | total loss: \u001b[1m\u001b[32m1.60382\u001b[0m\u001b[0m | time: 1.233s\n",
      "| Adam | epoch: 1651 | loss: 1.60382 - acc: 0.6106 | val_loss: 0.44311 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1652  | total loss: \u001b[1m\u001b[32m1.72430\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1652 | loss: 1.72430 - acc: 0.5604 | val_loss: 0.44283 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1653  | total loss: \u001b[1m\u001b[32m1.62700\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1653 | loss: 1.62700 - acc: 0.6013 | val_loss: 0.44276 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1654  | total loss: \u001b[1m\u001b[32m1.53480\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1654 | loss: 1.53480 - acc: 0.6380 | val_loss: 0.44292 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1655  | total loss: \u001b[1m\u001b[32m1.45348\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1655 | loss: 1.45348 - acc: 0.6711 | val_loss: 0.44297 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1656  | total loss: \u001b[1m\u001b[32m1.38746\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1656 | loss: 1.38746 - acc: 0.7009 | val_loss: 0.44312 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1657  | total loss: \u001b[1m\u001b[32m1.32340\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1657 | loss: 1.32340 - acc: 0.7245 | val_loss: 0.44330 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1658  | total loss: \u001b[1m\u001b[32m1.35248\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1658 | loss: 1.35248 - acc: 0.7146 | val_loss: 0.44311 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1659  | total loss: \u001b[1m\u001b[32m1.28755\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1659 | loss: 1.28755 - acc: 0.7369 | val_loss: 0.44307 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1660  | total loss: \u001b[1m\u001b[32m1.38484\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1660 | loss: 1.38484 - acc: 0.6944 | val_loss: 0.44282 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: L897AC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1661  | total loss: \u001b[1m\u001b[32m1.32386\u001b[0m\u001b[0m | time: 1.230s\n",
      "| Adam | epoch: 1661 | loss: 1.32386 - acc: 0.7203 | val_loss: 0.44251 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1662  | total loss: \u001b[1m\u001b[32m1.47844\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1662 | loss: 1.47844 - acc: 0.6592 | val_loss: 0.44219 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1663  | total loss: \u001b[1m\u001b[32m1.40351\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1663 | loss: 1.40351 - acc: 0.6917 | val_loss: 0.44198 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1664  | total loss: \u001b[1m\u001b[32m1.53906\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1664 | loss: 1.53906 - acc: 0.6319 | val_loss: 0.44158 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1665  | total loss: \u001b[1m\u001b[32m1.45692\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1665 | loss: 1.45692 - acc: 0.6672 | val_loss: 0.44078 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1666  | total loss: \u001b[1m\u001b[32m1.58350\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1666 | loss: 1.58350 - acc: 0.6114 | val_loss: 0.44010 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1667  | total loss: \u001b[1m\u001b[32m1.49920\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1667 | loss: 1.49920 - acc: 0.6456 | val_loss: 0.43908 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1668  | total loss: \u001b[1m\u001b[32m1.64141\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1668 | loss: 1.64141 - acc: 0.5888 | val_loss: 0.43821 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1669  | total loss: \u001b[1m\u001b[32m1.54899\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1669 | loss: 1.54899 - acc: 0.6237 | val_loss: 0.43790 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1670  | total loss: \u001b[1m\u001b[32m1.66839\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1670 | loss: 1.66839 - acc: 0.5691 | val_loss: 0.43755 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 4KQG6K\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1671  | total loss: \u001b[1m\u001b[32m1.57604\u001b[0m\u001b[0m | time: 1.223s\n",
      "| Adam | epoch: 1671 | loss: 1.57604 - acc: 0.6075 | val_loss: 0.43715 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1672  | total loss: \u001b[1m\u001b[32m1.49165\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1672 | loss: 1.49165 - acc: 0.6405 | val_loss: 0.43681 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1673  | total loss: \u001b[1m\u001b[32m1.61337\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1673 | loss: 1.61337 - acc: 0.5905 | val_loss: 0.43625 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1674  | total loss: \u001b[1m\u001b[32m1.74078\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1674 | loss: 1.74078 - acc: 0.5393 | val_loss: 0.43555 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1675  | total loss: \u001b[1m\u001b[32m1.63844\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1675 | loss: 1.63844 - acc: 0.5822 | val_loss: 0.43486 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1676  | total loss: \u001b[1m\u001b[32m1.76821\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1676 | loss: 1.76821 - acc: 0.5334 | val_loss: 0.43426 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1677  | total loss: \u001b[1m\u001b[32m1.66575\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1677 | loss: 1.66575 - acc: 0.5785 | val_loss: 0.43420 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1678  | total loss: \u001b[1m\u001b[32m1.75178\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1678 | loss: 1.75178 - acc: 0.5456 | val_loss: 0.43431 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1679  | total loss: \u001b[1m\u001b[32m1.64689\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1679 | loss: 1.64689 - acc: 0.5880 | val_loss: 0.43502 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1680  | total loss: \u001b[1m\u001b[32m1.72557\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1680 | loss: 1.72557 - acc: 0.5495 | val_loss: 0.43555 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 6ZC2LU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1681  | total loss: \u001b[1m\u001b[32m1.62667\u001b[0m\u001b[0m | time: 1.217s\n",
      "| Adam | epoch: 1681 | loss: 1.62667 - acc: 0.5930 | val_loss: 0.43581 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1682  | total loss: \u001b[1m\u001b[32m1.54158\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1682 | loss: 1.54158 - acc: 0.6274 | val_loss: 0.43656 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1683  | total loss: \u001b[1m\u001b[32m1.61119\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1683 | loss: 1.61119 - acc: 0.5944 | val_loss: 0.43740 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1684  | total loss: \u001b[1m\u001b[32m1.52161\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1684 | loss: 1.52161 - acc: 0.6318 | val_loss: 0.43815 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1685  | total loss: \u001b[1m\u001b[32m1.65367\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1685 | loss: 1.65367 - acc: 0.5796 | val_loss: 0.43845 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1686  | total loss: \u001b[1m\u001b[32m1.55941\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1686 | loss: 1.55941 - acc: 0.6169 | val_loss: 0.43885 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1687  | total loss: \u001b[1m\u001b[32m1.47574\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1687 | loss: 1.47574 - acc: 0.6505 | val_loss: 0.43901 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1688  | total loss: \u001b[1m\u001b[32m1.57555\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1688 | loss: 1.57555 - acc: 0.6120 | val_loss: 0.43916 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1689  | total loss: \u001b[1m\u001b[32m1.49129\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1689 | loss: 1.49129 - acc: 0.6446 | val_loss: 0.43967 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1690  | total loss: \u001b[1m\u001b[32m1.62600\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1690 | loss: 1.62600 - acc: 0.5879 | val_loss: 0.44028 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 5FM6I2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1691  | total loss: \u001b[1m\u001b[32m1.54659\u001b[0m\u001b[0m | time: 1.230s\n",
      "| Adam | epoch: 1691 | loss: 1.54659 - acc: 0.6198 | val_loss: 0.44080 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1692  | total loss: \u001b[1m\u001b[32m1.46535\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1692 | loss: 1.46535 - acc: 0.6531 | val_loss: 0.44109 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1693  | total loss: \u001b[1m\u001b[32m1.39189\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1693 | loss: 1.39189 - acc: 0.6862 | val_loss: 0.44092 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1694  | total loss: \u001b[1m\u001b[32m1.45327\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1694 | loss: 1.45327 - acc: 0.6614 | val_loss: 0.44013 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1695  | total loss: \u001b[1m\u001b[32m1.38418\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1695 | loss: 1.38418 - acc: 0.6812 | val_loss: 0.43953 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1696  | total loss: \u001b[1m\u001b[32m1.31411\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1696 | loss: 1.31411 - acc: 0.7130 | val_loss: 0.43919 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1697  | total loss: \u001b[1m\u001b[32m1.47442\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1697 | loss: 1.47442 - acc: 0.6464 | val_loss: 0.43919 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1698  | total loss: \u001b[1m\u001b[32m1.60650\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1698 | loss: 1.60650 - acc: 0.5880 | val_loss: 0.43894 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1699  | total loss: \u001b[1m\u001b[32m1.51672\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1699 | loss: 1.51672 - acc: 0.6245 | val_loss: 0.43895 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1700  | total loss: \u001b[1m\u001b[32m1.50521\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1700 | loss: 1.50521 - acc: 0.6277 | val_loss: 0.43860 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: I41LJR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1701  | total loss: \u001b[1m\u001b[32m1.43137\u001b[0m\u001b[0m | time: 1.214s\n",
      "| Adam | epoch: 1701 | loss: 1.43137 - acc: 0.6587 | val_loss: 0.43820 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1702  | total loss: \u001b[1m\u001b[32m1.57387\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1702 | loss: 1.57387 - acc: 0.6069 | val_loss: 0.43779 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1703  | total loss: \u001b[1m\u001b[32m1.48617\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1703 | loss: 1.48617 - acc: 0.6431 | val_loss: 0.43737 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1704  | total loss: \u001b[1m\u001b[32m1.41368\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1704 | loss: 1.41368 - acc: 0.6741 | val_loss: 0.43719 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1705  | total loss: \u001b[1m\u001b[32m1.34740\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1705 | loss: 1.34740 - acc: 0.7020 | val_loss: 0.43736 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1706  | total loss: \u001b[1m\u001b[32m1.51327\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1706 | loss: 1.51327 - acc: 0.6365 | val_loss: 0.43729 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1707  | total loss: \u001b[1m\u001b[32m1.43886\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1707 | loss: 1.43886 - acc: 0.6666 | val_loss: 0.43700 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1708  | total loss: \u001b[1m\u001b[32m1.51987\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1708 | loss: 1.51987 - acc: 0.6312 | val_loss: 0.43659 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1709  | total loss: \u001b[1m\u001b[32m1.44191\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1709 | loss: 1.44191 - acc: 0.6634 | val_loss: 0.43627 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1710  | total loss: \u001b[1m\u001b[32m1.58699\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1710 | loss: 1.58699 - acc: 0.6033 | val_loss: 0.43615 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 0YLB6K\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1711  | total loss: \u001b[1m\u001b[32m1.50157\u001b[0m\u001b[0m | time: 1.223s\n",
      "| Adam | epoch: 1711 | loss: 1.50157 - acc: 0.6398 | val_loss: 0.43589 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1712  | total loss: \u001b[1m\u001b[32m1.42507\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1712 | loss: 1.42507 - acc: 0.6696 | val_loss: 0.43581 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1713  | total loss: \u001b[1m\u001b[32m1.55045\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1713 | loss: 1.55045 - acc: 0.6198 | val_loss: 0.43607 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1714  | total loss: \u001b[1m\u001b[32m1.66953\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1714 | loss: 1.66953 - acc: 0.5672 | val_loss: 0.43624 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1715  | total loss: \u001b[1m\u001b[32m1.57197\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1715 | loss: 1.57197 - acc: 0.6058 | val_loss: 0.43655 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1716  | total loss: \u001b[1m\u001b[32m1.67785\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1716 | loss: 1.67785 - acc: 0.5671 | val_loss: 0.43658 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1717  | total loss: \u001b[1m\u001b[32m1.58494\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1717 | loss: 1.58494 - acc: 0.6041 | val_loss: 0.43658 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1718  | total loss: \u001b[1m\u001b[32m1.71422\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1718 | loss: 1.71422 - acc: 0.5531 | val_loss: 0.43644 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1719  | total loss: \u001b[1m\u001b[32m1.61722\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 1719 | loss: 1.61722 - acc: 0.5915 | val_loss: 0.43626 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1720  | total loss: \u001b[1m\u001b[32m1.71130\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1720 | loss: 1.71130 - acc: 0.5511 | val_loss: 0.43617 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 8PU6Z8\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1721  | total loss: \u001b[1m\u001b[32m1.61938\u001b[0m\u001b[0m | time: 1.222s\n",
      "| Adam | epoch: 1721 | loss: 1.61938 - acc: 0.5929 | val_loss: 0.43656 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1722  | total loss: \u001b[1m\u001b[32m1.74895\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1722 | loss: 1.74895 - acc: 0.5430 | val_loss: 0.43670 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1723  | total loss: \u001b[1m\u001b[32m1.64956\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1723 | loss: 1.64956 - acc: 0.5840 | val_loss: 0.43713 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1724  | total loss: \u001b[1m\u001b[32m1.76680\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1724 | loss: 1.76680 - acc: 0.5365 | val_loss: 0.43712 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1725  | total loss: \u001b[1m\u001b[32m1.66336\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1725 | loss: 1.66336 - acc: 0.5813 | val_loss: 0.43709 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1726  | total loss: \u001b[1m\u001b[32m1.76449\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1726 | loss: 1.76449 - acc: 0.5404 | val_loss: 0.43693 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1727  | total loss: \u001b[1m\u001b[32m1.65831\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1727 | loss: 1.65831 - acc: 0.5863 | val_loss: 0.43695 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1728  | total loss: \u001b[1m\u001b[32m1.74891\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1728 | loss: 1.74891 - acc: 0.5449 | val_loss: 0.43706 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1729  | total loss: \u001b[1m\u001b[32m1.64522\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1729 | loss: 1.64522 - acc: 0.5888 | val_loss: 0.43730 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1730  | total loss: \u001b[1m\u001b[32m1.65102\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1730 | loss: 1.65102 - acc: 0.5831 | val_loss: 0.43737 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: MNVCGH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1731  | total loss: \u001b[1m\u001b[32m1.55486\u001b[0m\u001b[0m | time: 1.216s\n",
      "| Adam | epoch: 1731 | loss: 1.55486 - acc: 0.6216 | val_loss: 0.43736 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1732  | total loss: \u001b[1m\u001b[32m1.67630\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1732 | loss: 1.67630 - acc: 0.5673 | val_loss: 0.43732 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1733  | total loss: \u001b[1m\u001b[32m1.58219\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1733 | loss: 1.58219 - acc: 0.6090 | val_loss: 0.43739 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1734  | total loss: \u001b[1m\u001b[32m1.61119\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1734 | loss: 1.61119 - acc: 0.5981 | val_loss: 0.43738 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1735  | total loss: \u001b[1m\u001b[32m1.52261\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1735 | loss: 1.52261 - acc: 0.6336 | val_loss: 0.43802 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1736  | total loss: \u001b[1m\u001b[32m1.65482\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1736 | loss: 1.65482 - acc: 0.5796 | val_loss: 0.43822 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1737  | total loss: \u001b[1m\u001b[32m1.56683\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1737 | loss: 1.56683 - acc: 0.6138 | val_loss: 0.43923 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1738  | total loss: \u001b[1m\u001b[32m1.66295\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1738 | loss: 1.66295 - acc: 0.5696 | val_loss: 0.43996 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1739  | total loss: \u001b[1m\u001b[32m1.56997\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1739 | loss: 1.56997 - acc: 0.6080 | val_loss: 0.44064 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1740  | total loss: \u001b[1m\u001b[32m1.57073\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1740 | loss: 1.57073 - acc: 0.6066 | val_loss: 0.44066 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 6SNL09\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1741  | total loss: \u001b[1m\u001b[32m1.49227\u001b[0m\u001b[0m | time: 1.234s\n",
      "| Adam | epoch: 1741 | loss: 1.49227 - acc: 0.6397 | val_loss: 0.44049 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1742  | total loss: \u001b[1m\u001b[32m1.41942\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1742 | loss: 1.41942 - acc: 0.6710 | val_loss: 0.44086 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1743  | total loss: \u001b[1m\u001b[32m1.53278\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1743 | loss: 1.53278 - acc: 0.6258 | val_loss: 0.44168 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1744  | total loss: \u001b[1m\u001b[32m1.56020\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1744 | loss: 1.56020 - acc: 0.6116 | val_loss: 0.44220 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1745  | total loss: \u001b[1m\u001b[32m1.47465\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1745 | loss: 1.47465 - acc: 0.6458 | val_loss: 0.44243 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1746  | total loss: \u001b[1m\u001b[32m1.52466\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1746 | loss: 1.52466 - acc: 0.6265 | val_loss: 0.44230 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1747  | total loss: \u001b[1m\u001b[32m1.44959\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1747 | loss: 1.44959 - acc: 0.6561 | val_loss: 0.44254 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1748  | total loss: \u001b[1m\u001b[32m1.57418\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1748 | loss: 1.57418 - acc: 0.6092 | val_loss: 0.44271 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1749  | total loss: \u001b[1m\u001b[32m1.50022\u001b[0m\u001b[0m | time: 1.071s\n",
      "| Adam | epoch: 1749 | loss: 1.50022 - acc: 0.6436 | val_loss: 0.44341 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1750  | total loss: \u001b[1m\u001b[32m1.59945\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1750 | loss: 1.59945 - acc: 0.6027 | val_loss: 0.44399 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: UVOW5R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1751  | total loss: \u001b[1m\u001b[32m1.51664\u001b[0m\u001b[0m | time: 1.224s\n",
      "| Adam | epoch: 1751 | loss: 1.51664 - acc: 0.6408 | val_loss: 0.44454 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1752  | total loss: \u001b[1m\u001b[32m1.64741\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1752 | loss: 1.64741 - acc: 0.5893 | val_loss: 0.44441 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1753  | total loss: \u001b[1m\u001b[32m1.55967\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1753 | loss: 1.55967 - acc: 0.6256 | val_loss: 0.44435 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1754  | total loss: \u001b[1m\u001b[32m1.61369\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1754 | loss: 1.61369 - acc: 0.6068 | val_loss: 0.44398 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1755  | total loss: \u001b[1m\u001b[32m1.53001\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1755 | loss: 1.53001 - acc: 0.6430 | val_loss: 0.44363 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1756  | total loss: \u001b[1m\u001b[32m1.45389\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1756 | loss: 1.45389 - acc: 0.6725 | val_loss: 0.44297 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1757  | total loss: \u001b[1m\u001b[32m1.38574\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1757 | loss: 1.38574 - acc: 0.6974 | val_loss: 0.44246 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1758  | total loss: \u001b[1m\u001b[32m1.53900\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1758 | loss: 1.53900 - acc: 0.6339 | val_loss: 0.44165 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1759  | total loss: \u001b[1m\u001b[32m1.45992\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1759 | loss: 1.45992 - acc: 0.6674 | val_loss: 0.44118 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1760  | total loss: \u001b[1m\u001b[32m1.58788\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1760 | loss: 1.58788 - acc: 0.6194 | val_loss: 0.44011 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: I2B1TF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1761  | total loss: \u001b[1m\u001b[32m1.49857\u001b[0m\u001b[0m | time: 1.227s\n",
      "| Adam | epoch: 1761 | loss: 1.49857 - acc: 0.6543 | val_loss: 0.43874 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1762  | total loss: \u001b[1m\u001b[32m1.51164\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1762 | loss: 1.51164 - acc: 0.6467 | val_loss: 0.43739 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1763  | total loss: \u001b[1m\u001b[32m1.43417\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1763 | loss: 1.43417 - acc: 0.6789 | val_loss: 0.43635 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1764  | total loss: \u001b[1m\u001b[32m1.56944\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1764 | loss: 1.56944 - acc: 0.6220 | val_loss: 0.43502 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1765  | total loss: \u001b[1m\u001b[32m1.48382\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1765 | loss: 1.48382 - acc: 0.6551 | val_loss: 0.43404 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1766  | total loss: \u001b[1m\u001b[32m1.63535\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1766 | loss: 1.63535 - acc: 0.5974 | val_loss: 0.43294 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1767  | total loss: \u001b[1m\u001b[32m1.54563\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1767 | loss: 1.54563 - acc: 0.6314 | val_loss: 0.43229 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1768  | total loss: \u001b[1m\u001b[32m1.66275\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1768 | loss: 1.66275 - acc: 0.5854 | val_loss: 0.43156 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1769  | total loss: \u001b[1m\u001b[32m1.57266\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1769 | loss: 1.57266 - acc: 0.6222 | val_loss: 0.43085 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1770  | total loss: \u001b[1m\u001b[32m1.57088\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1770 | loss: 1.57088 - acc: 0.6194 | val_loss: 0.43012 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: OD8FHX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1771  | total loss: \u001b[1m\u001b[32m1.48165\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1771 | loss: 1.48165 - acc: 0.6574 | val_loss: 0.42949 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1772  | total loss: \u001b[1m\u001b[32m1.49319\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1772 | loss: 1.49319 - acc: 0.6511 | val_loss: 0.42886 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1773  | total loss: \u001b[1m\u001b[32m1.41403\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1773 | loss: 1.41403 - acc: 0.6828 | val_loss: 0.42802 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1774  | total loss: \u001b[1m\u001b[32m1.34082\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1774 | loss: 1.34082 - acc: 0.7130 | val_loss: 0.42697 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1775  | total loss: \u001b[1m\u001b[32m1.28051\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1775 | loss: 1.28051 - acc: 0.7370 | val_loss: 0.42593 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1776  | total loss: \u001b[1m\u001b[32m1.41821\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1776 | loss: 1.41821 - acc: 0.6774 | val_loss: 0.42493 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1777  | total loss: \u001b[1m\u001b[32m1.34630\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1777 | loss: 1.34630 - acc: 0.7065 | val_loss: 0.42399 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1778  | total loss: \u001b[1m\u001b[32m1.39930\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1778 | loss: 1.39930 - acc: 0.6812 | val_loss: 0.42316 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1779  | total loss: \u001b[1m\u001b[32m1.33109\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1779 | loss: 1.33109 - acc: 0.7130 | val_loss: 0.42249 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1780  | total loss: \u001b[1m\u001b[32m1.45116\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1780 | loss: 1.45116 - acc: 0.6621 | val_loss: 0.42199 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: VOA5ZR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1781  | total loss: \u001b[1m\u001b[32m1.37913\u001b[0m\u001b[0m | time: 1.216s\n",
      "| Adam | epoch: 1781 | loss: 1.37913 - acc: 0.6927 | val_loss: 0.42196 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1782  | total loss: \u001b[1m\u001b[32m1.42706\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1782 | loss: 1.42706 - acc: 0.6735 | val_loss: 0.42167 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1783  | total loss: \u001b[1m\u001b[32m1.35100\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1783 | loss: 1.35100 - acc: 0.7061 | val_loss: 0.42174 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1784  | total loss: \u001b[1m\u001b[32m1.50431\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1784 | loss: 1.50431 - acc: 0.6417 | val_loss: 0.42163 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1785  | total loss: \u001b[1m\u001b[32m1.42404\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1785 | loss: 1.42404 - acc: 0.6729 | val_loss: 0.42208 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1786  | total loss: \u001b[1m\u001b[32m1.55797\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1786 | loss: 1.55797 - acc: 0.6150 | val_loss: 0.42241 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1787  | total loss: \u001b[1m\u001b[32m1.47732\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1787 | loss: 1.47732 - acc: 0.6488 | val_loss: 0.42258 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1788  | total loss: \u001b[1m\u001b[32m1.53260\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1788 | loss: 1.53260 - acc: 0.6261 | val_loss: 0.42247 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1789  | total loss: \u001b[1m\u001b[32m1.45105\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1789 | loss: 1.45105 - acc: 0.6557 | val_loss: 0.42226 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1790  | total loss: \u001b[1m\u001b[32m1.47917\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1790 | loss: 1.47917 - acc: 0.6464 | val_loss: 0.42210 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 1PYLYZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1791  | total loss: \u001b[1m\u001b[32m1.40013\u001b[0m\u001b[0m | time: 1.228s\n",
      "| Adam | epoch: 1791 | loss: 1.40013 - acc: 0.6770 | val_loss: 0.42161 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1792  | total loss: \u001b[1m\u001b[32m1.41194\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1792 | loss: 1.41194 - acc: 0.6718 | val_loss: 0.42097 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1793  | total loss: \u001b[1m\u001b[32m1.34867\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1793 | loss: 1.34867 - acc: 0.6984 | val_loss: 0.42050 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1794  | total loss: \u001b[1m\u001b[32m1.47623\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1794 | loss: 1.47623 - acc: 0.6426 | val_loss: 0.41993 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1795  | total loss: \u001b[1m\u001b[32m1.39939\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1795 | loss: 1.39939 - acc: 0.6752 | val_loss: 0.41932 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1796  | total loss: \u001b[1m\u001b[32m1.55937\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1796 | loss: 1.55937 - acc: 0.6124 | val_loss: 0.41873 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1797  | total loss: \u001b[1m\u001b[32m1.47540\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1797 | loss: 1.47540 - acc: 0.6512 | val_loss: 0.41835 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1798  | total loss: \u001b[1m\u001b[32m1.60294\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1798 | loss: 1.60294 - acc: 0.6017 | val_loss: 0.41795 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1799  | total loss: \u001b[1m\u001b[32m1.50741\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1799 | loss: 1.50741 - acc: 0.6415 | val_loss: 0.41750 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1800  | total loss: \u001b[1m\u001b[32m1.52131\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1800 | loss: 1.52131 - acc: 0.6367 | val_loss: 0.41710 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: YWJMBZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1801  | total loss: \u001b[1m\u001b[32m1.44720\u001b[0m\u001b[0m | time: 1.228s\n",
      "| Adam | epoch: 1801 | loss: 1.44720 - acc: 0.6684 | val_loss: 0.41653 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1802  | total loss: \u001b[1m\u001b[32m1.56388\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1802 | loss: 1.56388 - acc: 0.6156 | val_loss: 0.41587 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1803  | total loss: \u001b[1m\u001b[32m1.48022\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1803 | loss: 1.48022 - acc: 0.6462 | val_loss: 0.41520 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1804  | total loss: \u001b[1m\u001b[32m1.40643\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1804 | loss: 1.40643 - acc: 0.6769 | val_loss: 0.41505 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1805  | total loss: \u001b[1m\u001b[32m1.57135\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1805 | loss: 1.57135 - acc: 0.6139 | val_loss: 0.41502 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1806  | total loss: \u001b[1m\u001b[32m1.55461\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1806 | loss: 1.55461 - acc: 0.6197 | val_loss: 0.41486 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1807  | total loss: \u001b[1m\u001b[32m1.47209\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1807 | loss: 1.47209 - acc: 0.6515 | val_loss: 0.41510 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1808  | total loss: \u001b[1m\u001b[32m1.61413\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1808 | loss: 1.61413 - acc: 0.5957 | val_loss: 0.41515 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1809  | total loss: \u001b[1m\u001b[32m1.52436\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1809 | loss: 1.52436 - acc: 0.6315 | val_loss: 0.41559 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1810  | total loss: \u001b[1m\u001b[32m1.52886\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1810 | loss: 1.52886 - acc: 0.6292 | val_loss: 0.41562 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 6P6QKO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1811  | total loss: \u001b[1m\u001b[32m1.44608\u001b[0m\u001b[0m | time: 1.224s\n",
      "| Adam | epoch: 1811 | loss: 1.44608 - acc: 0.6616 | val_loss: 0.41525 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1812  | total loss: \u001b[1m\u001b[32m1.57443\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1812 | loss: 1.57443 - acc: 0.6033 | val_loss: 0.41513 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1813  | total loss: \u001b[1m\u001b[32m1.48908\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1813 | loss: 1.48908 - acc: 0.6398 | val_loss: 0.41490 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1814  | total loss: \u001b[1m\u001b[32m1.58545\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1814 | loss: 1.58545 - acc: 0.6040 | val_loss: 0.41464 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1815  | total loss: \u001b[1m\u001b[32m1.49602\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1815 | loss: 1.49602 - acc: 0.6420 | val_loss: 0.41424 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1816  | total loss: \u001b[1m\u001b[32m1.42117\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1816 | loss: 1.42117 - acc: 0.6716 | val_loss: 0.41369 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1817  | total loss: \u001b[1m\u001b[32m1.35289\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1817 | loss: 1.35289 - acc: 0.7028 | val_loss: 0.41350 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1818  | total loss: \u001b[1m\u001b[32m1.49330\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1818 | loss: 1.49330 - acc: 0.6482 | val_loss: 0.41336 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1819  | total loss: \u001b[1m\u001b[32m1.41360\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1819 | loss: 1.41360 - acc: 0.6787 | val_loss: 0.41276 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1820  | total loss: \u001b[1m\u001b[32m1.44978\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1820 | loss: 1.44978 - acc: 0.6655 | val_loss: 0.41221 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: QIZV2I\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1821  | total loss: \u001b[1m\u001b[32m1.37529\u001b[0m\u001b[0m | time: 1.227s\n",
      "| Adam | epoch: 1821 | loss: 1.37529 - acc: 0.6974 | val_loss: 0.41171 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1822  | total loss: \u001b[1m\u001b[32m1.31392\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1822 | loss: 1.31392 - acc: 0.7245 | val_loss: 0.41128 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1823  | total loss: \u001b[1m\u001b[32m1.38160\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1823 | loss: 1.38160 - acc: 0.6974 | val_loss: 0.41091 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1824  | total loss: \u001b[1m\u001b[32m1.40658\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1824 | loss: 1.40658 - acc: 0.6839 | val_loss: 0.41062 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1825  | total loss: \u001b[1m\u001b[32m1.33784\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1825 | loss: 1.33784 - acc: 0.7155 | val_loss: 0.41089 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1826  | total loss: \u001b[1m\u001b[32m1.48306\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1826 | loss: 1.48306 - acc: 0.6580 | val_loss: 0.41112 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1827  | total loss: \u001b[1m\u001b[32m1.40855\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1827 | loss: 1.40855 - acc: 0.6860 | val_loss: 0.41156 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1828  | total loss: \u001b[1m\u001b[32m1.53052\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1828 | loss: 1.53052 - acc: 0.6361 | val_loss: 0.41205 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1829  | total loss: \u001b[1m\u001b[32m1.44527\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1829 | loss: 1.44527 - acc: 0.6725 | val_loss: 0.41254 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1830  | total loss: \u001b[1m\u001b[32m1.46360\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1830 | loss: 1.46360 - acc: 0.6615 | val_loss: 0.41297 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: PAAC2E\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1831  | total loss: \u001b[1m\u001b[32m1.38135\u001b[0m\u001b[0m | time: 1.217s\n",
      "| Adam | epoch: 1831 | loss: 1.38135 - acc: 0.6938 | val_loss: 0.41317 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1832  | total loss: \u001b[1m\u001b[32m1.31649\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1832 | loss: 1.31649 - acc: 0.7213 | val_loss: 0.41324 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1833  | total loss: \u001b[1m\u001b[32m1.25744\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1833 | loss: 1.25744 - acc: 0.7460 | val_loss: 0.41320 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1834  | total loss: \u001b[1m\u001b[32m1.34282\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1834 | loss: 1.34282 - acc: 0.7167 | val_loss: 0.41331 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1835  | total loss: \u001b[1m\u001b[32m1.28491\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1835 | loss: 1.28491 - acc: 0.7404 | val_loss: 0.41326 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1836  | total loss: \u001b[1m\u001b[32m1.33055\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1836 | loss: 1.33055 - acc: 0.7195 | val_loss: 0.41304 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1837  | total loss: \u001b[1m\u001b[32m1.26824\u001b[0m\u001b[0m | time: 1.064s\n",
      "| Adam | epoch: 1837 | loss: 1.26824 - acc: 0.7428 | val_loss: 0.41275 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1838  | total loss: \u001b[1m\u001b[32m1.21143\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1838 | loss: 1.21143 - acc: 0.7623 | val_loss: 0.41236 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1839  | total loss: \u001b[1m\u001b[32m1.15562\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1839 | loss: 1.15562 - acc: 0.7798 | val_loss: 0.41210 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1840  | total loss: \u001b[1m\u001b[32m1.25492\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1840 | loss: 1.25492 - acc: 0.7362 | val_loss: 0.41160 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: LJO6QZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1841  | total loss: \u001b[1m\u001b[32m1.19606\u001b[0m\u001b[0m | time: 1.233s\n",
      "| Adam | epoch: 1841 | loss: 1.19606 - acc: 0.7595 | val_loss: 0.41121 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1842  | total loss: \u001b[1m\u001b[32m1.24718\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1842 | loss: 1.24718 - acc: 0.7445 | val_loss: 0.41073 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1843  | total loss: \u001b[1m\u001b[32m1.19087\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1843 | loss: 1.19087 - acc: 0.7638 | val_loss: 0.41051 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1844  | total loss: \u001b[1m\u001b[32m1.26526\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1844 | loss: 1.26526 - acc: 0.7374 | val_loss: 0.41017 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1845  | total loss: \u001b[1m\u001b[32m1.20945\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1845 | loss: 1.20945 - acc: 0.7605 | val_loss: 0.40990 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1846  | total loss: \u001b[1m\u001b[32m1.15706\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1846 | loss: 1.15706 - acc: 0.7798 | val_loss: 0.40957 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1847  | total loss: \u001b[1m\u001b[32m1.32194\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1847 | loss: 1.32194 - acc: 0.7127 | val_loss: 0.40952 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1848  | total loss: \u001b[1m\u001b[32m1.41144\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1848 | loss: 1.41144 - acc: 0.6680 | val_loss: 0.40917 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1849  | total loss: \u001b[1m\u001b[32m1.33889\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1849 | loss: 1.33889 - acc: 0.6950 | val_loss: 0.40885 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1850  | total loss: \u001b[1m\u001b[32m1.45141\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1850 | loss: 1.45141 - acc: 0.6536 | val_loss: 0.40820 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: OPCO11\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1851  | total loss: \u001b[1m\u001b[32m1.37130\u001b[0m\u001b[0m | time: 1.239s\n",
      "| Adam | epoch: 1851 | loss: 1.37130 - acc: 0.6867 | val_loss: 0.40737 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1852  | total loss: \u001b[1m\u001b[32m1.30294\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1852 | loss: 1.30294 - acc: 0.7118 | val_loss: 0.40672 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1853  | total loss: \u001b[1m\u001b[32m1.45759\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1853 | loss: 1.45759 - acc: 0.6500 | val_loss: 0.40628 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1854  | total loss: \u001b[1m\u001b[32m1.38133\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1854 | loss: 1.38133 - acc: 0.6803 | val_loss: 0.40549 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1855  | total loss: \u001b[1m\u001b[32m1.31458\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1855 | loss: 1.31458 - acc: 0.7044 | val_loss: 0.40499 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1856  | total loss: \u001b[1m\u001b[32m1.47252\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1856 | loss: 1.47252 - acc: 0.6434 | val_loss: 0.40460 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1857  | total loss: \u001b[1m\u001b[32m1.39060\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1857 | loss: 1.39060 - acc: 0.6790 | val_loss: 0.40454 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1858  | total loss: \u001b[1m\u001b[32m1.52212\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1858 | loss: 1.52212 - acc: 0.6314 | val_loss: 0.40434 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1859  | total loss: \u001b[1m\u001b[32m1.43961\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1859 | loss: 1.43961 - acc: 0.6667 | val_loss: 0.40460 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1860  | total loss: \u001b[1m\u001b[32m1.44316\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1860 | loss: 1.44316 - acc: 0.6626 | val_loss: 0.40480 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: AHB0YM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1861  | total loss: \u001b[1m\u001b[32m1.36683\u001b[0m\u001b[0m | time: 1.221s\n",
      "| Adam | epoch: 1861 | loss: 1.36683 - acc: 0.6963 | val_loss: 0.40547 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1862  | total loss: \u001b[1m\u001b[32m1.51468\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1862 | loss: 1.51468 - acc: 0.6345 | val_loss: 0.40626 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1863  | total loss: \u001b[1m\u001b[32m1.43118\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1863 | loss: 1.43118 - acc: 0.6648 | val_loss: 0.40666 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1864  | total loss: \u001b[1m\u001b[32m1.35691\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 1864 | loss: 1.35691 - acc: 0.6936 | val_loss: 0.40741 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1865  | total loss: \u001b[1m\u001b[32m1.47109\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1865 | loss: 1.47109 - acc: 0.6477 | val_loss: 0.40816 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1866  | total loss: \u001b[1m\u001b[32m1.62180\u001b[0m\u001b[0m | time: 1.063s\n",
      "| Adam | epoch: 1866 | loss: 1.62180 - acc: 0.5892 | val_loss: 0.40810 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1867  | total loss: \u001b[1m\u001b[32m1.52855\u001b[0m\u001b[0m | time: 1.071s\n",
      "| Adam | epoch: 1867 | loss: 1.52855 - acc: 0.6287 | val_loss: 0.40837 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1868  | total loss: \u001b[1m\u001b[32m1.56657\u001b[0m\u001b[0m | time: 1.074s\n",
      "| Adam | epoch: 1868 | loss: 1.56657 - acc: 0.6143 | val_loss: 0.40850 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1869  | total loss: \u001b[1m\u001b[32m1.47795\u001b[0m\u001b[0m | time: 1.066s\n",
      "| Adam | epoch: 1869 | loss: 1.47795 - acc: 0.6497 | val_loss: 0.40791 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1870  | total loss: \u001b[1m\u001b[32m1.49756\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1870 | loss: 1.49756 - acc: 0.6441 | val_loss: 0.40722 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: VZCW06\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1871  | total loss: \u001b[1m\u001b[32m1.41773\u001b[0m\u001b[0m | time: 1.226s\n",
      "| Adam | epoch: 1871 | loss: 1.41773 - acc: 0.6750 | val_loss: 0.40575 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1872  | total loss: \u001b[1m\u001b[32m1.45583\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1872 | loss: 1.45583 - acc: 0.6669 | val_loss: 0.40377 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1873  | total loss: \u001b[1m\u001b[32m1.37679\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1873 | loss: 1.37679 - acc: 0.6955 | val_loss: 0.40209 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1874  | total loss: \u001b[1m\u001b[32m1.45119\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1874 | loss: 1.45119 - acc: 0.6682 | val_loss: 0.40025 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1875  | total loss: \u001b[1m\u001b[32m1.37612\u001b[0m\u001b[0m | time: 1.075s\n",
      "| Adam | epoch: 1875 | loss: 1.37612 - acc: 0.6982 | val_loss: 0.39875 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1876  | total loss: \u001b[1m\u001b[32m1.50970\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1876 | loss: 1.50970 - acc: 0.6440 | val_loss: 0.39695 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1877  | total loss: \u001b[1m\u001b[32m1.42722\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1877 | loss: 1.42722 - acc: 0.6749 | val_loss: 0.39572 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1878  | total loss: \u001b[1m\u001b[32m1.58449\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1878 | loss: 1.58449 - acc: 0.6106 | val_loss: 0.39477 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1879  | total loss: \u001b[1m\u001b[32m1.49938\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1879 | loss: 1.49938 - acc: 0.6448 | val_loss: 0.39359 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1880  | total loss: \u001b[1m\u001b[32m1.51165\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1880 | loss: 1.51165 - acc: 0.6381 | val_loss: 0.39242 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 0J3KCZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1881  | total loss: \u001b[1m\u001b[32m1.42772\u001b[0m\u001b[0m | time: 1.219s\n",
      "| Adam | epoch: 1881 | loss: 1.42772 - acc: 0.6712 | val_loss: 0.39174 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1882  | total loss: \u001b[1m\u001b[32m1.57533\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1882 | loss: 1.57533 - acc: 0.6150 | val_loss: 0.39136 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1883  | total loss: \u001b[1m\u001b[32m1.48035\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1883 | loss: 1.48035 - acc: 0.6504 | val_loss: 0.39124 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1884  | total loss: \u001b[1m\u001b[32m1.61955\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1884 | loss: 1.61955 - acc: 0.5979 | val_loss: 0.39101 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1885  | total loss: \u001b[1m\u001b[32m1.52243\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1885 | loss: 1.52243 - acc: 0.6349 | val_loss: 0.39106 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1886  | total loss: \u001b[1m\u001b[32m1.56561\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1886 | loss: 1.56561 - acc: 0.6152 | val_loss: 0.39098 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1887  | total loss: \u001b[1m\u001b[32m1.47846\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1887 | loss: 1.47846 - acc: 0.6490 | val_loss: 0.39116 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1888  | total loss: \u001b[1m\u001b[32m1.63059\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1888 | loss: 1.63059 - acc: 0.5888 | val_loss: 0.39136 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1889  | total loss: \u001b[1m\u001b[32m1.54142\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1889 | loss: 1.54142 - acc: 0.6252 | val_loss: 0.39191 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1890  | total loss: \u001b[1m\u001b[32m1.52478\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1890 | loss: 1.52478 - acc: 0.6314 | val_loss: 0.39226 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 93TYZ6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1891  | total loss: \u001b[1m\u001b[32m1.43749\u001b[0m\u001b[0m | time: 1.223s\n",
      "| Adam | epoch: 1891 | loss: 1.43749 - acc: 0.6683 | val_loss: 0.39221 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1892  | total loss: \u001b[1m\u001b[32m1.35944\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1892 | loss: 1.35944 - acc: 0.6999 | val_loss: 0.39254 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1893  | total loss: \u001b[1m\u001b[32m1.52276\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1893 | loss: 1.52276 - acc: 0.6393 | val_loss: 0.39272 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1894  | total loss: \u001b[1m\u001b[32m1.65174\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1894 | loss: 1.65174 - acc: 0.5847 | val_loss: 0.39260 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1895  | total loss: \u001b[1m\u001b[32m1.55493\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1895 | loss: 1.55493 - acc: 0.6231 | val_loss: 0.39305 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1896  | total loss: \u001b[1m\u001b[32m1.64247\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1896 | loss: 1.64247 - acc: 0.5905 | val_loss: 0.39333 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1897  | total loss: \u001b[1m\u001b[32m1.54730\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1897 | loss: 1.54730 - acc: 0.6299 | val_loss: 0.39385 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1898  | total loss: \u001b[1m\u001b[32m1.66191\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1898 | loss: 1.66191 - acc: 0.5810 | val_loss: 0.39409 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1899  | total loss: \u001b[1m\u001b[32m1.56494\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1899 | loss: 1.56494 - acc: 0.6197 | val_loss: 0.39492 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1900  | total loss: \u001b[1m\u001b[32m1.69023\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1900 | loss: 1.69023 - acc: 0.5687 | val_loss: 0.39559 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: HGI39W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1901  | total loss: \u001b[1m\u001b[32m1.58806\u001b[0m\u001b[0m | time: 1.225s\n",
      "| Adam | epoch: 1901 | loss: 1.58806 - acc: 0.6118 | val_loss: 0.39658 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1902  | total loss: \u001b[1m\u001b[32m1.68900\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1902 | loss: 1.68900 - acc: 0.5663 | val_loss: 0.39753 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1903  | total loss: \u001b[1m\u001b[32m1.58917\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1903 | loss: 1.58917 - acc: 0.6065 | val_loss: 0.39913 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1904  | total loss: \u001b[1m\u001b[32m1.72406\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1904 | loss: 1.72406 - acc: 0.5568 | val_loss: 0.40048 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1905  | total loss: \u001b[1m\u001b[32m1.61800\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1905 | loss: 1.61800 - acc: 0.6011 | val_loss: 0.40123 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1906  | total loss: \u001b[1m\u001b[32m1.52715\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1906 | loss: 1.52715 - acc: 0.6379 | val_loss: 0.40201 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1907  | total loss: \u001b[1m\u001b[32m1.67040\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1907 | loss: 1.67040 - acc: 0.5788 | val_loss: 0.40249 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1908  | total loss: \u001b[1m\u001b[32m1.70540\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 1908 | loss: 1.70540 - acc: 0.5694 | val_loss: 0.40233 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1909  | total loss: \u001b[1m\u001b[32m1.60112\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1909 | loss: 1.60112 - acc: 0.6093 | val_loss: 0.40205 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1910  | total loss: \u001b[1m\u001b[32m1.72079\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1910 | loss: 1.72079 - acc: 0.5593 | val_loss: 0.40123 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: JGRADI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1911  | total loss: \u001b[1m\u001b[32m1.61932\u001b[0m\u001b[0m | time: 1.236s\n",
      "| Adam | epoch: 1911 | loss: 1.61932 - acc: 0.6002 | val_loss: 0.39986 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1912  | total loss: \u001b[1m\u001b[32m1.52644\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1912 | loss: 1.52644 - acc: 0.6355 | val_loss: 0.39874 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1913  | total loss: \u001b[1m\u001b[32m1.44477\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1913 | loss: 1.44477 - acc: 0.6704 | val_loss: 0.39830 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1914  | total loss: \u001b[1m\u001b[32m1.50962\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1914 | loss: 1.50962 - acc: 0.6440 | val_loss: 0.39742 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1915  | total loss: \u001b[1m\u001b[32m1.42920\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1915 | loss: 1.42920 - acc: 0.6765 | val_loss: 0.39624 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1916  | total loss: \u001b[1m\u001b[32m1.44793\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1916 | loss: 1.44793 - acc: 0.6682 | val_loss: 0.39496 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1917  | total loss: \u001b[1m\u001b[32m1.37320\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1917 | loss: 1.37320 - acc: 0.6951 | val_loss: 0.39388 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1918  | total loss: \u001b[1m\u001b[32m1.52787\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1918 | loss: 1.52787 - acc: 0.6350 | val_loss: 0.39285 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1919  | total loss: \u001b[1m\u001b[32m1.44300\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1919 | loss: 1.44300 - acc: 0.6699 | val_loss: 0.39220 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1920  | total loss: \u001b[1m\u001b[32m1.57051\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1920 | loss: 1.57051 - acc: 0.6201 | val_loss: 0.39137 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 66RKG5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1921  | total loss: \u001b[1m\u001b[32m1.48344\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 1921 | loss: 1.48344 - acc: 0.6550 | val_loss: 0.39080 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1922  | total loss: \u001b[1m\u001b[32m1.61469\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1922 | loss: 1.61469 - acc: 0.6067 | val_loss: 0.39018 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1923  | total loss: \u001b[1m\u001b[32m1.52129\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1923 | loss: 1.52129 - acc: 0.6460 | val_loss: 0.38947 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1924  | total loss: \u001b[1m\u001b[32m1.43698\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1924 | loss: 1.43698 - acc: 0.6752 | val_loss: 0.38891 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1925  | total loss: \u001b[1m\u001b[32m1.36376\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1925 | loss: 1.36376 - acc: 0.7045 | val_loss: 0.38846 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1926  | total loss: \u001b[1m\u001b[32m1.41231\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1926 | loss: 1.41231 - acc: 0.6841 | val_loss: 0.38756 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1927  | total loss: \u001b[1m\u001b[32m1.34335\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 1927 | loss: 1.34335 - acc: 0.7125 | val_loss: 0.38656 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1928  | total loss: \u001b[1m\u001b[32m1.27465\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1928 | loss: 1.27465 - acc: 0.7397 | val_loss: 0.38572 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1929  | total loss: \u001b[1m\u001b[32m1.21659\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 1929 | loss: 1.21659 - acc: 0.7611 | val_loss: 0.38547 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1930  | total loss: \u001b[1m\u001b[32m1.34859\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1930 | loss: 1.34859 - acc: 0.7037 | val_loss: 0.38502 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: U8F47E\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1931  | total loss: \u001b[1m\u001b[32m1.27940\u001b[0m\u001b[0m | time: 1.231s\n",
      "| Adam | epoch: 1931 | loss: 1.27940 - acc: 0.7318 | val_loss: 0.38436 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1932  | total loss: \u001b[1m\u001b[32m1.22139\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1932 | loss: 1.22139 - acc: 0.7570 | val_loss: 0.38369 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1933  | total loss: \u001b[1m\u001b[32m1.17522\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1933 | loss: 1.17522 - acc: 0.7751 | val_loss: 0.38291 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1934  | total loss: \u001b[1m\u001b[32m1.12343\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1934 | loss: 1.12343 - acc: 0.7960 | val_loss: 0.38176 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1935  | total loss: \u001b[1m\u001b[32m1.20211\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1935 | loss: 1.20211 - acc: 0.7633 | val_loss: 0.38078 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1936  | total loss: \u001b[1m\u001b[32m1.37129\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1936 | loss: 1.37129 - acc: 0.6995 | val_loss: 0.38004 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1937  | total loss: \u001b[1m\u001b[32m1.30064\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1937 | loss: 1.30064 - acc: 0.7279 | val_loss: 0.38004 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1938  | total loss: \u001b[1m\u001b[32m1.46109\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1938 | loss: 1.46109 - acc: 0.6692 | val_loss: 0.38027 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1939  | total loss: \u001b[1m\u001b[32m1.38535\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1939 | loss: 1.38535 - acc: 0.6960 | val_loss: 0.38061 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1940  | total loss: \u001b[1m\u001b[32m1.53106\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1940 | loss: 1.53106 - acc: 0.6421 | val_loss: 0.38106 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: HWMCPS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1941  | total loss: \u001b[1m\u001b[32m1.45233\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1941 | loss: 1.45233 - acc: 0.6700 | val_loss: 0.38173 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1942  | total loss: \u001b[1m\u001b[32m1.49850\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1942 | loss: 1.49850 - acc: 0.6562 | val_loss: 0.38212 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1943  | total loss: \u001b[1m\u001b[32m1.42109\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 1943 | loss: 1.42109 - acc: 0.6890 | val_loss: 0.38259 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1944  | total loss: \u001b[1m\u001b[32m1.53126\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1944 | loss: 1.53126 - acc: 0.6420 | val_loss: 0.38276 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1945  | total loss: \u001b[1m\u001b[32m1.44540\u001b[0m\u001b[0m | time: 1.061s\n",
      "| Adam | epoch: 1945 | loss: 1.44540 - acc: 0.6762 | val_loss: 0.38328 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1946  | total loss: \u001b[1m\u001b[32m1.57426\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1946 | loss: 1.57426 - acc: 0.6242 | val_loss: 0.38361 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1947  | total loss: \u001b[1m\u001b[32m1.48238\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1947 | loss: 1.48238 - acc: 0.6618 | val_loss: 0.38367 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1948  | total loss: \u001b[1m\u001b[32m1.56710\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1948 | loss: 1.56710 - acc: 0.6284 | val_loss: 0.38360 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1949  | total loss: \u001b[1m\u001b[32m1.47483\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1949 | loss: 1.47483 - acc: 0.6625 | val_loss: 0.38364 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1950  | total loss: \u001b[1m\u001b[32m1.53843\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1950 | loss: 1.53843 - acc: 0.6321 | val_loss: 0.38362 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: CHKQX3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1951  | total loss: \u001b[1m\u001b[32m1.44670\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1951 | loss: 1.44670 - acc: 0.6642 | val_loss: 0.38383 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1952  | total loss: \u001b[1m\u001b[32m1.59349\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1952 | loss: 1.59349 - acc: 0.6072 | val_loss: 0.38382 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1953  | total loss: \u001b[1m\u001b[32m1.50135\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1953 | loss: 1.50135 - acc: 0.6465 | val_loss: 0.38394 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1954  | total loss: \u001b[1m\u001b[32m1.55178\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1954 | loss: 1.55178 - acc: 0.6303 | val_loss: 0.38387 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1955  | total loss: \u001b[1m\u001b[32m1.45948\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1955 | loss: 1.45948 - acc: 0.6641 | val_loss: 0.38378 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1956  | total loss: \u001b[1m\u001b[32m1.57317\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1956 | loss: 1.57317 - acc: 0.6149 | val_loss: 0.38346 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1957  | total loss: \u001b[1m\u001b[32m1.48530\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1957 | loss: 1.48530 - acc: 0.6503 | val_loss: 0.38334 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1958  | total loss: \u001b[1m\u001b[32m1.63472\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1958 | loss: 1.63472 - acc: 0.5946 | val_loss: 0.38322 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1959  | total loss: \u001b[1m\u001b[32m1.54061\u001b[0m\u001b[0m | time: 1.071s\n",
      "| Adam | epoch: 1959 | loss: 1.54061 - acc: 0.6352 | val_loss: 0.38318 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1960  | total loss: \u001b[1m\u001b[32m1.64875\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1960 | loss: 1.64875 - acc: 0.5920 | val_loss: 0.38292 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 8I94A1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1961  | total loss: \u001b[1m\u001b[32m1.54696\u001b[0m\u001b[0m | time: 1.217s\n",
      "| Adam | epoch: 1961 | loss: 1.54696 - acc: 0.6328 | val_loss: 0.38243 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1962  | total loss: \u001b[1m\u001b[32m1.46145\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1962 | loss: 1.46145 - acc: 0.6632 | val_loss: 0.38158 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1963  | total loss: \u001b[1m\u001b[32m1.38269\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1963 | loss: 1.38269 - acc: 0.6907 | val_loss: 0.38101 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1964  | total loss: \u001b[1m\u001b[32m1.55704\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1964 | loss: 1.55704 - acc: 0.6247 | val_loss: 0.38037 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1965  | total loss: \u001b[1m\u001b[32m1.46711\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1965 | loss: 1.46711 - acc: 0.6622 | val_loss: 0.37959 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1966  | total loss: \u001b[1m\u001b[32m1.52712\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1966 | loss: 1.52712 - acc: 0.6413 | val_loss: 0.37865 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1967  | total loss: \u001b[1m\u001b[32m1.44326\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1967 | loss: 1.44326 - acc: 0.6741 | val_loss: 0.37766 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1968  | total loss: \u001b[1m\u001b[32m1.36446\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1968 | loss: 1.36446 - acc: 0.7067 | val_loss: 0.37687 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1969  | total loss: \u001b[1m\u001b[32m1.43295\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1969 | loss: 1.43295 - acc: 0.6766 | val_loss: 0.37606 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1970  | total loss: \u001b[1m\u001b[32m1.42687\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1970 | loss: 1.42687 - acc: 0.6793 | val_loss: 0.37531 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: RF4XCO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1971  | total loss: \u001b[1m\u001b[32m1.36132\u001b[0m\u001b[0m | time: 1.220s\n",
      "| Adam | epoch: 1971 | loss: 1.36132 - acc: 0.7020 | val_loss: 0.37481 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1972  | total loss: \u001b[1m\u001b[32m1.40572\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1972 | loss: 1.40572 - acc: 0.6912 | val_loss: 0.37408 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1973  | total loss: \u001b[1m\u001b[32m1.33405\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1973 | loss: 1.33405 - acc: 0.7189 | val_loss: 0.37374 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1974  | total loss: \u001b[1m\u001b[32m1.35208\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1974 | loss: 1.35208 - acc: 0.7111 | val_loss: 0.37339 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1975  | total loss: \u001b[1m\u001b[32m1.28152\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1975 | loss: 1.28152 - acc: 0.7384 | val_loss: 0.37300 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1976  | total loss: \u001b[1m\u001b[32m1.42873\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1976 | loss: 1.42873 - acc: 0.6771 | val_loss: 0.37281 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1977  | total loss: \u001b[1m\u001b[32m1.35575\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1977 | loss: 1.35575 - acc: 0.7047 | val_loss: 0.37279 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1978  | total loss: \u001b[1m\u001b[32m1.51064\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1978 | loss: 1.51064 - acc: 0.6451 | val_loss: 0.37256 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1979  | total loss: \u001b[1m\u001b[32m1.42908\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1979 | loss: 1.42908 - acc: 0.6759 | val_loss: 0.37218 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1980  | total loss: \u001b[1m\u001b[32m1.46606\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1980 | loss: 1.46606 - acc: 0.6615 | val_loss: 0.37174 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 4VORIL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1981  | total loss: \u001b[1m\u001b[32m1.38636\u001b[0m\u001b[0m | time: 1.211s\n",
      "| Adam | epoch: 1981 | loss: 1.38636 - acc: 0.6938 | val_loss: 0.37128 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1982  | total loss: \u001b[1m\u001b[32m1.31233\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1982 | loss: 1.31233 - acc: 0.7228 | val_loss: 0.37097 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1983  | total loss: \u001b[1m\u001b[32m1.45598\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1983 | loss: 1.45598 - acc: 0.6615 | val_loss: 0.37053 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1984  | total loss: \u001b[1m\u001b[32m1.37452\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1984 | loss: 1.37452 - acc: 0.6953 | val_loss: 0.37005 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1985  | total loss: \u001b[1m\u001b[32m1.29853\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1985 | loss: 1.29853 - acc: 0.7258 | val_loss: 0.36958 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1986  | total loss: \u001b[1m\u001b[32m1.45466\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1986 | loss: 1.45466 - acc: 0.6642 | val_loss: 0.36903 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1987  | total loss: \u001b[1m\u001b[32m1.37265\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1987 | loss: 1.37265 - acc: 0.6977 | val_loss: 0.36905 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1988  | total loss: \u001b[1m\u001b[32m1.51169\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1988 | loss: 1.51169 - acc: 0.6420 | val_loss: 0.36888 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1989  | total loss: \u001b[1m\u001b[32m1.42514\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1989 | loss: 1.42514 - acc: 0.6778 | val_loss: 0.36888 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1990  | total loss: \u001b[1m\u001b[32m1.44774\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1990 | loss: 1.44774 - acc: 0.6679 | val_loss: 0.36857 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: 63G3KI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 1991  | total loss: \u001b[1m\u001b[32m1.36840\u001b[0m\u001b[0m | time: 1.232s\n",
      "| Adam | epoch: 1991 | loss: 1.36840 - acc: 0.7011 | val_loss: 0.36809 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1992  | total loss: \u001b[1m\u001b[32m1.29799\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1992 | loss: 1.29799 - acc: 0.7294 | val_loss: 0.36803 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1993  | total loss: \u001b[1m\u001b[32m1.38633\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1993 | loss: 1.38633 - acc: 0.6893 | val_loss: 0.36786 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1994  | total loss: \u001b[1m\u001b[32m1.31012\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1994 | loss: 1.31012 - acc: 0.7188 | val_loss: 0.36787 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1995  | total loss: \u001b[1m\u001b[32m1.35313\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1995 | loss: 1.35313 - acc: 0.7000 | val_loss: 0.36791 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1996  | total loss: \u001b[1m\u001b[32m1.28203\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1996 | loss: 1.28203 - acc: 0.7269 | val_loss: 0.36789 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1997  | total loss: \u001b[1m\u001b[32m1.22114\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1997 | loss: 1.22114 - acc: 0.7511 | val_loss: 0.36805 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1998  | total loss: \u001b[1m\u001b[32m1.36241\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1998 | loss: 1.36241 - acc: 0.6932 | val_loss: 0.36809 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 1999  | total loss: \u001b[1m\u001b[32m1.28799\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1999 | loss: 1.28799 - acc: 0.7223 | val_loss: 0.36801 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2000  | total loss: \u001b[1m\u001b[32m1.44090\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 2000 | loss: 1.44090 - acc: 0.6610 | val_loss: 0.36791 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: OQSORF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 2001  | total loss: \u001b[1m\u001b[32m1.35753\u001b[0m\u001b[0m | time: 1.222s\n",
      "| Adam | epoch: 2001 | loss: 1.35753 - acc: 0.6949 | val_loss: 0.36775 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2002  | total loss: \u001b[1m\u001b[32m1.28819\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 2002 | loss: 1.28819 - acc: 0.7207 | val_loss: 0.36753 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2003  | total loss: \u001b[1m\u001b[32m1.22404\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 2003 | loss: 1.22404 - acc: 0.7486 | val_loss: 0.36708 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2004  | total loss: \u001b[1m\u001b[32m1.31281\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 2004 | loss: 1.31281 - acc: 0.7128 | val_loss: 0.36644 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2005  | total loss: \u001b[1m\u001b[32m1.24211\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 2005 | loss: 1.24211 - acc: 0.7384 | val_loss: 0.36575 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2006  | total loss: \u001b[1m\u001b[32m1.17689\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 2006 | loss: 1.17689 - acc: 0.7646 | val_loss: 0.36520 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2007  | total loss: \u001b[1m\u001b[32m1.12916\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 2007 | loss: 1.12916 - acc: 0.7850 | val_loss: 0.36453 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2008  | total loss: \u001b[1m\u001b[32m1.20900\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 2008 | loss: 1.20900 - acc: 0.7503 | val_loss: 0.36367 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2009  | total loss: \u001b[1m\u001b[32m1.15200\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 2009 | loss: 1.15200 - acc: 0.7737 | val_loss: 0.36310 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2010  | total loss: \u001b[1m\u001b[32m1.34831\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 2010 | loss: 1.34831 - acc: 0.7041 | val_loss: 0.36249 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: RGFSQ2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 2011  | total loss: \u001b[1m\u001b[32m1.27754\u001b[0m\u001b[0m | time: 1.222s\n",
      "| Adam | epoch: 2011 | loss: 1.27754 - acc: 0.7321 | val_loss: 0.36167 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2012  | total loss: \u001b[1m\u001b[32m1.22055\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 2012 | loss: 1.22055 - acc: 0.7542 | val_loss: 0.36123 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2013  | total loss: \u001b[1m\u001b[32m1.39188\u001b[0m\u001b[0m | time: 1.070s\n",
      "| Adam | epoch: 2013 | loss: 1.39188 - acc: 0.6882 | val_loss: 0.36107 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2014  | total loss: \u001b[1m\u001b[32m1.41394\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 2014 | loss: 1.41394 - acc: 0.6787 | val_loss: 0.36101 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2015  | total loss: \u001b[1m\u001b[32m1.33562\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 2015 | loss: 1.33562 - acc: 0.7077 | val_loss: 0.36098 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2016  | total loss: \u001b[1m\u001b[32m1.26237\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 2016 | loss: 1.26237 - acc: 0.7354 | val_loss: 0.36074 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2017  | total loss: \u001b[1m\u001b[32m1.42197\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 2017 | loss: 1.42197 - acc: 0.6728 | val_loss: 0.36088 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2018  | total loss: \u001b[1m\u001b[32m1.52670\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 2018 | loss: 1.52670 - acc: 0.6305 | val_loss: 0.36087 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2019  | total loss: \u001b[1m\u001b[32m1.43794\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 2019 | loss: 1.43794 - acc: 0.6675 | val_loss: 0.36077 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2020  | total loss: \u001b[1m\u001b[32m1.58716\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 2020 | loss: 1.58716 - acc: 0.6085 | val_loss: 0.36055 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: MBYKZX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 2021  | total loss: \u001b[1m\u001b[32m1.49638\u001b[0m\u001b[0m | time: 1.213s\n",
      "| Adam | epoch: 2021 | loss: 1.49638 - acc: 0.6461 | val_loss: 0.35996 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2022  | total loss: \u001b[1m\u001b[32m1.50976\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 2022 | loss: 1.50976 - acc: 0.6440 | val_loss: 0.35942 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2023  | total loss: \u001b[1m\u001b[32m1.42369\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 2023 | loss: 1.42369 - acc: 0.6780 | val_loss: 0.35908 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2024  | total loss: \u001b[1m\u001b[32m1.56286\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 2024 | loss: 1.56286 - acc: 0.6196 | val_loss: 0.35868 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2025  | total loss: \u001b[1m\u001b[32m1.47245\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 2025 | loss: 1.47245 - acc: 0.6545 | val_loss: 0.35813 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2026  | total loss: \u001b[1m\u001b[32m1.61868\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 2026 | loss: 1.61868 - acc: 0.6000 | val_loss: 0.35757 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2027  | total loss: \u001b[1m\u001b[32m1.51870\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 2027 | loss: 1.51870 - acc: 0.6369 | val_loss: 0.35692 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2028  | total loss: \u001b[1m\u001b[32m1.66220\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 2028 | loss: 1.66220 - acc: 0.5826 | val_loss: 0.35640 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2029  | total loss: \u001b[1m\u001b[32m1.55903\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 2029 | loss: 1.55903 - acc: 0.6228 | val_loss: 0.35578 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2030  | total loss: \u001b[1m\u001b[32m1.58342\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 2030 | loss: 1.58342 - acc: 0.6167 | val_loss: 0.35537 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "---------------------------------\n",
      "Run id: CV9BMH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 64\n",
      "Validation samples: 64\n",
      "--\n",
      "Training Step: 2031  | total loss: \u001b[1m\u001b[32m1.48033\u001b[0m\u001b[0m | time: 1.243s\n",
      "| Adam | epoch: 2031 | loss: 1.48033 - acc: 0.6535 | val_loss: 0.35512 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2032  | total loss: \u001b[1m\u001b[32m1.63458\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 2032 | loss: 1.63458 - acc: 0.5928 | val_loss: 0.35474 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2033  | total loss: \u001b[1m\u001b[32m1.54141\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 2033 | loss: 1.54141 - acc: 0.6289 | val_loss: 0.35427 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2034  | total loss: \u001b[1m\u001b[32m1.44888\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 2034 | loss: 1.44888 - acc: 0.6644 | val_loss: 0.35400 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2035  | total loss: \u001b[1m\u001b[32m1.37225\u001b[0m\u001b[0m | time: 1.056s\n",
      "| Adam | epoch: 2035 | loss: 1.37225 - acc: 0.6933 | val_loss: 0.35416 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2036  | total loss: \u001b[1m\u001b[32m1.51951\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 2036 | loss: 1.51951 - acc: 0.6349 | val_loss: 0.35446 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2037  | total loss: \u001b[1m\u001b[32m1.43266\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 2037 | loss: 1.43266 - acc: 0.6683 | val_loss: 0.35452 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n",
      "Training Step: 2038  | total loss: \u001b[1m\u001b[32m1.35469\u001b[0m\u001b[0m | time: 1.055s\n",
      "| Adam | epoch: 2038 | loss: 1.35469 - acc: 0.6999 | val_loss: 0.35448 - val_acc: 1.0000 -- iter: 64/64\n",
      "--\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4b8e92f0f841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tflearn.lstm.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3-tf/lib/python3.6/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    213\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                          callbacks=callbacks)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3-tf/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[1;32m    334\u001b[0m                                                        \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                                                        show_metric)\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                             \u001b[0;31m# Update training state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3-tf/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_metric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0meval_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_metric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3-tf/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mevaluate_flow\u001b[0;34m(session, ops_to_evaluate, dataflow)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcurrent_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m             \u001b[0mfeed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3-tf/lib/python3.6/site-packages/tflearn/data_flow.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3-tf/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3-tf/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(2000):\n",
    "    model.fit(trainX, trainY, n_epoch = 10, validation_set = (testX, testY), show_metric = True, batch_size = BATCH_SIZE)\n",
    "    _y = model.predict(x)\n",
    "model.save('tflearn.lstm.model')\n",
    "print(_y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
