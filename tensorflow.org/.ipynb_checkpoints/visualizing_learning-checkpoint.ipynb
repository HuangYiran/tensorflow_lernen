{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations in Tensorflow don't do anything until you run them, or an op that depends on their output. And the summary nodes that we've just created are peripheral to your graph: none of the ops you  are currently running depend on them. So, to generate summaries, we need to run all of these summary nodes. Managing them by hand would be tedious, so use tf.summary.merge_all to combine them into a single op that generates all the summary data.<br>\n",
    "Then, you can just run the merged summary op, which wll generae a serialized Summary protobuf objet with all of your summary data at a given step. Finally, to write this summary data to disk, pass the summary protobuf to a tf.summary.FileWriter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name, act = tf.nn.relu):\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.random_normal([output_dim]))\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "            tf.summary.histogram('pre_activation', preactivate)\n",
    "        activations = act(preactivate, name = 'activation')\n",
    "        tf.summary.histogram('activations', activations)\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden1 = nn_layer(x, 784, 500, 'layer1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    tf.summary.scalar('dropout_keep_probability', keep_prob)\n",
    "    dropped = tf.nn.dropout(hidden1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = nn_layer(dropped, 500, 10, 'layer2', act = tf.identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    with tf.name_scope('total'):\n",
    "        diff = tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y)\n",
    "        cross_entropy = tf.reduce_mean(diff)\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at step 0: 0.05\n",
      "Accuracy at step 10: 0.03\n",
      "Accuracy at step 20: 0.03\n",
      "Accuracy at step 30: 0.06\n",
      "Accuracy at step 40: 0.05\n",
      "Accuracy at step 50: 0.08\n",
      "Accuracy at step 60: 0.07\n",
      "Accuracy at step 70: 0.07\n",
      "Accuracy at step 80: 0.1\n",
      "Accuracy at step 90: 0.08\n",
      "Accuracy at step 100: 0.06\n",
      "Accuracy at step 110: 0.1\n",
      "Accuracy at step 120: 0.08\n",
      "Accuracy at step 130: 0.11\n",
      "Accuracy at step 140: 0.09\n",
      "Accuracy at step 150: 0.08\n",
      "Accuracy at step 160: 0.08\n",
      "Accuracy at step 170: 0.08\n",
      "Accuracy at step 180: 0.05\n",
      "Accuracy at step 190: 0.15\n",
      "Accuracy at step 200: 0.16\n",
      "Accuracy at step 210: 0.12\n",
      "Accuracy at step 220: 0.18\n",
      "Accuracy at step 230: 0.16\n",
      "Accuracy at step 240: 0.09\n",
      "Accuracy at step 250: 0.1\n",
      "Accuracy at step 260: 0.14\n",
      "Accuracy at step 270: 0.17\n",
      "Accuracy at step 280: 0.14\n",
      "Accuracy at step 290: 0.14\n",
      "Accuracy at step 300: 0.18\n",
      "Accuracy at step 310: 0.12\n",
      "Accuracy at step 320: 0.21\n",
      "Accuracy at step 330: 0.22\n",
      "Accuracy at step 340: 0.18\n",
      "Accuracy at step 350: 0.17\n",
      "Accuracy at step 360: 0.26\n",
      "Accuracy at step 370: 0.16\n",
      "Accuracy at step 380: 0.23\n",
      "Accuracy at step 390: 0.25\n",
      "Accuracy at step 400: 0.25\n",
      "Accuracy at step 410: 0.2\n",
      "Accuracy at step 420: 0.31\n",
      "Accuracy at step 430: 0.28\n",
      "Accuracy at step 440: 0.21\n",
      "Accuracy at step 450: 0.27\n",
      "Accuracy at step 460: 0.31\n",
      "Accuracy at step 470: 0.29\n",
      "Accuracy at step 480: 0.3\n",
      "Accuracy at step 490: 0.35\n",
      "Accuracy at step 500: 0.27\n",
      "Accuracy at step 510: 0.34\n",
      "Accuracy at step 520: 0.35\n",
      "Accuracy at step 530: 0.28\n",
      "Accuracy at step 540: 0.3\n",
      "Accuracy at step 550: 0.33\n",
      "Accuracy at step 560: 0.42\n",
      "Accuracy at step 570: 0.3\n",
      "Accuracy at step 580: 0.32\n",
      "Accuracy at step 590: 0.33\n",
      "Accuracy at step 600: 0.37\n",
      "Accuracy at step 610: 0.35\n",
      "Accuracy at step 620: 0.47\n",
      "Accuracy at step 630: 0.33\n",
      "Accuracy at step 640: 0.33\n",
      "Accuracy at step 650: 0.43\n",
      "Accuracy at step 660: 0.37\n",
      "Accuracy at step 670: 0.41\n",
      "Accuracy at step 680: 0.46\n",
      "Accuracy at step 690: 0.44\n",
      "Accuracy at step 700: 0.43\n",
      "Accuracy at step 710: 0.48\n",
      "Accuracy at step 720: 0.43\n",
      "Accuracy at step 730: 0.5\n",
      "Accuracy at step 740: 0.47\n",
      "Accuracy at step 750: 0.5\n",
      "Accuracy at step 760: 0.43\n",
      "Accuracy at step 770: 0.42\n",
      "Accuracy at step 780: 0.47\n",
      "Accuracy at step 790: 0.52\n",
      "Accuracy at step 800: 0.6\n",
      "Accuracy at step 810: 0.53\n",
      "Accuracy at step 820: 0.49\n",
      "Accuracy at step 830: 0.46\n",
      "Accuracy at step 840: 0.56\n",
      "Accuracy at step 850: 0.56\n",
      "Accuracy at step 860: 0.58\n",
      "Accuracy at step 870: 0.54\n",
      "Accuracy at step 880: 0.58\n",
      "Accuracy at step 890: 0.52\n",
      "Accuracy at step 900: 0.52\n",
      "Accuracy at step 910: 0.55\n",
      "Accuracy at step 920: 0.53\n",
      "Accuracy at step 930: 0.66\n",
      "Accuracy at step 940: 0.63\n",
      "Accuracy at step 950: 0.6\n",
      "Accuracy at step 960: 0.5\n",
      "Accuracy at step 970: 0.62\n",
      "Accuracy at step 980: 0.58\n",
      "Accuracy at step 990: 0.6\n",
      "Accuracy at step 1000: 0.58\n",
      "Accuracy at step 1010: 0.65\n",
      "Accuracy at step 1020: 0.57\n",
      "Accuracy at step 1030: 0.62\n",
      "Accuracy at step 1040: 0.62\n",
      "Accuracy at step 1050: 0.58\n",
      "Accuracy at step 1060: 0.68\n",
      "Accuracy at step 1070: 0.62\n",
      "Accuracy at step 1080: 0.69\n",
      "Accuracy at step 1090: 0.61\n",
      "Accuracy at step 1100: 0.6\n",
      "Accuracy at step 1110: 0.57\n",
      "Accuracy at step 1120: 0.62\n",
      "Accuracy at step 1130: 0.65\n",
      "Accuracy at step 1140: 0.71\n",
      "Accuracy at step 1150: 0.64\n",
      "Accuracy at step 1160: 0.71\n",
      "Accuracy at step 1170: 0.67\n",
      "Accuracy at step 1180: 0.6\n",
      "Accuracy at step 1190: 0.59\n",
      "Accuracy at step 1200: 0.6\n",
      "Accuracy at step 1210: 0.61\n",
      "Accuracy at step 1220: 0.6\n",
      "Accuracy at step 1230: 0.65\n",
      "Accuracy at step 1240: 0.57\n",
      "Accuracy at step 1250: 0.69\n",
      "Accuracy at step 1260: 0.71\n",
      "Accuracy at step 1270: 0.67\n",
      "Accuracy at step 1280: 0.69\n",
      "Accuracy at step 1290: 0.71\n",
      "Accuracy at step 1300: 0.66\n",
      "Accuracy at step 1310: 0.69\n",
      "Accuracy at step 1320: 0.64\n",
      "Accuracy at step 1330: 0.62\n",
      "Accuracy at step 1340: 0.67\n",
      "Accuracy at step 1350: 0.65\n",
      "Accuracy at step 1360: 0.5\n",
      "Accuracy at step 1370: 0.63\n",
      "Accuracy at step 1380: 0.76\n",
      "Accuracy at step 1390: 0.69\n",
      "Accuracy at step 1400: 0.62\n",
      "Accuracy at step 1410: 0.66\n",
      "Accuracy at step 1420: 0.78\n",
      "Accuracy at step 1430: 0.67\n",
      "Accuracy at step 1440: 0.67\n",
      "Accuracy at step 1450: 0.74\n",
      "Accuracy at step 1460: 0.77\n",
      "Accuracy at step 1470: 0.74\n",
      "Accuracy at step 1480: 0.73\n",
      "Accuracy at step 1490: 0.72\n",
      "Accuracy at step 1500: 0.69\n",
      "Accuracy at step 1510: 0.67\n",
      "Accuracy at step 1520: 0.64\n",
      "Accuracy at step 1530: 0.68\n",
      "Accuracy at step 1540: 0.7\n",
      "Accuracy at step 1550: 0.7\n",
      "Accuracy at step 1560: 0.79\n",
      "Accuracy at step 1570: 0.75\n",
      "Accuracy at step 1580: 0.7\n",
      "Accuracy at step 1590: 0.72\n",
      "Accuracy at step 1600: 0.71\n",
      "Accuracy at step 1610: 0.72\n",
      "Accuracy at step 1620: 0.68\n",
      "Accuracy at step 1630: 0.7\n",
      "Accuracy at step 1640: 0.65\n",
      "Accuracy at step 1650: 0.76\n",
      "Accuracy at step 1660: 0.66\n",
      "Accuracy at step 1670: 0.8\n",
      "Accuracy at step 1680: 0.75\n",
      "Accuracy at step 1690: 0.69\n",
      "Accuracy at step 1700: 0.68\n",
      "Accuracy at step 1710: 0.66\n",
      "Accuracy at step 1720: 0.8\n",
      "Accuracy at step 1730: 0.74\n",
      "Accuracy at step 1740: 0.72\n",
      "Accuracy at step 1750: 0.75\n",
      "Accuracy at step 1760: 0.78\n",
      "Accuracy at step 1770: 0.78\n",
      "Accuracy at step 1780: 0.67\n",
      "Accuracy at step 1790: 0.78\n",
      "Accuracy at step 1800: 0.77\n",
      "Accuracy at step 1810: 0.74\n",
      "Accuracy at step 1820: 0.71\n",
      "Accuracy at step 1830: 0.74\n",
      "Accuracy at step 1840: 0.82\n",
      "Accuracy at step 1850: 0.76\n",
      "Accuracy at step 1860: 0.84\n",
      "Accuracy at step 1870: 0.74\n",
      "Accuracy at step 1880: 0.78\n",
      "Accuracy at step 1890: 0.77\n",
      "Accuracy at step 1900: 0.74\n",
      "Accuracy at step 1910: 0.75\n",
      "Accuracy at step 1920: 0.73\n",
      "Accuracy at step 1930: 0.72\n",
      "Accuracy at step 1940: 0.73\n",
      "Accuracy at step 1950: 0.74\n",
      "Accuracy at step 1960: 0.82\n",
      "Accuracy at step 1970: 0.78\n",
      "Accuracy at step 1980: 0.84\n",
      "Accuracy at step 1990: 0.7\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter('./log/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('./log/test')\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(2000):\n",
    "        xs, ys = mnist.train.next_batch(100)\n",
    "        if i % 10 == 0:\n",
    "            summary, acc = sess.run([merged, accuracy], feed_dict = {x: xs, y_: ys, keep_prob: 1})\n",
    "            print('Accuracy at step %s: %s' %(i, acc))\n",
    "        else:\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict = {x: xs, y_: ys, keep_prob: 0.5})\n",
    "            train_writer.add_summary(summary, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create randomly initialized embedding weights which will be trained\n",
    "N = 10000 # number of items\n",
    "D = 200 # Diemnsionality of the embedding\n",
    "embedding_var = tf.Variable(tf.random_normal([N, D]), name = 'word_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto\n",
    "config = projector.ProjectorConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can add multiple embeddings. here only one\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link this tensor to its metadata file (e.g. lavels)\n",
    "embedding.metadata_path = os.path.join('./log/', 'metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the same LOG_DIR where you stored your checkpoint\n",
    "summary_writer = tf.summary.FileWriter('./log/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the next line writes a projector_config.pbtxt in the LOG_DIR, TensorBoard will read this file during startup\n",
    "projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
