{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节主要目的是学习自定义input_fn。其目的在于，在把数据提供给模型之前，可以进行更多的逻辑处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_input_fn():\n",
    "    # Preprocess your data here...\n",
    "    \n",
    "    # ... then return 1) a mapping of feature columns to Tensors with \n",
    "    # the corresponding feature data, and \n",
    "    # 2) a Tensor containing labels \n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas dataframes和numpy arrays需先转化为tensor才能作为输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for continuous data, you can create and populate a Tensor using tf.constant:\n",
    "feature_column_data = [1, 2.4, 0, 9.9, 3, 120]\n",
    "feature_tensor = tf.constant(feature_column_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sparse, catgoricaldata(data where the majority of values are 0), you'll instead want to populate a SparseTensor, \n",
    "# tf.SparseTensor(indices, values, dense_shape)\n",
    "# indices: the indices of the elements in your tensor that contain nonzero values. Takes a list of terms,\n",
    "#   where each term is itself a list containing the index of a nonzero element.\n",
    "sparse_tensor = tf.SparseTensor(indices = [[0, 1], [2, 4]],\n",
    "                                values = [6, 0.5],\n",
    "                                dense_shape = [3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed data to your model for training, you simply pass the input function you've create to you fit operation as the value of the input_fn parameter.<br>\n",
    "Also note that the input_fn parameter receive a function object, not the return of a function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-637730284703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_input_function_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmy_input_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_input_fn_training_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# alternatively, you can use Python's functools.partial function to construct a new function object with all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# However, if you'd like to be able to parameterize your input function, there are other methods for doing so.\n",
    "def my_input_function_training_set():\n",
    "    return my_input_function(training_set)\n",
    "classifier.fit(input_fn = my_input_fn_training_set, steps = 2000)\n",
    "\n",
    "# alternatively, you can use Python's functools.partial function to construct a new function object with all \n",
    "# parameter values fixed\n",
    "classifier.fit(input_fn = functools.partial(my_input_function, data_set = training_set), steps = 2000)\n",
    "\n",
    "# a third option is to wrap your input_fn invocation in a lambda and pass it to the input_fn parameter:\n",
    "classifier.fit(input_fn=lambda: my_input_fn(training_set), steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A neural network model for Boston House Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO) #设定log等级，及等级一下的就不用log了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"tax\", \"ptratio\", \"medv\"]\n",
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\"\n",
    "\n",
    "BOSTON_TRAININGSET = \"boston_train.csv\"\n",
    "BOSTON_TESTSET = \"boston_test.csv\"\n",
    "BOSTON_PREDICTSET = \"boston_predict.csv\"\n",
    "BOSTON_TRAININGSET_URL = \"http://download.tensorflow.org/data/boston_train.csv\"\n",
    "BOSTON_TESTSET_URL = \"http://download.tensorflow.org/data/boston_test.csv\"\n",
    "BOSTON_PREDICTSET_URL = \"http://download.tensorflow.org/data/boston_predict.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(BOSTON_TRAININGSET):\n",
    "    raw = urlopen(BOSTON_TRAININGSET_URL).read()\n",
    "    with open(BOSTON_TRAININGSET, \"w\") as f:\n",
    "        f.write(raw.decode(\"utf-8\"))\n",
    "\n",
    "if not os.path.exists(BOSTON_TESTSET):\n",
    "    raw = urlopen(BOSTON_TESTSET_URL).read()\n",
    "    with open(BOSTON_TESTSET, \"w\") as f:\n",
    "        f.write(raw.decode(\"utf-8\"))\n",
    "\n",
    "if not os.path.exists(BOSTON_PREDICTSET): \n",
    "    raw = urlopen(BOSTON_PREDICTSET_URL).read()\n",
    "    with open(BOSTON_PREDICTSET, \"w\") as f:\n",
    "        f.write(raw.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03359</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.428</td>\n",
       "      <td>7.024</td>\n",
       "      <td>15.8</td>\n",
       "      <td>5.4011</td>\n",
       "      <td>252</td>\n",
       "      <td>18.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12650</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.453</td>\n",
       "      <td>6.762</td>\n",
       "      <td>43.4</td>\n",
       "      <td>7.9809</td>\n",
       "      <td>284</td>\n",
       "      <td>19.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05515</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.472</td>\n",
       "      <td>7.236</td>\n",
       "      <td>41.1</td>\n",
       "      <td>4.0220</td>\n",
       "      <td>222</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.15174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.700</td>\n",
       "      <td>5.390</td>\n",
       "      <td>98.9</td>\n",
       "      <td>1.7281</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.24522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.782</td>\n",
       "      <td>71.7</td>\n",
       "      <td>4.0317</td>\n",
       "      <td>304</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus    nox     rm   age     dis  tax  ptratio  medv\n",
       "0  0.03359  75.0   2.95  0.428  7.024  15.8  5.4011  252     18.3   NaN\n",
       "1  5.09017   0.0  18.10  0.713  6.297  91.8  2.3682  666     20.2   NaN\n",
       "2  0.12650  25.0   5.13  0.453  6.762  43.4  7.9809  284     19.7   NaN\n",
       "3  0.05515  33.0   2.18  0.472  7.236  41.1  4.0220  222     18.4   NaN\n",
       "4  8.15174   0.0  18.10  0.700  5.390  98.9  1.7281  666     20.2   NaN\n",
       "5  0.24522   0.0   9.90  0.544  5.782  71.7  4.0317  304     18.4   NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_csv(BOSTON_TRAININGSET, skipinitialspace = True,\n",
    "                          skiprows = 1, names = COLUMNS)\n",
    "test_set = pd.read_csv(BOSTON_TESTSET, skipinitialspace = True,\n",
    "                      skiprows = 1, names = COLUMNS)\n",
    "prediction_set = pd.read_csv(BOSTON_PREDICTSET, skipinitialspace = True,\n",
    "                            skiprows = 1, names = COLUMNS)\n",
    "prediction_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [tf.contrib.layers.real_valued_column(k) for k in FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1148f3400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.contrib.learn.DNNRegressor(feature_columns = feature_cols,\n",
    "                                         hidden_units = [10, 10],\n",
    "                                         model_dir = \"./boston_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(data_set):\n",
    "    feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n",
    "    labels = tf.constant(data_set[LABEL].values)\n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/ihuangyiran/anaconda2/envs/py3-tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./boston_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 229.514, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1020.35\n",
      "INFO:tensorflow:loss = 86.5402, step = 101 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1051.77\n",
      "INFO:tensorflow:loss = 78.5526, step = 201 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1066.35\n",
      "INFO:tensorflow:loss = 72.7036, step = 301 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1000.15\n",
      "INFO:tensorflow:loss = 69.2047, step = 401 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.714\n",
      "INFO:tensorflow:loss = 66.3272, step = 501 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.506\n",
      "INFO:tensorflow:loss = 63.9687, step = 601 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 1076.31\n",
      "INFO:tensorflow:loss = 61.8234, step = 701 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1067.71\n",
      "INFO:tensorflow:loss = 60.2592, step = 801 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1056.66\n",
      "INFO:tensorflow:loss = 57.3311, step = 901 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1074.35\n",
      "INFO:tensorflow:loss = 55.3685, step = 1001 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.267\n",
      "INFO:tensorflow:loss = 55.1293, step = 1101 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1053.91\n",
      "INFO:tensorflow:loss = 52.0879, step = 1201 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1020.43\n",
      "INFO:tensorflow:loss = 50.0768, step = 1301 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1067.81\n",
      "INFO:tensorflow:loss = 48.3492, step = 1401 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1041.85\n",
      "INFO:tensorflow:loss = 46.7775, step = 1501 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1057.39\n",
      "INFO:tensorflow:loss = 45.4037, step = 1601 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1093.73\n",
      "INFO:tensorflow:loss = 43.9774, step = 1701 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1055.35\n",
      "INFO:tensorflow:loss = 43.0844, step = 1801 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.128\n",
      "INFO:tensorflow:loss = 41.6337, step = 1901 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 783.007\n",
      "INFO:tensorflow:loss = 40.9898, step = 2001 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.455\n",
      "INFO:tensorflow:loss = 40.1924, step = 2101 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.696\n",
      "INFO:tensorflow:loss = 39.3214, step = 2201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.377\n",
      "INFO:tensorflow:loss = 39.6563, step = 2301 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 910.89\n",
      "INFO:tensorflow:loss = 38.1481, step = 2401 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1070.65\n",
      "INFO:tensorflow:loss = 37.5643, step = 2501 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 998.663\n",
      "INFO:tensorflow:loss = 36.5097, step = 2601 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1004.84\n",
      "INFO:tensorflow:loss = 36.179, step = 2701 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 966.931\n",
      "INFO:tensorflow:loss = 35.8313, step = 2801 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 981.317\n",
      "INFO:tensorflow:loss = 35.3319, step = 2901 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.331\n",
      "INFO:tensorflow:loss = 35.0922, step = 3001 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 983.586\n",
      "INFO:tensorflow:loss = 34.4601, step = 3101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1071.24\n",
      "INFO:tensorflow:loss = 34.6122, step = 3201 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1051.17\n",
      "INFO:tensorflow:loss = 33.914, step = 3301 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1077.76\n",
      "INFO:tensorflow:loss = 34.3905, step = 3401 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1076.51\n",
      "INFO:tensorflow:loss = 33.3389, step = 3501 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1091.21\n",
      "INFO:tensorflow:loss = 32.5715, step = 3601 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1102.1\n",
      "INFO:tensorflow:loss = 32.3926, step = 3701 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.06\n",
      "INFO:tensorflow:loss = 33.0674, step = 3801 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1075.59\n",
      "INFO:tensorflow:loss = 31.6159, step = 3901 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.898\n",
      "INFO:tensorflow:loss = 31.367, step = 4001 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.206\n",
      "INFO:tensorflow:loss = 31.349, step = 4101 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 931.227\n",
      "INFO:tensorflow:loss = 31.2898, step = 4201 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 975.354\n",
      "INFO:tensorflow:loss = 30.8638, step = 4301 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1039.16\n",
      "INFO:tensorflow:loss = 30.5831, step = 4401 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 918.804\n",
      "INFO:tensorflow:loss = 30.4169, step = 4501 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 901.185\n",
      "INFO:tensorflow:loss = 30.271, step = 4601 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 873.324\n",
      "INFO:tensorflow:loss = 30.314, step = 4701 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 976.228\n",
      "INFO:tensorflow:loss = 29.9989, step = 4801 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1009.22\n",
      "INFO:tensorflow:loss = 29.8305, step = 4901 (0.099 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ./boston_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 29.5532.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x114254ac8>, 'hidden_units': [10, 10], 'feature_columns': (_RealValuedColumn(column_name='crim', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='zn', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='indus', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='nox', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='rm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='age', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dis', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='tax', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='ptratio', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)), 'optimizer': None, 'activation_fn': <function relu at 0x109fb5ea0>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(input_fn = lambda: input_fn(training_set), steps = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/ihuangyiran/anaconda2/envs/py3-tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-12-09:38:08\n",
      "INFO:tensorflow:Restoring parameters from ./boston_model/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-12-09:38:08\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 13.7506\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    }
   ],
   "source": [
    "ev = regressor.evaluate(input_fn = lambda: input_fn(test_set), steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 13.750644\n"
     ]
    }
   ],
   "source": [
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ihuangyiran/anaconda2/envs/py3-tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Restoring parameters from ./boston_model/model.ckpt-5000\n",
      "Predictions: [36.897224, 19.84107, 22.817165, 38.114002, 16.066898, 19.218407]\n"
     ]
    }
   ],
   "source": [
    "y = regressor.predict(input_fn = lambda: input_fn(prediction_set))\n",
    "# .predict() returns an iterator; convert to a list and print predictions\n",
    "predictions = list(itertools.islice(y, 6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要知道如何读取数据（注意了quickstart中的进行区别），推荐用lambda\n",
    "### 懂得contrib.learn的建模，训练，评估和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
